{"time_total_s": 2.3765981197357178, "hostname": "e9379f55ba79", "time_this_iter_s": 2.3765981197357178, "experiment_id": "d32ddf96cb8546f994c7d29ed46fab9d", "timesteps_total": null, "timesteps_since_restore": 0, "training_iteration": 1, "config": {"workers": 2, "dataset": "Mallat", "num_rnn_layers": 1, "hidden_dims": 64, "learning_rate": 0.01, "epochs": 99999, "dropout": 0.3, "fold": 8, "earliness_factor": 1, "switch_epoch": 9999, "batchsize": 96}, "loss": 2.0765488147735596, "pid": 7046, "timestamp": 1544558204, "confusion_matrix": "[[0. 0. 0. 2. 0. 0. 0. 0.]\n [0. 0. 0. 1. 0. 0. 0. 0.]\n [0. 0. 0. 1. 0. 0. 0. 0.]\n [0. 0. 0. 2. 0. 0. 0. 0.]\n [0. 0. 0. 0. 0. 0. 0. 0.]\n [0. 0. 0. 2. 0. 0. 0. 0.]\n [0. 0. 0. 1. 0. 0. 0. 0.]\n [0. 0. 0. 1. 0. 0. 0. 0.]]", "date": "2018-12-11_20-56-44", "targets": "[[5 5 5 ... 5 5 5]\n [3 3 3 ... 3 3 3]\n [7 7 7 ... 7 7 7]\n ...\n [0 0 0 ... 0 0 0]\n [2 2 2 ... 2 2 2]\n [6 6 6 ... 6 6 6]]", "episodes_total": null, "done": false, "iterations_since_restore": 1, "weights": "[[5.8670375e-05 5.8512280e-05 5.8375153e-05 ... 5.4730313e-05\n  5.4731154e-05 9.4163698e-01]\n [5.8645201e-05 5.8391604e-05 5.8170448e-05 ... 5.4667660e-05\n  5.4663291e-05 9.4163793e-01]\n [5.8650628e-05 5.8419391e-05 5.8219008e-05 ... 5.4569431e-05\n  5.4561893e-05 9.4163728e-01]\n ...\n [5.8650799e-05 5.8419286e-05 5.8215675e-05 ... 5.4707987e-05\n  5.4709293e-05 9.4163620e-01]\n [5.8652644e-05 5.8428031e-05 5.8228663e-05 ... 5.4620603e-05\n  5.4620876e-05 9.4163537e-01]\n [5.8655944e-05 5.8445141e-05 5.8261987e-05 ... 5.4774730e-05\n  5.4770073e-05 9.4163567e-01]]", "time_since_restore": 2.3765981197357178, "node_ip": "172.17.0.2", "probas": "[[[0.10507285 0.14012349 0.11439393 ... 0.11436211 0.14011239 0.12916918]\n  [0.10544665 0.13965106 0.11462643 ... 0.11436966 0.13993758 0.12904276]\n  [0.10536093 0.13975854 0.114572   ... 0.11436717 0.13997798 0.1290718 ]\n  ...\n  [0.10535882 0.13976124 0.11457069 ... 0.11436714 0.139979   0.12907253]\n  [0.10533015 0.13979724 0.1145526  ... 0.11436639 0.13999245 0.12908223]\n  [0.10528015 0.13986024 0.11452134 ... 0.11436523 0.14001587 0.12909913]]\n\n [[0.10554145 0.13940531 0.11460961 ... 0.11423599 0.14012592 0.12897508]\n  [0.10616375 0.13852428 0.11496219 ... 0.11417516 0.13998823 0.12872195]\n  [0.10602038 0.13872828 0.11487857 ... 0.11418738 0.14001918 0.1287821 ]\n  ...\n  [0.10602796 0.13871932 0.1148838  ... 0.11418793 0.14001529 0.1287792 ]\n  [0.10598762 0.13877773 0.11486109 ... 0.11419237 0.14002255 0.12879613]\n  [0.1058902  0.13891356 0.11480436 ... 0.11420001 0.1400468  0.12883581]]\n\n [[0.10577868 0.13897304 0.11475363 ... 0.11414005 0.1401903  0.12881507]\n  [0.10650024 0.13785288 0.11518729 ... 0.11402962 0.1401145  0.12845518]\n  [0.10633212 0.13811916 0.11508162 ... 0.11405262 0.14013039 0.1285433 ]\n  ...\n  [0.10635623 0.13808614 0.11509698 ... 0.11405156 0.14012334 0.12853281]\n  [0.10631961 0.13814701 0.11507462 ... 0.11405844 0.14012374 0.12855303]\n  [0.10618678 0.13834828 0.11499306 ... 0.11407503 0.1401432  0.12861799]]\n\n ...\n\n [[0.10556765 0.13808432 0.11539425 ... 0.11445226 0.13991362 0.12826437]\n  [0.1056818  0.13777821 0.11554209 ... 0.1144489  0.13988653 0.12814136]\n  [0.10578682 0.13732713 0.11577623 ... 0.11448241 0.13983932 0.12793781]\n  ...\n  [0.10558678 0.13798338 0.11544841 ... 0.11446543 0.13989647 0.1282147 ]\n  [0.10567077 0.13758369 0.11565904 ... 0.11450747 0.13984136 0.12802523]\n  [0.10556057 0.13827288 0.1152845  ... 0.11440653 0.13995855 0.12837073]]\n\n [[0.10556367 0.13810201 0.11538501 ... 0.11445063 0.13991609 0.12827271]\n  [0.10568256 0.13777256 0.1155452  ... 0.11444991 0.1398854  0.12813847]\n  [0.10578642 0.13730901 0.11578681 ... 0.11448688 0.13983622 0.12792781]\n  ...\n  [0.10558328 0.13800259 0.11543819 ... 0.11446325 0.1398992  0.12822406]\n  [0.10567059 0.13759723 0.11565137 ... 0.11450469 0.13984343 0.12803255]\n  [0.10556299 0.1382654  0.11528832 ... 0.114407   0.13995731 0.12836747]]\n\n [[0.1055603  0.13811862 0.11537629 ... 0.11444893 0.13991858 0.12828074]\n  [0.10568362 0.13776663 0.11554848 ... 0.11445083 0.13988432 0.12813556]\n  [0.10578589 0.13729194 0.11579679 ... 0.11449125 0.13983324 0.12791835]\n  ...\n  [0.10558061 0.13802025 0.1154287  ... 0.11446093 0.13990194 0.1282329 ]\n  [0.10567115 0.13760883 0.11564461 ... 0.11450177 0.13984546 0.12803915]\n  [0.10556583 0.13825718 0.11529242 ... 0.11440735 0.13995604 0.12836394]]]", "accuracy": 0.2, "inputs": "[[[-0.6441754 ]\n  [-0.6316425 ]\n  [-0.62136537]\n  ...\n  [-0.8751152 ]\n  [-0.86900634]\n  [-0.86335516]]\n\n [[-1.0574203 ]\n  [-1.0514047 ]\n  [-1.0463719 ]\n  ...\n  [-0.9943956 ]\n  [-0.9967297 ]\n  [-0.99922913]]\n\n [[-0.960383  ]\n  [-0.9472135 ]\n  [-0.9349204 ]\n  ...\n  [-1.1757457 ]\n  [-1.1830101 ]\n  [-1.1899081 ]]\n\n ...\n\n [[-0.9579931 ]\n  [-0.9583305 ]\n  [-0.9592496 ]\n  ...\n  [-0.91240275]\n  [-0.9057921 ]\n  [-0.899797  ]]\n\n [[-0.92588603]\n  [-0.9337288 ]\n  [-0.9419923 ]\n  ...\n  [-1.0675538 ]\n  [-1.0628523 ]\n  [-1.0588943 ]]\n\n [[-0.8702758 ]\n  [-0.85922086]\n  [-0.84914935]\n  ...\n  [-0.811603  ]\n  [-0.8145301 ]\n  [-0.8177387 ]]]"}
{"time_total_s": 4.815410375595093, "hostname": "e9379f55ba79", "time_this_iter_s": 2.438812255859375, "experiment_id": "d32ddf96cb8546f994c7d29ed46fab9d", "timesteps_total": null, "timesteps_since_restore": 0, "training_iteration": 2, "config": {"workers": 2, "dataset": "Mallat", "num_rnn_layers": 1, "hidden_dims": 64, "learning_rate": 0.01, "epochs": 99999, "dropout": 0.3, "fold": 8, "earliness_factor": 1, "switch_epoch": 9999, "batchsize": 96}, "loss": 2.08358097076416, "pid": 7046, "timestamp": 1544558207, "confusion_matrix": "[[0. 0. 0. 2. 0. 0. 0. 0.]\n [0. 0. 0. 1. 0. 0. 0. 0.]\n [0. 0. 0. 1. 0. 0. 0. 0.]\n [0. 0. 0. 2. 0. 0. 0. 0.]\n [0. 0. 0. 0. 0. 0. 0. 0.]\n [0. 0. 0. 2. 0. 0. 0. 0.]\n [0. 0. 0. 1. 0. 0. 0. 0.]\n [0. 0. 0. 1. 0. 0. 0. 0.]]", "date": "2018-12-11_20-56-47", "targets": "[[5 5 5 ... 5 5 5]\n [3 3 3 ... 3 3 3]\n [7 7 7 ... 7 7 7]\n ...\n [0 0 0 ... 0 0 0]\n [2 2 2 ... 2 2 2]\n [6 6 6 ... 6 6 6]]", "episodes_total": null, "done": false, "iterations_since_restore": 2, "weights": "[[5.9856808e-05 5.9570000e-05 5.9339276e-05 ... 5.5207402e-05\n  5.5212899e-05 9.4016385e-01]\n [5.9794344e-05 5.9353169e-05 5.9002032e-05 ... 5.5085598e-05\n  5.5079534e-05 9.4015592e-01]\n [5.9807626e-05 5.9401180e-05 5.9078597e-05 ... 5.4879336e-05\n  5.4865352e-05 9.4016635e-01]\n ...\n [5.9807971e-05 5.9400962e-05 5.9073416e-05 ... 5.5156350e-05\n  5.5163000e-05 9.4015759e-01]\n [5.9812533e-05 5.9416252e-05 5.9094207e-05 ... 5.4963144e-05\n  5.4968161e-05 9.4016898e-01]\n [5.9820744e-05 5.9446797e-05 5.9148155e-05 ... 5.5317530e-05\n  5.5311113e-05 9.4016165e-01]]", "time_since_restore": 4.815410375595093, "node_ip": "172.17.0.2", "probas": "[[[0.09367006 0.14847669 0.10296649 ... 0.0939413  0.15891573 0.13215569]\n  [0.09408163 0.14760391 0.10336979 ... 0.09377091 0.15892783 0.13200717]\n  [0.09398842 0.14780258 0.10327512 ... 0.09380978 0.15892406 0.1320407 ]\n  ...\n  [0.09398609 0.14780751 0.10327278 ... 0.09381074 0.15892397 0.13204151]\n  [0.09395474 0.14787415 0.10324144 ... 0.09382377 0.15892285 0.13205278]\n  [0.09389988 0.14799048 0.10318713 ... 0.09384647 0.15892105 0.13207252]]\n\n [[0.09405674 0.1473076  0.10348408 ... 0.09364494 0.15914306 0.13194497]\n  [0.09460986 0.14579809 0.10421684 ... 0.09332178 0.15933527 0.13167909]\n  [0.09448842 0.14614652 0.10404085 ... 0.09339488 0.15928574 0.1317399 ]\n  ...\n  [0.09449653 0.14612971 0.1040496  ... 0.09339156 0.15928613 0.13173665]\n  [0.09446279 0.14622864 0.10400065 ... 0.09341269 0.15927137 0.13175385]\n  [0.09437542 0.14646287 0.10388494 ... 0.09346224 0.15924293 0.13179538]]\n\n [[0.09413812 0.14667714 0.10389745 ... 0.09346323 0.15936391 0.13183388]\n  [0.09462842 0.1448491  0.10492042 ... 0.09308843 0.15971698 0.13152018]\n  [0.094527   0.14528228 0.10466588 ... 0.09317048 0.15962526 0.13159251]\n  ...\n  [0.09454761 0.14522487 0.1046968  ... 0.09315935 0.15963203 0.13158196]\n  [0.09452829 0.14532146 0.10463936 ... 0.09317832 0.15960877 0.13159776]\n  [0.09443454 0.14565401 0.10445283 ... 0.09324474 0.15954891 0.13165553]]\n\n ...\n\n [[0.09305162 0.14569004 0.10617876 ... 0.09465726 0.16000687 0.13214317]\n  [0.09297372 0.1451836  0.10662834 ... 0.09477144 0.16016744 0.13211882]\n  [0.09269331 0.14441478 0.10742495 ... 0.09515177 0.16047971 0.13212569]\n  ...\n  [0.09298591 0.14552939 0.10636902 ... 0.09476113 0.16007611 0.13214673]\n  [0.09271999 0.14486028 0.10710587 ... 0.0951574  0.16036005 0.13215843]\n  [0.09322329 0.1459676  0.10576516 ... 0.09438334 0.15986186 0.13212049]]\n\n [[0.09306167 0.14571795 0.10614714 ... 0.09464225 0.15999517 0.13214296]\n  [0.09296926 0.1451744  0.10663971 ... 0.09477859 0.16017154 0.13211922]\n  [0.09267024 0.14438248 0.10746705 ... 0.09518401 0.1604978  0.13212915]\n  ...\n  [0.09299921 0.14556009 0.10633288 ... 0.09474199 0.1600622  0.13214579]\n  [0.09273598 0.14488356 0.10707559 ... 0.0951357  0.16034669 0.13215597]\n  [0.09322125 0.14595592 0.10577711 ... 0.09438759 0.15986562 0.13212004]]\n\n [[0.09307177 0.14574388 0.10611678 ... 0.09462716 0.1599839  0.13214245]\n  [0.09296513 0.14516458 0.10665114 ... 0.09478533 0.1601756  0.13211943]\n  [0.09264801 0.14435188 0.10750718 ... 0.09521531 0.16051514 0.13213259]\n  ...\n  [0.09301245 0.14558801 0.10629871 ... 0.09472293 0.16004902 0.13214463]\n  [0.09275141 0.14490336 0.10704807 ... 0.09511453 0.16033447 0.13215335]\n  [0.09321935 0.14594296 0.10578977 ... 0.09439165 0.15986955 0.13211939]]]", "accuracy": 0.2, "inputs": "[[[-0.6441754 ]\n  [-0.6316425 ]\n  [-0.62136537]\n  ...\n  [-0.8751152 ]\n  [-0.86900634]\n  [-0.86335516]]\n\n [[-1.0574203 ]\n  [-1.0514047 ]\n  [-1.0463719 ]\n  ...\n  [-0.9943956 ]\n  [-0.9967297 ]\n  [-0.99922913]]\n\n [[-0.960383  ]\n  [-0.9472135 ]\n  [-0.9349204 ]\n  ...\n  [-1.1757457 ]\n  [-1.1830101 ]\n  [-1.1899081 ]]\n\n ...\n\n [[-0.9579931 ]\n  [-0.9583305 ]\n  [-0.9592496 ]\n  ...\n  [-0.91240275]\n  [-0.9057921 ]\n  [-0.899797  ]]\n\n [[-0.92588603]\n  [-0.9337288 ]\n  [-0.9419923 ]\n  ...\n  [-1.0675538 ]\n  [-1.0628523 ]\n  [-1.0588943 ]]\n\n [[-0.8702758 ]\n  [-0.85922086]\n  [-0.84914935]\n  ...\n  [-0.811603  ]\n  [-0.8145301 ]\n  [-0.8177387 ]]]"}
{"time_total_s": 7.202019453048706, "hostname": "e9379f55ba79", "time_this_iter_s": 2.3866090774536133, "experiment_id": "d32ddf96cb8546f994c7d29ed46fab9d", "timesteps_total": null, "timesteps_since_restore": 0, "training_iteration": 3, "config": {"workers": 2, "dataset": "Mallat", "num_rnn_layers": 1, "hidden_dims": 64, "learning_rate": 0.01, "epochs": 99999, "dropout": 0.3, "fold": 8, "earliness_factor": 1, "switch_epoch": 9999, "batchsize": 96}, "loss": 2.1108880043029785, "pid": 7046, "timestamp": 1544558209, "confusion_matrix": "[[0. 0. 0. 2. 0. 0. 0. 0.]\n [0. 0. 0. 1. 0. 0. 0. 0.]\n [0. 0. 0. 1. 0. 0. 0. 0.]\n [0. 0. 0. 2. 0. 0. 0. 0.]\n [0. 0. 0. 0. 0. 0. 0. 0.]\n [0. 0. 0. 2. 0. 0. 0. 0.]\n [0. 0. 0. 1. 0. 0. 0. 0.]\n [0. 0. 0. 1. 0. 0. 0. 0.]]", "date": "2018-12-11_20-56-49", "targets": "[[5 5 5 ... 5 5 5]\n [3 3 3 ... 3 3 3]\n [7 7 7 ... 7 7 7]\n ...\n [0 0 0 ... 0 0 0]\n [2 2 2 ... 2 2 2]\n [6 6 6 ... 6 6 6]]", "episodes_total": null, "done": false, "iterations_since_restore": 3, "weights": "[[6.0749924e-05 6.0394759e-05 6.0141636e-05 ... 5.5837412e-05\n  5.5844372e-05 9.3838882e-01]\n [6.0685070e-05 6.0161274e-05 5.9795268e-05 ... 5.5665638e-05\n  5.5659253e-05 9.3826300e-01]\n [6.0697632e-05 6.0210001e-05 5.9870123e-05 ... 5.5421093e-05\n  5.5408043e-05 9.3835843e-01]\n ...\n [6.0697977e-05 6.0210405e-05 5.9865961e-05 ... 5.5774537e-05\n  5.5782712e-05 9.3828118e-01]\n [6.0702554e-05 6.0226648e-05 5.9887199e-05 ... 5.5579294e-05\n  5.5583801e-05 9.3843448e-01]\n [6.0710830e-05 6.0258193e-05 5.9940496e-05 ... 5.5953900e-05\n  5.5946668e-05 9.3835139e-01]]", "time_since_restore": 7.202019453048706, "node_ip": "172.17.0.2", "probas": "[[[0.08326678 0.15450008 0.10063826 ... 0.07545574 0.17908601 0.13194324]\n  [0.08387032 0.15352343 0.10105362 ... 0.07548579 0.17887318 0.13179795]\n  [0.08373424 0.15374336 0.10095619 ... 0.07547732 0.1789221  0.1318289 ]\n  ...\n  [0.08373084 0.15374881 0.10095377 ... 0.07547712 0.17892331 0.1318297 ]\n  [0.08368503 0.15382294 0.10092153 ... 0.07547452 0.17893973 0.13184041]\n  [0.08360469 0.15395272 0.10086562 ... 0.07547022 0.1789682  0.13185944]]\n\n [[0.08385681 0.1532848  0.10118528 ... 0.07537596 0.17892301 0.13163675]\n  [0.08461569 0.15171865 0.10195294 ... 0.07543919 0.17862359 0.13138172]\n  [0.08445597 0.15207367 0.10176837 ... 0.07541513 0.17869233 0.1314326 ]\n  ...\n  [0.08446708 0.1520555  0.10177733 ... 0.07541662 0.17868812 0.1314304 ]\n  [0.08442207 0.1521563  0.10172582 ... 0.07541125 0.17870714 0.131446  ]\n  [0.08430344 0.15239897 0.10160485 ... 0.0753988  0.17875478 0.13148344]]\n\n [[0.08404201 0.15279658 0.10161111 ... 0.07531601 0.17880028 0.13141537]\n  [0.08459946 0.1510523  0.10270638 ... 0.07552878 0.17842649 0.13115901]\n  [0.08450802 0.15145959 0.10243132 ... 0.07545085 0.17851336 0.13120013]\n  ...\n  [0.08453169 0.15140058 0.10246415 ... 0.07545909 0.17850068 0.13119444]\n  [0.08451477 0.15148827 0.10240189 ... 0.07544336 0.17851956 0.13120563]\n  [0.08441167 0.15180941 0.10220213 ... 0.07539843 0.17858884 0.13124621]]\n\n ...\n\n [[0.07974267 0.15169497 0.10474613 ... 0.0796236  0.18110596 0.13216032]\n  [0.07899589 0.15082435 0.10530548 ... 0.08037312 0.18151961 0.13239253]\n  [0.07688578 0.14886634 0.10636711 ... 0.0821939  0.18307026 0.13309951]\n  ...\n  [0.07915936 0.15124518 0.10503142 ... 0.08011815 0.18156394 0.13234174]\n  [0.07678906 0.1491824  0.10609698 ... 0.08203008 0.18351749 0.13313289]\n  [0.08111703 0.15253809 0.1040806  ... 0.07842423 0.18004185 0.13176101]]\n\n [[0.07982764 0.15176198 0.10470057 ... 0.07954917 0.18104333 0.13213474]\n  [0.07895737 0.15079467 0.10532283 ... 0.08040538 0.18155065 0.13240494]\n  [0.07671522 0.14872582 0.10642845 ... 0.08232464 0.18322068 0.1331588 ]\n  ...\n  [0.07926497 0.15132804 0.10497952 ... 0.0800292  0.18148296 0.13230899]\n  [0.07690408 0.14927757 0.10605454 ... 0.08194378 0.1834165  0.13309363]\n  [0.08109371 0.15251766 0.10409734 ... 0.07844817 0.18005677 0.13176748]]\n\n [[0.07991128 0.15182577 0.10465642 ... 0.07947624 0.18098137 0.13210972]\n  [0.07891997 0.15076475 0.10534016 ... 0.08043695 0.18158053 0.132417  ]\n  [0.0765484  0.1485875  0.10648716 ... 0.08245134 0.18336998 0.13321726]\n  ...\n  [0.07936869 0.15140656 0.10492972 ... 0.07994247 0.18140276 0.13227707]\n  [0.07701643 0.14936739 0.10601474 ... 0.08186079 0.18331616 0.1330554 ]\n  [0.08107009 0.15249577 0.10411492 ... 0.0784727  0.1800715  0.13177404]]]", "accuracy": 0.2, "inputs": "[[[-0.6441754 ]\n  [-0.6316425 ]\n  [-0.62136537]\n  ...\n  [-0.8751152 ]\n  [-0.86900634]\n  [-0.86335516]]\n\n [[-1.0574203 ]\n  [-1.0514047 ]\n  [-1.0463719 ]\n  ...\n  [-0.9943956 ]\n  [-0.9967297 ]\n  [-0.99922913]]\n\n [[-0.960383  ]\n  [-0.9472135 ]\n  [-0.9349204 ]\n  ...\n  [-1.1757457 ]\n  [-1.1830101 ]\n  [-1.1899081 ]]\n\n ...\n\n [[-0.9579931 ]\n  [-0.9583305 ]\n  [-0.9592496 ]\n  ...\n  [-0.91240275]\n  [-0.9057921 ]\n  [-0.899797  ]]\n\n [[-0.92588603]\n  [-0.9337288 ]\n  [-0.9419923 ]\n  ...\n  [-1.0675538 ]\n  [-1.0628523 ]\n  [-1.0588943 ]]\n\n [[-0.8702758 ]\n  [-0.85922086]\n  [-0.84914935]\n  ...\n  [-0.811603  ]\n  [-0.8145301 ]\n  [-0.8177387 ]]]"}
{"time_total_s": 9.750792026519775, "hostname": "e9379f55ba79", "time_this_iter_s": 2.5487725734710693, "experiment_id": "d32ddf96cb8546f994c7d29ed46fab9d", "timesteps_total": null, "timesteps_since_restore": 0, "training_iteration": 4, "config": {"workers": 2, "dataset": "Mallat", "num_rnn_layers": 1, "hidden_dims": 64, "learning_rate": 0.01, "epochs": 99999, "dropout": 0.3, "fold": 8, "earliness_factor": 1, "switch_epoch": 9999, "batchsize": 96}, "loss": 2.095419406890869, "pid": 7046, "timestamp": 1544558212, "confusion_matrix": "[[0. 0. 0. 2. 0. 0. 0. 0.]\n [0. 0. 0. 1. 0. 0. 0. 0.]\n [0. 0. 0. 1. 0. 0. 0. 0.]\n [0. 0. 0. 2. 0. 0. 0. 0.]\n [0. 0. 0. 0. 0. 0. 0. 0.]\n [0. 0. 0. 2. 0. 0. 0. 0.]\n [0. 0. 0. 1. 0. 0. 0. 0.]\n [0. 0. 0. 1. 0. 0. 0. 0.]]", "date": "2018-12-11_20-56-52", "targets": "[[5 5 5 ... 5 5 5]\n [3 3 3 ... 3 3 3]\n [7 7 7 ... 7 7 7]\n ...\n [0 0 0 ... 0 0 0]\n [2 2 2 ... 2 2 2]\n [6 6 6 ... 6 6 6]]", "episodes_total": null, "done": false, "iterations_since_restore": 4, "weights": "[[6.1033759e-05 6.0688948e-05 6.0522867e-05 ... 5.7287209e-05\n  5.7284433e-05 9.3969989e-01]\n [6.0991864e-05 6.0512055e-05 6.0288443e-05 ... 5.7034031e-05\n  5.7031535e-05 9.3726605e-01]\n [6.0997743e-05 6.0544502e-05 6.0335020e-05 ... 5.6985897e-05\n  5.6988902e-05 9.3777907e-01]\n ...\n [6.0997911e-05 6.0545939e-05 6.0333699e-05 ... 5.7244852e-05\n  5.7241145e-05 9.3883407e-01]\n [6.1000359e-05 6.0558130e-05 6.0348088e-05 ... 5.7372206e-05\n  5.7364490e-05 9.4007230e-01]\n [6.1005361e-05 6.0579725e-05 6.0381411e-05 ... 5.7171881e-05\n  5.7167301e-05 9.3863666e-01]]", "time_since_restore": 9.750792026519775, "node_ip": "172.17.0.2", "probas": "[[[0.08683209 0.15761736 0.11385312 ... 0.07179721 0.1880855  0.13538781]\n  [0.08751235 0.1563308  0.11473749 ... 0.07186355 0.18766287 0.13510312]\n  [0.08736102 0.1566204  0.11452936 ... 0.07184553 0.187762   0.135164  ]\n  ...\n  [0.08735725 0.15662768 0.11452425 ... 0.07184511 0.18776447 0.13516557]\n  [0.08730597 0.15672524 0.11445544 ... 0.0718395  0.18779734 0.13518655]\n  [0.08721578 0.15689617 0.11433631 ... 0.07183014 0.1878542  0.13522385]]\n\n [[0.08751029 0.1562909  0.11498327 ... 0.07175518 0.18729317 0.13475023]\n  [0.08825546 0.15439086 0.1166279  ... 0.07196413 0.18636602 0.134252  ]\n  [0.08811253 0.15482321 0.11622912 ... 0.07189776 0.18658549 0.13435057]\n  ...\n  [0.0881239  0.15479828 0.11624868 ... 0.07190071 0.18657766 0.13434695]\n  [0.08808269 0.1549188  0.11613798 ... 0.07188401 0.18664132 0.13437772]\n  [0.08796809 0.15521696 0.1158778  ... 0.07184764 0.18678321 0.13444977]]\n\n [[0.08772896 0.15605496 0.1157727  ... 0.0717507  0.18641278 0.13418272]\n  [0.08804124 0.15407537 0.11806255 ... 0.07233366 0.18497562 0.13361448]\n  [0.08804109 0.15455224 0.11748138 ... 0.0721441  0.18531685 0.13371077]\n  ...\n  [0.08805786 0.15447414 0.11755335 ... 0.07216284 0.1852837  0.13370141]\n  [0.08806133 0.1545688  0.11742423 ... 0.07212186 0.18536834 0.13372931]\n  [0.08800736 0.15494901 0.11700143 ... 0.072007   0.18561518 0.1338157 ]]\n\n ...\n\n [[0.08168634 0.15561396 0.11978915 ... 0.0769844  0.18551897 0.13248807]\n  [0.08040685 0.1544252  0.12080494 ... 0.07809051 0.18560664 0.13263096]\n  [0.07695328 0.15163104 0.12257988 ... 0.08062643 0.18663672 0.13328473]\n  ...\n  [0.08077618 0.15500878 0.12020866 ... 0.07762105 0.18581687 0.13262227]\n  [0.07679511 0.15202418 0.12186064 ... 0.08026371 0.1873864  0.13341539]\n  [0.08368258 0.1567046  0.11890952 ... 0.07556799 0.18489978 0.13227272]]\n\n [[0.08181923 0.15570216 0.11971962 ... 0.07688702 0.1854843  0.13247187]\n  [0.08034783 0.15438429 0.12082998 ... 0.07813113 0.18562846 0.1326413 ]\n  [0.07667638 0.1514256  0.12267031 ... 0.08080225 0.18676557 0.13334903]\n  ...\n  [0.08094401 0.15511969 0.1201295  ... 0.07750297 0.18576553 0.13259824]\n  [0.0769888  0.15216266 0.12179618 ... 0.08014306 0.18729882 0.13337365]\n  [0.08364698 0.15667781 0.11893555 ... 0.07559836 0.18490353 0.1322743 ]]\n\n [[0.08194921 0.15578564 0.11965322 ... 0.07679237 0.18544975 0.13245647]\n  [0.08029026 0.15434285 0.12085544 ... 0.07817117 0.18564917 0.13265152]\n  [0.07640393 0.15122202 0.12275626 ... 0.08097326 0.18689606 0.13341378]\n  ...\n  [0.08110753 0.15522414 0.12005488 ... 0.07738895 0.18571395 0.1325751 ]\n  [0.0771781  0.15229376 0.12173765 ... 0.08002785 0.18720956 0.13333263]\n  [0.08361059 0.156649   0.11896339 ... 0.07562982 0.18490657 0.13227591]]]", "accuracy": 0.2, "inputs": "[[[-0.6441754 ]\n  [-0.6316425 ]\n  [-0.62136537]\n  ...\n  [-0.8751152 ]\n  [-0.86900634]\n  [-0.86335516]]\n\n [[-1.0574203 ]\n  [-1.0514047 ]\n  [-1.0463719 ]\n  ...\n  [-0.9943956 ]\n  [-0.9967297 ]\n  [-0.99922913]]\n\n [[-0.960383  ]\n  [-0.9472135 ]\n  [-0.9349204 ]\n  ...\n  [-1.1757457 ]\n  [-1.1830101 ]\n  [-1.1899081 ]]\n\n ...\n\n [[-0.9579931 ]\n  [-0.9583305 ]\n  [-0.9592496 ]\n  ...\n  [-0.91240275]\n  [-0.9057921 ]\n  [-0.899797  ]]\n\n [[-0.92588603]\n  [-0.9337288 ]\n  [-0.9419923 ]\n  ...\n  [-1.0675538 ]\n  [-1.0628523 ]\n  [-1.0588943 ]]\n\n [[-0.8702758 ]\n  [-0.85922086]\n  [-0.84914935]\n  ...\n  [-0.811603  ]\n  [-0.8145301 ]\n  [-0.8177387 ]]]"}
{"time_total_s": 12.107168674468994, "hostname": "e9379f55ba79", "time_this_iter_s": 2.3563766479492188, "experiment_id": "d32ddf96cb8546f994c7d29ed46fab9d", "timesteps_total": null, "timesteps_since_restore": 0, "training_iteration": 5, "config": {"workers": 2, "dataset": "Mallat", "num_rnn_layers": 1, "hidden_dims": 64, "learning_rate": 0.01, "epochs": 99999, "dropout": 0.3, "fold": 8, "earliness_factor": 1, "switch_epoch": 9999, "batchsize": 96}, "loss": 2.0671377182006836, "pid": 7046, "timestamp": 1544558214, "confusion_matrix": "[[0. 0. 0. 2. 0. 0. 0. 0.]\n [0. 0. 0. 1. 0. 0. 0. 0.]\n [0. 0. 0. 1. 0. 0. 0. 0.]\n [0. 0. 0. 2. 0. 0. 0. 0.]\n [0. 0. 0. 0. 0. 0. 0. 0.]\n [0. 0. 0. 2. 0. 0. 0. 0.]\n [0. 0. 0. 1. 0. 0. 0. 0.]\n [0. 0. 0. 1. 0. 0. 0. 0.]]", "date": "2018-12-11_20-56-54", "targets": "[[5 5 5 ... 5 5 5]\n [3 3 3 ... 3 3 3]\n [7 7 7 ... 7 7 7]\n ...\n [0 0 0 ... 0 0 0]\n [2 2 2 ... 2 2 2]\n [6 6 6 ... 6 6 6]]", "episodes_total": null, "done": false, "iterations_since_restore": 5, "weights": "[[6.4462001e-05 6.4137661e-05 6.4045111e-05 ... 6.1088496e-05\n  6.1085637e-05 9.4226450e-01]\n [6.4469445e-05 6.4014050e-05 6.3862521e-05 ... 6.0985749e-05\n  6.0981398e-05 9.4165277e-01]\n [6.4463355e-05 6.4034371e-05 6.3901687e-05 ... 6.0881168e-05\n  6.0875896e-05 9.4137299e-01]\n ...\n [6.4463231e-05 6.4036998e-05 6.3901687e-05 ... 6.1044899e-05\n  6.1041930e-05 9.4167101e-01]\n [6.4461819e-05 6.4046108e-05 6.3914064e-05 ... 6.1016824e-05\n  6.1013223e-05 9.4198245e-01]\n [6.4460037e-05 6.4058630e-05 6.3938998e-05 ... 6.1046856e-05\n  6.1042083e-05 9.4188988e-01]]", "time_since_restore": 12.107168674468994, "node_ip": "172.17.0.2", "probas": "[[[0.09750647 0.15202779 0.12336501 ... 0.08116551 0.18052639 0.13708736]\n  [0.09784731 0.14960174 0.12434229 ... 0.08205356 0.1808459  0.13699807]\n  [0.09777961 0.15015417 0.12411411 ... 0.08184106 0.18077068 0.13700937]\n  ...\n  [0.09777789 0.15016796 0.12410855 ... 0.0818359  0.1807689  0.13700975]\n  [0.09775372 0.15035312 0.12403283 ... 0.08176611 0.18074405 0.13701485]\n  [0.09770991 0.15067656 0.12390152 ... 0.08164594 0.1807011  0.13702522]]\n\n [[0.09772149 0.14947642 0.12449355 ... 0.08234822 0.18035853 0.13663764]\n  [0.0976878  0.14578775 0.12614025 ... 0.08424456 0.1806258  0.13657705]\n  [0.09774502 0.14664018 0.1257487  ... 0.08376554 0.18055286 0.13655892]\n  ...\n  [0.09774749 0.14659137 0.12576981 ... 0.08378673 0.18056276 0.13656113]\n  [0.09776118 0.14682764 0.12566139 ... 0.08365444 0.18054774 0.13656068]\n  [0.09777145 0.14740932 0.12540038 ... 0.08335292 0.18049583 0.13656077]]\n\n [[0.09757271 0.14869563 0.12494827 ... 0.08332918 0.17980695 0.13628647]\n  [0.09674583 0.14469635 0.12689298 ... 0.08630259 0.17991373 0.1363817 ]\n  [0.09704474 0.14566445 0.12641187 ... 0.0855111  0.17985715 0.13629964]\n  ...\n  [0.097026   0.14551152 0.12648329 ... 0.08560028 0.17988041 0.13631146]\n  [0.09709623 0.14570759 0.12638307 ... 0.08542208 0.179882   0.13629982]\n  [0.09725434 0.1464708  0.12601301 ... 0.08487267 0.17983271 0.13626139]]\n\n ...\n\n [[0.09442048 0.1493973  0.12439908 ... 0.08813947 0.17963023 0.13517937]\n  [0.09351495 0.1483081  0.12481604 ... 0.08947887 0.17994925 0.13532135]\n  [0.09170711 0.14657895 0.12536624 ... 0.09179765 0.18064487 0.1357073 ]\n  ...\n  [0.09404356 0.14906603 0.12450498 ... 0.08863151 0.17976652 0.1352382 ]\n  [0.09247533 0.14761001 0.12495816 ... 0.09063808 0.18036725 0.13555115]\n  [0.09521493 0.1499159  0.12425636 ... 0.08715419 0.17936194 0.13508755]]\n\n [[0.09448371 0.149451   0.12438129 ... 0.08805547 0.17960912 0.13517115]\n  [0.0934919  0.14828677 0.12482253 ... 0.08950803 0.17995855 0.13532603]\n  [0.09160698 0.14650543 0.12538143 ... 0.09190897 0.18068683 0.13573244]\n  ...\n  [0.09411898 0.14912485 0.12448715 ... 0.08853584 0.17974034 0.13522685]\n  [0.09254673 0.14765598 0.12494919 ... 0.09055879 0.18033925 0.13553572]\n  [0.09519468 0.14989075 0.12426616 ... 0.08718574 0.17936894 0.13508947]]\n\n [[0.09454428 0.14949998 0.12436542 ... 0.08797583 0.17958891 0.13516349]\n  [0.09346867 0.14826374 0.12482991 ... 0.08953817 0.17996782 0.1353308 ]\n  [0.09151156 0.14643516 0.12539566 ... 0.09201451 0.18072706 0.13575679]\n  ...\n  [0.09419002 0.14917739 0.12447173 ... 0.08844689 0.17971563 0.13521641]\n  [0.09261136 0.14769435 0.12494288 ... 0.09048873 0.18031363 0.13552168]\n  [0.09517317 0.14986283 0.12427727 ... 0.0872198  0.17937636 0.13509157]]]", "accuracy": 0.2, "inputs": "[[[-0.6441754 ]\n  [-0.6316425 ]\n  [-0.62136537]\n  ...\n  [-0.8751152 ]\n  [-0.86900634]\n  [-0.86335516]]\n\n [[-1.0574203 ]\n  [-1.0514047 ]\n  [-1.0463719 ]\n  ...\n  [-0.9943956 ]\n  [-0.9967297 ]\n  [-0.99922913]]\n\n [[-0.960383  ]\n  [-0.9472135 ]\n  [-0.9349204 ]\n  ...\n  [-1.1757457 ]\n  [-1.1830101 ]\n  [-1.1899081 ]]\n\n ...\n\n [[-0.9579931 ]\n  [-0.9583305 ]\n  [-0.9592496 ]\n  ...\n  [-0.91240275]\n  [-0.9057921 ]\n  [-0.899797  ]]\n\n [[-0.92588603]\n  [-0.9337288 ]\n  [-0.9419923 ]\n  ...\n  [-1.0675538 ]\n  [-1.0628523 ]\n  [-1.0588943 ]]\n\n [[-0.8702758 ]\n  [-0.85922086]\n  [-0.84914935]\n  ...\n  [-0.811603  ]\n  [-0.8145301 ]\n  [-0.8177387 ]]]"}
{"time_total_s": 14.68326449394226, "hostname": "e9379f55ba79", "time_this_iter_s": 2.5760958194732666, "experiment_id": "d32ddf96cb8546f994c7d29ed46fab9d", "timesteps_total": null, "timesteps_since_restore": 0, "training_iteration": 6, "config": {"workers": 2, "dataset": "Mallat", "num_rnn_layers": 1, "hidden_dims": 64, "learning_rate": 0.01, "epochs": 99999, "dropout": 0.3, "fold": 8, "earliness_factor": 1, "switch_epoch": 9999, "batchsize": 96}, "loss": 2.039350986480713, "pid": 7046, "timestamp": 1544558217, "confusion_matrix": "[[0. 0. 0. 2. 0. 0. 0. 0.]\n [0. 0. 0. 1. 0. 0. 0. 0.]\n [0. 0. 0. 1. 0. 0. 0. 0.]\n [0. 0. 0. 2. 0. 0. 0. 0.]\n [0. 0. 0. 0. 0. 0. 0. 0.]\n [0. 0. 0. 2. 0. 0. 0. 0.]\n [0. 0. 0. 1. 0. 0. 0. 0.]\n [0. 0. 0. 1. 0. 0. 0. 0.]]", "date": "2018-12-11_20-56-57", "targets": "[[5 5 5 ... 5 5 5]\n [3 3 3 ... 3 3 3]\n [7 7 7 ... 7 7 7]\n ...\n [0 0 0 ... 0 0 0]\n [2 2 2 ... 2 2 2]\n [6 6 6 ... 6 6 6]]", "episodes_total": null, "done": false, "iterations_since_restore": 6, "weights": "[[6.7758236e-05 6.7413996e-05 6.7319132e-05 ... 6.3796339e-05\n  6.3797117e-05 9.4080269e-01]\n [6.7817637e-05 6.7311215e-05 6.7088869e-05 ... 6.3610540e-05\n  6.3604355e-05 9.3980354e-01]\n [6.7799148e-05 6.7328037e-05 6.7146539e-05 ... 6.3411826e-05\n  6.3400228e-05 9.3973666e-01]\n ...\n [6.7798697e-05 6.7331959e-05 6.7146735e-05 ... 6.3701140e-05\n  6.3702537e-05 9.3983519e-01]\n [6.7793204e-05 6.7340625e-05 6.7164219e-05 ... 6.3610663e-05\n  6.3610925e-05 9.4063950e-01]\n [6.7784407e-05 6.7348716e-05 6.7196765e-05 ... 6.3813211e-05\n  6.3806692e-05 9.4049525e-01]]", "time_since_restore": 14.68326449394226, "node_ip": "172.17.0.2", "probas": "[[[0.10654148 0.15110774 0.11558764 ... 0.08934934 0.16454293 0.1322956 ]\n  [0.10682518 0.14867501 0.1164353  ... 0.09073784 0.16548666 0.13244879]\n  [0.10677561 0.14922535 0.11623768 ... 0.09040713 0.16526207 0.13239947]\n  ...\n  [0.10677423 0.14923905 0.1162328  ... 0.090399   0.16525653 0.13239834]\n  [0.10675544 0.14942406 0.1161672  ... 0.09029025 0.16518271 0.1323839 ]\n  [0.1067201  0.14974768 0.11605331 ... 0.09010256 0.1650552  0.13236097]]\n\n [[0.10664702 0.14917642 0.11645465 ... 0.09115331 0.16472399 0.1319405 ]\n  [0.10633557 0.14596473 0.1177851  ... 0.09400401 0.16598566 0.1323042 ]\n  [0.10647414 0.14669867 0.11747082 ... 0.09329139 0.16565894 0.13217245]\n  ...\n  [0.1064738  0.14664891 0.11748914 ... 0.09332392 0.16568561 0.13218193]\n  [0.1065093  0.1468479  0.11740284 ... 0.09312695 0.16560444 0.13215232]\n  [0.10656541 0.14736164 0.1171907  ... 0.09267399 0.16538686 0.1320804 ]]\n\n [[0.10631775 0.14955167 0.1164747  ... 0.09244596 0.16428672 0.131621  ]\n  [0.10495532 0.14674816 0.11781131 ... 0.09661589 0.16575941 0.13224126]\n  [0.10540709 0.14743242 0.11748135 ... 0.09552296 0.16532852 0.1320141 ]\n  ...\n  [0.10537356 0.14728992 0.11754091 ... 0.09565311 0.16540618 0.13204788]\n  [0.10547914 0.14740372 0.11747927 ... 0.09541001 0.1653328  0.1320077 ]\n  [0.10573662 0.14798287 0.1172117  ... 0.09463551 0.16501206 0.13186324]]\n\n ...\n\n [[0.10305889 0.15452321 0.11417646 ... 0.09646688 0.16572812 0.13061777]\n  [0.10207701 0.15391567 0.11432985 ... 0.09793185 0.1666471  0.13085294]\n  [0.10019435 0.15295047 0.11447097 ... 0.10033951 0.1683528  0.13139579]\n  ...\n  [0.10267107 0.15437077 0.11419269 ... 0.09697755 0.16607262 0.13071176]\n  [0.10105523 0.15359797 0.11429464 ... 0.0990595  0.16753131 0.13116151]\n  [0.1038607  0.15465395 0.11421707 ... 0.09548249 0.16505803 0.13045295]]\n\n [[0.10312469 0.1545435  0.11417532 ... 0.09637979 0.1656716  0.13060388]\n  [0.10205358 0.15390322 0.11433173 ... 0.09796208 0.16666889 0.13085984]\n  [0.10009544 0.152911   0.11446964 ... 0.10044742 0.16844031 0.1314281 ]\n  ...\n  [0.10274846 0.15439253 0.1141931  ... 0.09688025 0.16600662 0.13069412]\n  [0.10112567 0.1536161  0.11429867 ... 0.09898343 0.16747156 0.13114128]\n  [0.10383891 0.1546402  0.11422082 ... 0.09551733 0.1650791  0.13045739]]\n\n [[0.10318735 0.15456066 0.11417516 ... 0.09629793 0.16561805 0.13059084]\n  [0.10202968 0.15388942 0.11433427 ... 0.09799383 0.16669124 0.13086694]\n  [0.10000131 0.15287283 0.11446841 ... 0.10054965 0.16852374 0.13145927]\n  ...\n  [0.10282087 0.15441051 0.11419451 ... 0.09679057 0.16594514 0.13067773]\n  [0.10118878 0.1536301  0.11430355 ... 0.09891733 0.16741838 0.13112305]\n  [0.10381554 0.15462464 0.11422525 ... 0.09555528 0.16510169 0.13046215]]]", "accuracy": 0.2, "inputs": "[[[-0.6441754 ]\n  [-0.6316425 ]\n  [-0.62136537]\n  ...\n  [-0.8751152 ]\n  [-0.86900634]\n  [-0.86335516]]\n\n [[-1.0574203 ]\n  [-1.0514047 ]\n  [-1.0463719 ]\n  ...\n  [-0.9943956 ]\n  [-0.9967297 ]\n  [-0.99922913]]\n\n [[-0.960383  ]\n  [-0.9472135 ]\n  [-0.9349204 ]\n  ...\n  [-1.1757457 ]\n  [-1.1830101 ]\n  [-1.1899081 ]]\n\n ...\n\n [[-0.9579931 ]\n  [-0.9583305 ]\n  [-0.9592496 ]\n  ...\n  [-0.91240275]\n  [-0.9057921 ]\n  [-0.899797  ]]\n\n [[-0.92588603]\n  [-0.9337288 ]\n  [-0.9419923 ]\n  ...\n  [-1.0675538 ]\n  [-1.0628523 ]\n  [-1.0588943 ]]\n\n [[-0.8702758 ]\n  [-0.85922086]\n  [-0.84914935]\n  ...\n  [-0.811603  ]\n  [-0.8145301 ]\n  [-0.8177387 ]]]"}
{"time_total_s": 17.055407524108887, "hostname": "e9379f55ba79", "time_this_iter_s": 2.372143030166626, "experiment_id": "d32ddf96cb8546f994c7d29ed46fab9d", "timesteps_total": null, "timesteps_since_restore": 0, "training_iteration": 7, "config": {"workers": 2, "dataset": "Mallat", "num_rnn_layers": 1, "hidden_dims": 64, "learning_rate": 0.01, "epochs": 99999, "dropout": 0.3, "fold": 8, "earliness_factor": 1, "switch_epoch": 9999, "batchsize": 96}, "loss": 2.0377631187438965, "pid": 7046, "timestamp": 1544558219, "confusion_matrix": "[[0. 0. 0. 2. 0. 0. 0. 0.]\n [0. 0. 0. 1. 0. 0. 0. 0.]\n [0. 0. 0. 1. 0. 0. 0. 0.]\n [0. 0. 0. 2. 0. 0. 0. 0.]\n [0. 0. 0. 0. 0. 0. 0. 0.]\n [0. 0. 0. 2. 0. 0. 0. 0.]\n [0. 0. 0. 1. 0. 0. 0. 0.]\n [0. 0. 0. 1. 0. 0. 0. 0.]]", "date": "2018-12-11_20-56-59", "targets": "[[5 5 5 ... 5 5 5]\n [3 3 3 ... 3 3 3]\n [7 7 7 ... 7 7 7]\n ...\n [0 0 0 ... 0 0 0]\n [2 2 2 ... 2 2 2]\n [6 6 6 ... 6 6 6]]", "episodes_total": null, "done": false, "iterations_since_restore": 7, "weights": "[[6.9824477e-05 6.9498230e-05 6.9388770e-05 ... 6.5305408e-05\n  6.5306900e-05 9.3708462e-01]\n [6.9955779e-05 6.9438334e-05 6.9111280e-05 ... 6.5179309e-05\n  6.5172593e-05 9.3715286e-01]\n [6.9921160e-05 6.9448673e-05 6.9189693e-05 ... 6.4952765e-05\n  6.4939893e-05 9.3704408e-01]\n ...\n [6.9920294e-05 6.9453970e-05 6.9190486e-05 ... 6.5269931e-05\n  6.5272172e-05 9.3707496e-01]\n [6.9909358e-05 6.9461050e-05 6.9213907e-05 ... 6.5089429e-05\n  6.5090251e-05 9.3683946e-01]\n [6.9890957e-05 6.9461974e-05 6.9253911e-05 ... 6.5357846e-05\n  6.5350789e-05 9.3709850e-01]]", "time_since_restore": 17.055407524108887, "node_ip": "172.17.0.2", "probas": "[[[0.11033062 0.14986132 0.10709637 ... 0.0848184  0.15491141 0.13577312]\n  [0.11064974 0.14665265 0.10827003 ... 0.08634762 0.15676767 0.13596645]\n  [0.11059747 0.1473805  0.10799603 ... 0.08598357 0.15632465 0.13590568]\n  ...\n  [0.11059602 0.14739864 0.10798928 ... 0.08597466 0.15631384 0.13590433]\n  [0.11057551 0.14764297 0.10789835 ... 0.08585489 0.15616825 0.13588637]\n  [0.11053637 0.1480702  0.10774065 ... 0.08564824 0.15591727 0.1358577 ]]\n\n [[0.11053131 0.14734142 0.10832513 ... 0.0868513  0.155954   0.13526732]\n  [0.11013832 0.14308749 0.1102068  ... 0.09000277 0.15883307 0.13563791]\n  [0.11031532 0.14406584 0.10976045 ... 0.08921696 0.15810038 0.13549884]\n  ...\n  [0.11031353 0.14399952 0.10978579 ... 0.08925223 0.15814959 0.13551025]\n  [0.11035783 0.14426404 0.10966299 ... 0.08903445 0.15795915 0.13548025]\n  [0.11043069 0.14494593 0.1093633  ... 0.08853488 0.15747909 0.13540381]]\n\n [[0.11006584 0.14770569 0.10840732 ... 0.0883231  0.15623268 0.13483761]\n  [0.10834768 0.14385681 0.11033683 ... 0.09290394 0.16006611 0.13538463]\n  [0.10891704 0.14480592 0.10985903 ... 0.09171046 0.15901153 0.1351727 ]\n  ...\n  [0.10887478 0.14461559 0.10994189 ... 0.09185135 0.15916707 0.1352077 ]\n  [0.10900791 0.14477776 0.10985064 ... 0.09158437 0.15895809 0.13517334]\n  [0.10933243 0.1455677  0.10946796 ... 0.09073715 0.15819302 0.13503696]]\n\n ...\n\n [[0.10512608 0.15171027 0.1061243  ... 0.0929058  0.16218689 0.13451579]\n  [0.10396758 0.15075758 0.10639501 ... 0.09438161 0.16409901 0.13467784]\n  [0.10174838 0.14919165 0.10673517 ... 0.09676338 0.16751516 0.13513029]\n  ...\n  [0.10466351 0.15142077 0.10619086 ... 0.09342579 0.16289939 0.13460478]\n  [0.10275485 0.15010713 0.10648401 ... 0.09550749 0.16584206 0.1350014 ]\n  [0.10609981 0.15212299 0.10605886 ... 0.09188473 0.16076635 0.13432513]]\n\n [[0.10520492 0.1517519  0.10611565 ... 0.09281706 0.16206744 0.13450328]\n  [0.1039399  0.15073617 0.10640034 ... 0.09441215 0.16414247 0.13468459]\n  [0.10163199 0.1491216  0.10674448 ... 0.0968685  0.1676844  0.13516164]\n  ...\n  [0.10475608 0.15146685 0.10618284 ... 0.09332734 0.16276209 0.1345884 ]\n  [0.10283826 0.15014549 0.10648116 ... 0.09543272 0.16572407 0.13498156]\n  [0.10607378 0.15209953 0.10606632 ... 0.09192085 0.16081132 0.13432887]]\n\n [[0.10528023 0.15178955 0.1061083  ... 0.09273354 0.16195421 0.13449116]\n  [0.10391167 0.1507133  0.10640628 ... 0.09444419 0.16418722 0.1346912 ]\n  [0.10152124 0.14905423 0.10675342 ... 0.09696797 0.16784534 0.13519196]\n  ...\n  [0.10484288 0.15150782 0.10617623 ... 0.0932364  0.16263421 0.1345726 ]\n  [0.10291306 0.1501778  0.1064797  ... 0.09536767 0.16561942 0.13496296]\n  [0.10604592 0.15207385 0.10607464 ... 0.09196015 0.1608597  0.1343327 ]]]", "accuracy": 0.2, "inputs": "[[[-0.6441754 ]\n  [-0.6316425 ]\n  [-0.62136537]\n  ...\n  [-0.8751152 ]\n  [-0.86900634]\n  [-0.86335516]]\n\n [[-1.0574203 ]\n  [-1.0514047 ]\n  [-1.0463719 ]\n  ...\n  [-0.9943956 ]\n  [-0.9967297 ]\n  [-0.99922913]]\n\n [[-0.960383  ]\n  [-0.9472135 ]\n  [-0.9349204 ]\n  ...\n  [-1.1757457 ]\n  [-1.1830101 ]\n  [-1.1899081 ]]\n\n ...\n\n [[-0.9579931 ]\n  [-0.9583305 ]\n  [-0.9592496 ]\n  ...\n  [-0.91240275]\n  [-0.9057921 ]\n  [-0.899797  ]]\n\n [[-0.92588603]\n  [-0.9337288 ]\n  [-0.9419923 ]\n  ...\n  [-1.0675538 ]\n  [-1.0628523 ]\n  [-1.0588943 ]]\n\n [[-0.8702758 ]\n  [-0.85922086]\n  [-0.84914935]\n  ...\n  [-0.811603  ]\n  [-0.8145301 ]\n  [-0.8177387 ]]]"}
{"time_total_s": 19.45023226737976, "hostname": "e9379f55ba79", "time_this_iter_s": 2.394824743270874, "experiment_id": "d32ddf96cb8546f994c7d29ed46fab9d", "timesteps_total": null, "timesteps_since_restore": 0, "training_iteration": 8, "config": {"workers": 2, "dataset": "Mallat", "num_rnn_layers": 1, "hidden_dims": 64, "learning_rate": 0.01, "epochs": 99999, "dropout": 0.3, "fold": 8, "earliness_factor": 1, "switch_epoch": 9999, "batchsize": 96}, "loss": 2.054220199584961, "pid": 7046, "timestamp": 1544558221, "confusion_matrix": "[[0. 0. 0. 2. 0. 0. 0. 0.]\n [0. 0. 0. 1. 0. 0. 0. 0.]\n [0. 0. 0. 1. 0. 0. 0. 0.]\n [0. 0. 0. 2. 0. 0. 0. 0.]\n [0. 0. 0. 0. 0. 0. 0. 0.]\n [0. 0. 0. 2. 0. 0. 0. 0.]\n [0. 0. 0. 1. 0. 0. 0. 0.]\n [0. 0. 0. 1. 0. 0. 0. 0.]]", "date": "2018-12-11_20-57-01", "targets": "[[5 5 5 ... 5 5 5]\n [3 3 3 ... 3 3 3]\n [7 7 7 ... 7 7 7]\n ...\n [0 0 0 ... 0 0 0]\n [2 2 2 ... 2 2 2]\n [6 6 6 ... 6 6 6]]", "episodes_total": null, "done": false, "iterations_since_restore": 8, "weights": "[[7.0492635e-05 7.0266877e-05 7.0260787e-05 ... 6.6282533e-05\n  6.6281958e-05 9.3740278e-01]\n [7.0759343e-05 7.0396163e-05 7.0162947e-05 ... 6.6147848e-05\n  6.6141729e-05 9.3689346e-01]\n [7.0692171e-05 7.0362068e-05 7.0205118e-05 ... 6.5978522e-05\n  6.5967892e-05 9.3694222e-01]\n ...\n [7.0690556e-05 7.0370661e-05 7.0213486e-05 ... 6.6223773e-05\n  6.6223758e-05 9.3689150e-01]\n [7.0668917e-05 7.0365888e-05 7.0229820e-05 ... 6.6133754e-05\n  6.6132809e-05 9.3726933e-01]\n [7.0632261e-05 7.0335707e-05 7.0235656e-05 ... 6.6301189e-05\n  6.6294931e-05 9.3725002e-01]]", "time_since_restore": 19.45023226737976, "node_ip": "172.17.0.2", "probas": "[[[0.10464292 0.15271126 0.10783947 ... 0.07798167 0.15761437 0.14101717]\n  [0.10476597 0.14876492 0.10961413 ... 0.07951373 0.15964195 0.14111614]\n  [0.10476737 0.14966267 0.10919738 ... 0.07914715 0.15915434 0.14107226]\n  ...\n  [0.10476717 0.149685   0.1091871  ... 0.07913818 0.15914242 0.14107133]\n  [0.10476334 0.14998598 0.10904916 ... 0.07901782 0.15898265 0.14105967]\n  [0.10475191 0.15051185 0.10881029 ... 0.07881046 0.15870784 0.14104278]]\n\n [[0.10477643 0.15014744 0.1097681  ... 0.07988974 0.15818036 0.14013404]\n  [0.10388655 0.14516573 0.11277075 ... 0.083076   0.16109087 0.14035553]\n  [0.10420802 0.14632264 0.1120481  ... 0.08227182 0.16033325 0.14023569]\n  ...\n  [0.10419839 0.14623873 0.11208732 ... 0.08230847 0.16038993 0.140248  ]\n  [0.10427963 0.1465463  0.11188854 ... 0.08208703 0.16019872 0.14022641]\n  [0.10443798 0.14735438 0.11140998 ... 0.08157894 0.15970154 0.14016694]]\n\n [[0.1042397  0.15121904 0.11019552 ... 0.08107933 0.15782884 0.1393862 ]\n  [0.10166725 0.14690165 0.11358573 ... 0.08576386 0.16165261 0.1397091 ]\n  [0.10248809 0.14800549 0.11273144 ... 0.08451841 0.1605588  0.13953228]\n  ...\n  [0.102415   0.14777009 0.11286459 ... 0.08466784 0.16073152 0.13956784]\n  [0.10260121 0.14794469 0.11269264 ... 0.08439327 0.16052626 0.13954641]\n  [0.10309496 0.14886387 0.11203352 ... 0.08351561 0.1597333  0.13943747]]\n\n ...\n\n [[0.09899078 0.1559205  0.10896875 ... 0.08518372 0.16400957 0.13765363]\n  [0.09749006 0.15468085 0.10967609 ... 0.08677319 0.16620785 0.1376374 ]\n  [0.09468423 0.15249844 0.11072247 ... 0.08936014 0.17021805 0.13780893]\n  ...\n  [0.09841257 0.15551305 0.10919538 ... 0.08574271 0.16484033 0.1376735 ]\n  [0.09600709 0.1536787  0.11012083 ... 0.08799259 0.16828763 0.13781455]\n  [0.10017355 0.15655993 0.10858498 ... 0.08409052 0.16234605 0.13761742]]\n\n [[0.09908915 0.15597951 0.10893346 ... 0.08508868 0.16387105 0.1376535 ]\n  [0.09745528 0.15465078 0.10969105 ... 0.0868063  0.16625898 0.13764048]\n  [0.0945409  0.1523924  0.11076424 ... 0.08947463 0.17042072 0.13782753]\n  ...\n  [0.09852731 0.15558062 0.10915763 ... 0.08563688 0.16467987 0.13767076]\n  [0.09610905 0.15373985 0.11009521 ... 0.08791156 0.16814674 0.13780467]\n  [0.1001401  0.15652971 0.10860366 ... 0.08412913 0.16239743 0.13761646]]\n\n [[0.09918263 0.15603393 0.10890093 ... 0.08499922 0.16373956 0.13765329]\n  [0.09741952 0.15461943 0.109707   ... 0.08684103 0.16631146 0.13764337]\n  [0.09440456 0.15229063 0.11080397 ... 0.08958295 0.17061356 0.13784586]\n  ...\n  [0.09863437 0.15564209 0.10912345 ... 0.08553914 0.16453014 0.13766779]\n  [0.09619983 0.15379302 0.11007356 ... 0.08784102 0.16802132 0.13779491]\n  [0.10010403 0.15649702 0.10862405 ... 0.08417109 0.16245249 0.13761514]]]", "accuracy": 0.2, "inputs": "[[[-0.6441754 ]\n  [-0.6316425 ]\n  [-0.62136537]\n  ...\n  [-0.8751152 ]\n  [-0.86900634]\n  [-0.86335516]]\n\n [[-1.0574203 ]\n  [-1.0514047 ]\n  [-1.0463719 ]\n  ...\n  [-0.9943956 ]\n  [-0.9967297 ]\n  [-0.99922913]]\n\n [[-0.960383  ]\n  [-0.9472135 ]\n  [-0.9349204 ]\n  ...\n  [-1.1757457 ]\n  [-1.1830101 ]\n  [-1.1899081 ]]\n\n ...\n\n [[-0.9579931 ]\n  [-0.9583305 ]\n  [-0.9592496 ]\n  ...\n  [-0.91240275]\n  [-0.9057921 ]\n  [-0.899797  ]]\n\n [[-0.92588603]\n  [-0.9337288 ]\n  [-0.9419923 ]\n  ...\n  [-1.0675538 ]\n  [-1.0628523 ]\n  [-1.0588943 ]]\n\n [[-0.8702758 ]\n  [-0.85922086]\n  [-0.84914935]\n  ...\n  [-0.811603  ]\n  [-0.8145301 ]\n  [-0.8177387 ]]]"}
{"time_total_s": 21.660296201705933, "hostname": "e9379f55ba79", "time_this_iter_s": 2.210063934326172, "experiment_id": "d32ddf96cb8546f994c7d29ed46fab9d", "timesteps_total": null, "timesteps_since_restore": 0, "training_iteration": 9, "config": {"workers": 2, "dataset": "Mallat", "num_rnn_layers": 1, "hidden_dims": 64, "learning_rate": 0.01, "epochs": 99999, "dropout": 0.3, "fold": 8, "earliness_factor": 1, "switch_epoch": 9999, "batchsize": 96}, "loss": 2.0630617141723633, "pid": 7046, "timestamp": 1544558224, "confusion_matrix": "[[0. 0. 0. 2. 0. 0. 0. 0.]\n [0. 0. 0. 1. 0. 0. 0. 0.]\n [0. 0. 0. 1. 0. 0. 0. 0.]\n [0. 0. 0. 2. 0. 0. 0. 0.]\n [0. 0. 0. 0. 0. 0. 0. 0.]\n [0. 0. 0. 2. 0. 0. 0. 0.]\n [0. 0. 0. 1. 0. 0. 0. 0.]\n [0. 0. 0. 1. 0. 0. 0. 0.]]", "date": "2018-12-11_20-57-04", "targets": "[[5 5 5 ... 5 5 5]\n [3 3 3 ... 3 3 3]\n [7 7 7 ... 7 7 7]\n ...\n [0 0 0 ... 0 0 0]\n [2 2 2 ... 2 2 2]\n [6 6 6 ... 6 6 6]]", "episodes_total": null, "done": false, "iterations_since_restore": 9, "weights": "[[7.1289054e-05 7.1082439e-05 7.1001639e-05 ... 6.6441673e-05\n  6.6444321e-05 9.3745935e-01]\n [7.1660521e-05 7.1258386e-05 7.0766844e-05 ... 6.6249057e-05\n  6.6242224e-05 9.3680596e-01]\n [7.1569142e-05 7.1218790e-05 7.0856389e-05 ... 6.6018038e-05\n  6.6005086e-05 9.3699133e-01]\n ...\n [7.1566887e-05 7.1229384e-05 7.0865317e-05 ... 6.6354209e-05\n  6.6357607e-05 9.3676829e-01]\n [7.1537208e-05 7.1223549e-05 7.0895323e-05 ... 6.6220244e-05\n  6.6221437e-05 9.3735635e-01]\n [7.1486473e-05 7.1185117e-05 7.0922375e-05 ... 6.6498498e-05\n  6.6491120e-05 9.3732548e-01]]", "time_since_restore": 21.660296201705933, "node_ip": "172.17.0.2", "probas": "[[[0.10131813 0.15489611 0.10808732 ... 0.07423073 0.1591206  0.14588362]\n  [0.1010977  0.14985088 0.10990235 ... 0.07668306 0.16187876 0.14605224]\n  [0.10118955 0.15100877 0.10947558 ... 0.07609819 0.16121322 0.14599055]\n  ...\n  [0.10119151 0.1510375  0.10946506 ... 0.07608386 0.16119696 0.14598922]\n  [0.10121623 0.15142424 0.10932388 ... 0.07589156 0.16097923 0.14597188]\n  [0.10125273 0.15209834 0.10907946 ... 0.07555996 0.160605   0.14594536]]\n\n [[0.10123888 0.15175217 0.10991424 ... 0.07759392 0.16008902 0.14519699]\n  [0.09960369 0.14505544 0.11293346 ... 0.08284134 0.16421618 0.14561039]\n  [0.10013388 0.14665116 0.11220446 ... 0.0815238  0.1631429  0.14544567]\n  ...\n  [0.10011274 0.14653914 0.11224446 ... 0.0815819  0.16321921 0.14545952]\n  [0.1002479  0.14696124 0.11204447 ... 0.0812171  0.16294554 0.14542474]\n  [0.10053244 0.14805411 0.11156197 ... 0.08038456 0.16224557 0.14533596]]\n\n [[0.10059348 0.15275308 0.11017934 ... 0.08001533 0.15999174 0.14462972]\n  [0.09686935 0.14604545 0.11361203 ... 0.08790495 0.16562878 0.14506467]\n  [0.09802713 0.14782166 0.11274082 ... 0.08582196 0.16403559 0.14487892]\n  ...\n  [0.09791087 0.14749141 0.11287573 ... 0.08606412 0.16427411 0.14491723]\n  [0.09816682 0.1478006  0.11270032 ... 0.08559836 0.16396427 0.14489265]\n  [0.09888974 0.14919662 0.11203098 ... 0.08413564 0.1628185  0.14476681]]\n\n ...\n\n [[0.09424559 0.15250407 0.11060873 ... 0.08787969 0.16988628 0.14180875]\n  [0.09226906 0.15010564 0.11143038 ... 0.09052921 0.17299367 0.14157167]\n  [0.08860362 0.1458455  0.11270116 ... 0.09482615 0.17863308 0.1413144 ]\n  ...\n  [0.09348945 0.15163562 0.11091233 ... 0.0888067  0.17106755 0.14174365]\n  [0.09034374 0.14796636 0.11208387 ... 0.09253693 0.17593229 0.1415291 ]\n  [0.09578082 0.1541175  0.11001051 ... 0.08606537 0.16749546 0.14195116]]\n\n [[0.09437324 0.1526399  0.11056079 ... 0.08772144 0.1696885  0.14182356]\n  [0.09222309 0.15004759 0.11144978 ... 0.09058391 0.17306589 0.14156985]\n  [0.08841787 0.14563408 0.11275803 ... 0.09501491 0.17891727 0.1413108 ]\n  ...\n  [0.09363793 0.15179165 0.11085977 ... 0.08863089 0.17083903 0.14175853]\n  [0.0904747  0.14810242 0.11204591 ... 0.0924032  0.1757335  0.14153537]\n  [0.09573616 0.1540582  0.11003365 ... 0.08612961 0.1675688  0.14194553]]\n\n [[0.0944943  0.15276791 0.11051539 ... 0.08757258 0.16950047 0.14183764]\n  [0.09217572 0.14998785 0.11146977 ... 0.09064135 0.1731398  0.14156775]\n  [0.0882411  0.1454323  0.11281203 ... 0.09519356 0.17918757 0.14130811]\n  ...\n  [0.09377626 0.15193652 0.11081067 ... 0.08846869 0.1706255  0.14177215]\n  [0.09059118 0.14822313 0.11201215 ... 0.09228708 0.17555644 0.1415401 ]\n  [0.09568804 0.15399477 0.11005842 ... 0.08619957 0.1676473  0.14193936]]]", "accuracy": 0.2, "inputs": "[[[-0.6441754 ]\n  [-0.6316425 ]\n  [-0.62136537]\n  ...\n  [-0.8751152 ]\n  [-0.86900634]\n  [-0.86335516]]\n\n [[-1.0574203 ]\n  [-1.0514047 ]\n  [-1.0463719 ]\n  ...\n  [-0.9943956 ]\n  [-0.9967297 ]\n  [-0.99922913]]\n\n [[-0.960383  ]\n  [-0.9472135 ]\n  [-0.9349204 ]\n  ...\n  [-1.1757457 ]\n  [-1.1830101 ]\n  [-1.1899081 ]]\n\n ...\n\n [[-0.9579931 ]\n  [-0.9583305 ]\n  [-0.9592496 ]\n  ...\n  [-0.91240275]\n  [-0.9057921 ]\n  [-0.899797  ]]\n\n [[-0.92588603]\n  [-0.9337288 ]\n  [-0.9419923 ]\n  ...\n  [-1.0675538 ]\n  [-1.0628523 ]\n  [-1.0588943 ]]\n\n [[-0.8702758 ]\n  [-0.85922086]\n  [-0.84914935]\n  ...\n  [-0.811603  ]\n  [-0.8145301 ]\n  [-0.8177387 ]]]"}
{"time_total_s": 23.66593599319458, "hostname": "e9379f55ba79", "time_this_iter_s": 2.0056397914886475, "experiment_id": "d32ddf96cb8546f994c7d29ed46fab9d", "timesteps_total": null, "timesteps_since_restore": 0, "training_iteration": 10, "config": {"workers": 2, "dataset": "Mallat", "num_rnn_layers": 1, "hidden_dims": 64, "learning_rate": 0.01, "epochs": 99999, "dropout": 0.3, "fold": 8, "earliness_factor": 1, "switch_epoch": 9999, "batchsize": 96}, "loss": 2.105154514312744, "pid": 7046, "timestamp": 1544558226, "confusion_matrix": "[[0. 0. 0. 2. 0. 0. 0. 0.]\n [0. 0. 0. 1. 0. 0. 0. 0.]\n [0. 0. 0. 1. 0. 0. 0. 0.]\n [0. 0. 0. 2. 0. 0. 0. 0.]\n [0. 0. 0. 0. 0. 0. 0. 0.]\n [0. 0. 0. 2. 0. 0. 0. 0.]\n [0. 0. 0. 1. 0. 0. 0. 0.]\n [0. 0. 0. 0. 0. 0. 1. 0.]]", "date": "2018-12-11_20-57-06", "targets": "[[5 5 5 ... 5 5 5]\n [3 3 3 ... 3 3 3]\n [7 7 7 ... 7 7 7]\n ...\n [0 0 0 ... 0 0 0]\n [2 2 2 ... 2 2 2]\n [6 6 6 ... 6 6 6]]", "episodes_total": null, "done": true, "iterations_since_restore": 10, "weights": "[[7.2467701e-05 7.2348317e-05 7.2305491e-05 ... 6.7957961e-05\n  6.7955050e-05 9.4027120e-01]\n [7.2898743e-05 7.2549679e-05 7.1983479e-05 ... 6.7811219e-05\n  6.7806453e-05 9.3932611e-01]\n [7.2795039e-05 7.2512339e-05 7.2109840e-05 ... 6.7727211e-05\n  6.7724461e-05 9.3940604e-01]\n ...\n [7.2792463e-05 7.2523333e-05 7.2117051e-05 ... 6.7808141e-05\n  6.7804787e-05 9.3825096e-01]\n [7.2758456e-05 7.2517454e-05 7.2155854e-05 ... 6.7800327e-05\n  6.7794259e-05 9.3858236e-01]\n [7.2699921e-05 7.2476396e-05 7.2200462e-05 ... 6.7879468e-05\n  6.7873654e-05 9.3930608e-01]]", "time_since_restore": 23.66593599319458, "node_ip": "172.17.0.2", "probas": "[[[0.10134339 0.15790832 0.10962244 ... 0.06883685 0.1537359  0.14548399]\n  [0.10063971 0.15229891 0.11158384 ... 0.07157238 0.1580107  0.14442582]\n  [0.10085721 0.15359576 0.11112526 ... 0.07092047 0.15697682 0.14464842]\n  ...\n  [0.10086214 0.15362781 0.11111392 ... 0.07090446 0.15695156 0.14465408]\n  [0.10092675 0.1540596  0.11096182 ... 0.07069007 0.15661365 0.1447313 ]\n  [0.10103037 0.1548107  0.11069808 ... 0.07032025 0.15603319 0.14486918]]\n\n [[0.10102972 0.1545681  0.11184848 ... 0.07277809 0.1563407  0.14282884]\n  [0.09843568 0.14686199 0.11521465 ... 0.0788152  0.16343586 0.14084603]\n  [0.09923362 0.14873508 0.11441094 ... 0.07729748 0.161605   0.14125113]\n  ...\n  [0.09919662 0.1486067  0.11445154 ... 0.07736181 0.16172083 0.1412403 ]\n  [0.09940037 0.14910005 0.11422771 ... 0.07694012 0.16124281 0.14136705]\n  [0.0998484  0.1503635  0.11369614 ... 0.07598513 0.16006158 0.14164995]]\n\n [[0.10019256 0.15530859 0.11272709 ... 0.07595347 0.1578033  0.14061674]\n  [0.09496518 0.1467326  0.11685349 ... 0.08542421 0.16788682 0.13764489]\n  [0.09656171 0.14905946 0.11583231 ... 0.08291993 0.16511476 0.13829906]\n  ...\n  [0.09638906 0.14866805 0.11597185 ... 0.08319733 0.16549693 0.1382419 ]\n  [0.09673582 0.1490965  0.11575098 ... 0.08262859 0.16492812 0.13841197]\n  [0.09775767 0.15085313 0.11497847 ... 0.08088895 0.16294903 0.13889508]]\n\n ...\n\n [[0.0911521  0.1475089  0.11752696 ... 0.08867359 0.17488956 0.13402872]\n  [0.08848854 0.14396513 0.11862607 ... 0.09200612 0.17954122 0.13276523]\n  [0.08360282 0.13762961 0.12029458 ... 0.09740853 0.18774074 0.13094407]\n  ...\n  [0.0901216  0.14614971 0.11797401 ... 0.08986951 0.17662036 0.13363126]\n  [0.08588971 0.14060186 0.1195888  ... 0.0946002  0.18369386 0.1320713 ]\n  [0.09326864 0.15023375 0.11654709 ... 0.08625884 0.1713959  0.13478777]]\n\n [[0.09132527 0.14772876 0.11745286 ... 0.08846784 0.17459741 0.13410181]\n  [0.08842584 0.14387874 0.11865221 ... 0.09207541 0.17964569 0.1327446 ]\n  [0.08335622 0.13731012 0.12037153 ... 0.09764726 0.18814026 0.13087726]\n  ...\n  [0.09032222 0.14640261 0.1178927  ... 0.08964077 0.17628664 0.1337095 ]\n  [0.08606393 0.14081895 0.11953133 ... 0.09442721 0.1834136  0.13212278]\n  [0.09320671 0.15014498 0.11657961 ... 0.08634083 0.17150667 0.13475773]]\n\n [[0.09148974 0.147938   0.11738151 ... 0.08827338 0.17432019 0.13417017]\n  [0.08836135 0.14379068 0.11867861 ... 0.09214782 0.17975335 0.13272232]\n  [0.08312166 0.13700607 0.1204441  ... 0.09787283 0.1885198  0.13081492]\n  ...\n  [0.09050953 0.14663959 0.11781542 ... 0.08942864 0.17597553 0.13378078]\n  [0.08621915 0.14101335 0.11947902 ... 0.094276   0.18316539 0.1321657 ]\n  [0.09314007 0.15005061 0.11661402 ... 0.08642974 0.17162578 0.13472457]]]", "accuracy": 0.2, "inputs": "[[[-0.6441754 ]\n  [-0.6316425 ]\n  [-0.62136537]\n  ...\n  [-0.8751152 ]\n  [-0.86900634]\n  [-0.86335516]]\n\n [[-1.0574203 ]\n  [-1.0514047 ]\n  [-1.0463719 ]\n  ...\n  [-0.9943956 ]\n  [-0.9967297 ]\n  [-0.99922913]]\n\n [[-0.960383  ]\n  [-0.9472135 ]\n  [-0.9349204 ]\n  ...\n  [-1.1757457 ]\n  [-1.1830101 ]\n  [-1.1899081 ]]\n\n ...\n\n [[-0.9579931 ]\n  [-0.9583305 ]\n  [-0.9592496 ]\n  ...\n  [-0.91240275]\n  [-0.9057921 ]\n  [-0.899797  ]]\n\n [[-0.92588603]\n  [-0.9337288 ]\n  [-0.9419923 ]\n  ...\n  [-1.0675538 ]\n  [-1.0628523 ]\n  [-1.0588943 ]]\n\n [[-0.8702758 ]\n  [-0.85922086]\n  [-0.84914935]\n  ...\n  [-0.811603  ]\n  [-0.8145301 ]\n  [-0.8177387 ]]]"}

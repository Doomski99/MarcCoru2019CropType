{"time_total_s": 2.4759433269500732, "pid": 7043, "time_this_iter_s": 2.4759433269500732, "experiment_id": "8f8a7e61c7ec410bb3790f174773713a", "timesteps_total": null, "timesteps_since_restore": 0, "training_iteration": 1, "config": {"workers": 2, "learning_rate": 0.01, "num_rnn_layers": 1, "hidden_dims": 64, "fold": 7, "dropout": 0.3, "epochs": 99999, "earliness_factor": 1, "switch_epoch": 9999, "batchsize": 96, "dataset": "Mallat"}, "loss": 2.0843329429626465, "hostname": "e9379f55ba79", "timestamp": 1544558204, "confusion_matrix": "[[0. 0. 0. 1. 0. 0. 0. 0.]\n [0. 0. 0. 2. 0. 0. 0. 0.]\n [0. 0. 0. 0. 0. 0. 0. 0.]\n [0. 0. 0. 2. 0. 0. 0. 0.]\n [0. 0. 0. 1. 0. 0. 0. 0.]\n [0. 0. 0. 1. 0. 0. 0. 0.]\n [0. 0. 0. 1. 0. 0. 0. 0.]\n [0. 0. 0. 0. 0. 0. 0. 0.]]", "date": "2018-12-11_20-56-44", "targets": "[[6 6 6 ... 6 6 6]\n [5 5 5 ... 5 5 5]\n [1 1 1 ... 1 1 1]\n ...\n [0 0 0 ... 0 0 0]\n [3 3 3 ... 3 3 3]\n [4 4 4 ... 4 4 4]]", "weights": "[[4.4979133e-05 4.4976427e-05 4.4989887e-05 ... 4.3008393e-05\n  4.3006501e-05 9.5485640e-01]\n [4.4986642e-05 4.4981785e-05 4.4990018e-05 ... 4.3018423e-05\n  4.3016033e-05 9.5485598e-01]\n [4.4988057e-05 4.4982306e-05 4.4989672e-05 ... 4.3027576e-05\n  4.3025349e-05 9.5487058e-01]\n ...\n [4.4977678e-05 4.4975699e-05 4.4990276e-05 ... 4.3041135e-05\n  4.3041044e-05 9.5487094e-01]\n [4.4976179e-05 4.4974626e-05 4.4990487e-05 ... 4.3023461e-05\n  4.3022137e-05 9.5486575e-01]\n [4.4987974e-05 4.4981745e-05 4.4989116e-05 ... 4.3016316e-05\n  4.3014006e-05 9.5485646e-01]]", "done": false, "iterations_since_restore": 1, "episodes_total": null, "time_since_restore": 2.4759433269500732, "node_ip": "172.17.0.2", "probas": "[[[0.10452289 0.12448729 0.12738022 ... 0.11656594 0.147213   0.13793144]\n  [0.10448506 0.12455432 0.12745474 ... 0.11656296 0.14714836 0.13796757]\n  [0.10447807 0.12456671 0.12746835 ... 0.11656238 0.14713638 0.13797443]\n  ...\n  [0.10453022 0.12447426 0.12736557 ... 0.11656652 0.14722553 0.13792464]\n  [0.1045379  0.12446064 0.12735018 ... 0.11656707 0.14723864 0.13791756]\n  [0.10447846 0.12456594 0.12746753 ... 0.1165624  0.14713709 0.13797401]]\n\n [[0.10462773 0.1245235  0.12706076 ... 0.11629774 0.14763968 0.13787381]\n  [0.10457149 0.12459627 0.1271814  ... 0.11632185 0.14752923 0.13791747]\n  [0.10456514 0.12460282 0.1271962  ... 0.11632665 0.1475142  0.13792253]\n  ...\n  [0.10463681 0.12451255 0.12704058 ... 0.11629298 0.14765829 0.13786712]\n  [0.10464938 0.12449586 0.12701376 ... 0.11628821 0.14768182 0.13785794]\n  [0.1045692  0.12459621 0.12718864 ... 0.11632662 0.14752027 0.13791919]]\n\n [[0.10463472 0.12480403 0.12688263 ... 0.1159843  0.14792329 0.13793609]\n  [0.10456858 0.12485471 0.12703532 ... 0.11604179 0.14777988 0.13797846]\n  [0.10456566 0.12485123 0.12704591 ... 0.11605065 0.14776704 0.13797949]\n  ...\n  [0.10464329 0.1248     0.12686098 ... 0.11597418 0.14794417 0.13793127]\n  [0.10465949 0.12478585 0.12682466 ... 0.1159622  0.14797616 0.13792138]\n  [0.10457481 0.12483884 0.12702836 ... 0.11604836 0.14778152 0.13797246]]\n\n ...\n\n [[0.10426382 0.1257988  0.12683904 ... 0.11548219 0.14834395 0.13837288]\n  [0.10427272 0.12586151 0.12674014 ... 0.11539477 0.14847757 0.13837567]\n  [0.10428923 0.1258931  0.12665729 ... 0.11533278 0.14857665 0.13836938]\n  ...\n  [0.10433289 0.12590633 0.12652217 ... 0.11525322 0.14871202 0.13834561]\n  [0.10429589 0.12586145 0.12667713 ... 0.11536066 0.1485382  0.13836142]\n  [0.10427035 0.1258495  0.12676013 ... 0.11541214 0.14845161 0.13837549]]\n\n [[0.10426429 0.12579823 0.1268382  ... 0.11548205 0.14834471 0.13837248]\n  [0.10427247 0.12585856 0.12674405 ... 0.11539852 0.14847232 0.13837543]\n  [0.1042892  0.12589145 0.12665907 ... 0.11533465 0.14857417 0.13836914]\n  ...\n  [0.10433494 0.12591232 0.12650907 ... 0.11524295 0.14872812 0.13834512]\n  [0.10429698 0.12586345 0.12667142 ... 0.11535651 0.14854507 0.13836099]\n  [0.1042707  0.12584633 0.12676272 ... 0.11541533 0.14844754 0.13837482]]\n\n [[0.10426494 0.12579763 0.12683691 ... 0.11548166 0.14834589 0.13837194]\n  [0.10427247 0.1258555  0.12674733 ... 0.11540201 0.14846759 0.13837498]\n  [0.10428935 0.12588975 0.12666045 ... 0.11533636 0.14857204 0.13836882]\n  ...\n  [0.10433704 0.12591812 0.1264961  ... 0.11523287 0.14874406 0.1383446 ]\n  [0.10429825 0.12586537 0.12666537 ... 0.11535224 0.14855222 0.13836043]\n  [0.10427132 0.12584314 0.12676443 ... 0.115418   0.14844431 0.13837396]]]", "accuracy": 0.25, "inputs": "[[[-0.99560374]\n  [-0.9983266 ]\n  [-1.0014445 ]\n  ...\n  [-0.8010217 ]\n  [-0.8020213 ]\n  [-0.8034348 ]]\n\n [[-0.884163  ]\n  [-0.8722339 ]\n  [-0.8617986 ]\n  ...\n  [-0.86358935]\n  [-0.8614071 ]\n  [-0.85974586]]\n\n [[-0.8636094 ]\n  [-0.8601534 ]\n  [-0.85754985]\n  ...\n  [-0.9232365 ]\n  [-0.9223625 ]\n  [-0.9218354 ]]\n\n ...\n\n [[-1.017276  ]\n  [-1.0176198 ]\n  [-1.0185472 ]\n  ...\n  [-1.0338676 ]\n  [-1.0427345 ]\n  [-1.051585  ]]\n\n [[-1.039985  ]\n  [-1.0463375 ]\n  [-1.0530899 ]\n  ...\n  [-0.91811097]\n  [-0.9222992 ]\n  [-0.9268466 ]]\n\n [[-0.86484635]\n  [-0.87112236]\n  [-0.8790098 ]\n  ...\n  [-0.850916  ]\n  [-0.8499488 ]\n  [-0.8496884 ]]]"}
{"time_total_s": 4.937323093414307, "pid": 7043, "time_this_iter_s": 2.4613797664642334, "experiment_id": "8f8a7e61c7ec410bb3790f174773713a", "timesteps_total": null, "timesteps_since_restore": 0, "training_iteration": 2, "config": {"workers": 2, "learning_rate": 0.01, "num_rnn_layers": 1, "hidden_dims": 64, "fold": 7, "dropout": 0.3, "epochs": 99999, "earliness_factor": 1, "switch_epoch": 9999, "batchsize": 96, "dataset": "Mallat"}, "loss": 2.093489408493042, "hostname": "e9379f55ba79", "timestamp": 1544558207, "confusion_matrix": "[[0. 0. 0. 1. 0. 0. 0. 0.]\n [0. 0. 0. 2. 0. 0. 0. 0.]\n [0. 0. 0. 0. 0. 0. 0. 0.]\n [0. 0. 0. 2. 0. 0. 0. 0.]\n [0. 0. 0. 1. 0. 0. 0. 0.]\n [0. 0. 0. 1. 0. 0. 0. 0.]\n [0. 0. 0. 1. 0. 0. 0. 0.]\n [0. 0. 0. 0. 0. 0. 0. 0.]]", "date": "2018-12-11_20-56-47", "targets": "[[6 6 6 ... 6 6 6]\n [5 5 5 ... 5 5 5]\n [1 1 1 ... 1 1 1]\n ...\n [0 0 0 ... 0 0 0]\n [3 3 3 ... 3 3 3]\n [4 4 4 ... 4 4 4]]", "weights": "[[4.4185526e-05 4.4364831e-05 4.4612658e-05 ... 4.3494540e-05\n  4.3492888e-05 9.5564044e-01]\n [4.4184682e-05 4.4339457e-05 4.4550085e-05 ... 4.3650049e-05\n  4.3641608e-05 9.5564443e-01]\n [4.4184559e-05 4.4335266e-05 4.4542267e-05 ... 4.3761898e-05\n  4.3756558e-05 9.5567286e-01]\n ...\n [4.4185694e-05 4.4369739e-05 4.4623466e-05 ... 4.3898268e-05\n  4.3917105e-05 9.5567405e-01]\n [4.4185908e-05 4.4375196e-05 4.4637767e-05 ... 4.3701901e-05\n  4.3707652e-05 9.5566046e-01]\n [4.4184559e-05 4.4335819e-05 4.4545915e-05 ... 4.3619606e-05\n  4.3612039e-05 9.5564014e-01]]", "done": false, "iterations_since_restore": 2, "episodes_total": null, "time_since_restore": 4.937323093414307, "node_ip": "172.17.0.2", "probas": "[[[0.0997954  0.12648442 0.12456635 ... 0.10043668 0.16249998 0.1432774 ]\n  [0.09977847 0.1265757  0.12466779 ... 0.10039931 0.16235735 0.14331849]\n  [0.09977535 0.12659244 0.12468633 ... 0.10039239 0.16233091 0.1433265 ]\n  ...\n  [0.09979871 0.12646662 0.12454649 ... 0.10044394 0.1625276  0.1432699 ]\n  [0.09980218 0.12644789 0.12452561 ... 0.10045156 0.1625565  0.14326218]\n  [0.09977557 0.12659144 0.12468523 ... 0.10039283 0.16233253 0.14332604]]\n\n [[0.09965388 0.12638864 0.12452784 ... 0.10047608 0.16302082 0.14334205]\n  [0.09964583 0.12651628 0.12464252 ... 0.10042256 0.16282004 0.1433677 ]\n  [0.09964664 0.12652948 0.124654   ... 0.10041686 0.16279525 0.14337014]\n  ...\n  [0.09965453 0.12636796 0.12451002 ... 0.1004848  0.16305342 0.14333917]\n  [0.09965692 0.12633842 0.12448394 ... 0.10049704 0.16309682 0.14333464]\n  [0.09964854 0.12651964 0.1246444  ... 0.10042085 0.16280843 0.14336704]]\n\n [[0.09943317 0.12652066 0.12480985 ... 0.10050689 0.16307977 0.14359865]\n  [0.09944412 0.12666981 0.12489699 ... 0.10043117 0.16286619 0.14359248]\n  [0.09944953 0.12667383 0.12489504 ... 0.10042727 0.16285394 0.14358774]\n  ...\n  [0.09942966 0.12650111 0.12480152 ... 0.10051761 0.16310775 0.14360261]\n  [0.09942871 0.12646203 0.12477889 ... 0.1005367  0.16315739 0.14360493]\n  [0.09945242 0.12665191 0.12487727 ... 0.10043678 0.16288202 0.14358336]]\n\n ...\n\n [[0.09865352 0.12651701 0.12597273 ... 0.10113916 0.16261598 0.14431985]\n  [0.09855156 0.1263145  0.12606755 ... 0.1012967  0.16276087 0.1443574 ]\n  [0.09848354 0.12615168 0.12611721 ... 0.10141577 0.16288407 0.14438121]\n  ...\n  [0.09840989 0.12592126 0.12613598 ... 0.10157571 0.16307372 0.1444144 ]\n  [0.09852532 0.12622786 0.12606142 ... 0.10135869 0.16284567 0.1443679 ]\n  [0.09857156 0.12635414 0.12604952 ... 0.10126582 0.16273202 0.14434977]]\n\n [[0.09865361 0.12651569 0.12597194 ... 0.10113986 0.16261749 0.14431958]\n  [0.09855598 0.12632239 0.12606302 ... 0.1012903  0.16275536 0.14435554]\n  [0.09848589 0.12615566 0.12611464 ... 0.10141252 0.1628815  0.14438018]\n  ...\n  [0.09839714 0.12588842 0.1261474  ... 0.10159836 0.16309515 0.144419  ]\n  [0.0985207  0.12621598 0.12606482 ... 0.1013672  0.16285439 0.14436945]\n  [0.09857565 0.12636022 0.12604456 ... 0.1012606  0.1627284  0.14434797]]\n\n [[0.0986535  0.12651372 0.12597099 ... 0.10114089 0.16261955 0.14431931]\n  [0.09856028 0.12632956 0.12605838 ... 0.10128445 0.16275072 0.14435375]\n  [0.09848814 0.12615918 0.12611198 ... 0.10140962 0.16287951 0.14437924]\n  ...\n  [0.09838455 0.1258555  0.12615857 ... 0.10162079 0.16311646 0.14442348]\n  [0.09851597 0.12620348 0.12606801 ... 0.10137597 0.16286363 0.14437097]\n  [0.09857934 0.1263651  0.1260397  ... 0.10125628 0.162726   0.14434636]]]", "accuracy": 0.25, "inputs": "[[[-0.99560374]\n  [-0.9983266 ]\n  [-1.0014445 ]\n  ...\n  [-0.8010217 ]\n  [-0.8020213 ]\n  [-0.8034348 ]]\n\n [[-0.884163  ]\n  [-0.8722339 ]\n  [-0.8617986 ]\n  ...\n  [-0.86358935]\n  [-0.8614071 ]\n  [-0.85974586]]\n\n [[-0.8636094 ]\n  [-0.8601534 ]\n  [-0.85754985]\n  ...\n  [-0.9232365 ]\n  [-0.9223625 ]\n  [-0.9218354 ]]\n\n ...\n\n [[-1.017276  ]\n  [-1.0176198 ]\n  [-1.0185472 ]\n  ...\n  [-1.0338676 ]\n  [-1.0427345 ]\n  [-1.051585  ]]\n\n [[-1.039985  ]\n  [-1.0463375 ]\n  [-1.0530899 ]\n  ...\n  [-0.91811097]\n  [-0.9222992 ]\n  [-0.9268466 ]]\n\n [[-0.86484635]\n  [-0.87112236]\n  [-0.8790098 ]\n  ...\n  [-0.850916  ]\n  [-0.8499488 ]\n  [-0.8496884 ]]]"}
{"time_total_s": 7.402811527252197, "pid": 7043, "time_this_iter_s": 2.4654884338378906, "experiment_id": "8f8a7e61c7ec410bb3790f174773713a", "timesteps_total": null, "timesteps_since_restore": 0, "training_iteration": 3, "config": {"workers": 2, "learning_rate": 0.01, "num_rnn_layers": 1, "hidden_dims": 64, "fold": 7, "dropout": 0.3, "epochs": 99999, "earliness_factor": 1, "switch_epoch": 9999, "batchsize": 96, "dataset": "Mallat"}, "loss": 2.129657030105591, "hostname": "e9379f55ba79", "timestamp": 1544558209, "confusion_matrix": "[[0. 0. 0. 1. 0. 0. 0. 0.]\n [0. 0. 0. 2. 0. 0. 0. 0.]\n [0. 0. 0. 0. 0. 0. 0. 0.]\n [0. 0. 0. 2. 0. 0. 0. 0.]\n [0. 0. 0. 1. 0. 0. 0. 0.]\n [0. 0. 0. 1. 0. 0. 0. 0.]\n [0. 0. 0. 1. 0. 0. 0. 0.]\n [0. 0. 0. 0. 0. 0. 0. 0.]]", "date": "2018-12-11_20-56-49", "targets": "[[6 6 6 ... 6 6 6]\n [5 5 5 ... 5 5 5]\n [1 1 1 ... 1 1 1]\n ...\n [0 0 0 ... 0 0 0]\n [3 3 3 ... 3 3 3]\n [4 4 4 ... 4 4 4]]", "weights": "[[4.3339325e-05 4.3714921e-05 4.4252858e-05 ... 4.4167395e-05\n  4.4166118e-05 9.5622438e-01]\n [4.3331722e-05 4.3656804e-05 4.4113691e-05 ... 4.4539447e-05\n  4.4521748e-05 9.5624125e-01]\n [4.3330318e-05 4.3647524e-05 4.4096614e-05 ... 4.4810215e-05\n  4.4800043e-05 9.5631140e-01]\n ...\n [4.3340809e-05 4.3725846e-05 4.4276621e-05 ... 4.5137160e-05\n  4.5185890e-05 9.5631182e-01]\n [4.3342341e-05 4.3738357e-05 4.4308381e-05 ... 4.4664230e-05\n  4.4680804e-05 9.5629537e-01]\n [4.3330401e-05 4.3649146e-05 4.4105193e-05 ... 4.4465683e-05\n  4.4450138e-05 9.5622212e-01]]", "done": false, "iterations_since_restore": 3, "episodes_total": null, "time_since_restore": 7.402811527252197, "node_ip": "172.17.0.2", "probas": "[[[0.09891402 0.12282056 0.12109873 ... 0.09118468 0.17410326 0.14813064]\n  [0.09889837 0.1228707  0.12127053 ... 0.09117507 0.17392659 0.14806135]\n  [0.09889545 0.12287977 0.12130214 ... 0.09117336 0.17389387 0.14804924]\n  ...\n  [0.09891702 0.12281063 0.12106524 ... 0.09118657 0.17413746 0.14814481]\n  [0.09892014 0.12280018 0.12103012 ... 0.09118859 0.17417324 0.1481599 ]\n  [0.09889563 0.12287921 0.12130022 ... 0.09117344 0.17389582 0.14804994]]\n\n [[0.09866083 0.12315037 0.12091911 ... 0.09105416 0.1741723  0.14939852]\n  [0.09867462 0.12319233 0.12111849 ... 0.09103814 0.17398497 0.14915816]\n  [0.09867874 0.12319321 0.12113942 ... 0.09103748 0.17396563 0.1491236 ]\n  ...\n  [0.09865709 0.1231442  0.12088815 ... 0.09105702 0.17420104 0.14944226]\n  [0.09865439 0.12313251 0.12084363 ... 0.09106172 0.1742426  0.14949585]\n  [0.09868008 0.12318766 0.12112334 ... 0.09103909 0.17398119 0.14913337]]\n\n [[0.09827042 0.12361645 0.12124003 ... 0.09114593 0.17350243 0.15071112]\n  [0.0983475  0.12364991 0.12140618 ... 0.09107552 0.17336237 0.1502946 ]\n  [0.09835971 0.12364224 0.12140649 ... 0.09107044 0.17336702 0.15025026]\n  ...\n  [0.09825528 0.12361359 0.12122272 ... 0.09115818 0.17351602 0.15077832]\n  [0.09823768 0.12359898 0.12118139 ... 0.09117755 0.1735534  0.15087523]\n  [0.09835821 0.12363134 0.12137593 ... 0.09107661 0.17339648 0.15028246]]\n\n ...\n\n [[0.09693157 0.12348098 0.12142184 ... 0.0932252  0.17279282 0.1514922 ]\n  [0.09654704 0.12320605 0.1212766  ... 0.09371188 0.17320853 0.15173659]\n  [0.09625196 0.12299136 0.12116399 ... 0.09407064 0.17354684 0.15195544]\n  ...\n  [0.09586793 0.12272697 0.12102058 ... 0.0945116  0.17398852 0.15234384]\n  [0.09640484 0.12312856 0.12121731 ... 0.09386623 0.17336065 0.15191336]\n  [0.0966252  0.12326035 0.12130237 ... 0.09361554 0.17312583 0.15168369]]\n\n [[0.09693071 0.12347998 0.12142002 ... 0.09322616 0.1727952  0.15149368]\n  [0.09656385 0.12321748 0.12128117 ... 0.09369121 0.17319176 0.15172583]\n  [0.09626093 0.1229976  0.12116579 ... 0.09405964 0.17353785 0.15194999]\n  ...\n  [0.09580968 0.12267748 0.12099919 ... 0.09458388 0.17406175 0.15237983]\n  [0.09638448 0.12311268 0.12120853 ... 0.09389157 0.17338543 0.15192756]\n  [0.09663929 0.12327016 0.12130548 ... 0.09359758 0.17311227 0.15167642]]\n\n [[0.09692905 0.12347869 0.12141782 ... 0.09322803 0.17279851 0.1514965 ]\n  [0.09657948 0.12322829 0.12128516 ... 0.09367171 0.17317624 0.1517166 ]\n  [0.09626907 0.1230035  0.12116729 ... 0.09404945 0.17352971 0.15194577]\n  ...\n  [0.09575157 0.12262764 0.12097782 ... 0.09465588 0.17413546 0.15241584]\n  [0.09636345 0.12309629 0.12119928 ... 0.09391756 0.1734111  0.1519428 ]\n  [0.09665137 0.12327889 0.1213078  ... 0.09358195 0.17310105 0.1516716 ]]]", "accuracy": 0.25, "inputs": "[[[-0.99560374]\n  [-0.9983266 ]\n  [-1.0014445 ]\n  ...\n  [-0.8010217 ]\n  [-0.8020213 ]\n  [-0.8034348 ]]\n\n [[-0.884163  ]\n  [-0.8722339 ]\n  [-0.8617986 ]\n  ...\n  [-0.86358935]\n  [-0.8614071 ]\n  [-0.85974586]]\n\n [[-0.8636094 ]\n  [-0.8601534 ]\n  [-0.85754985]\n  ...\n  [-0.9232365 ]\n  [-0.9223625 ]\n  [-0.9218354 ]]\n\n ...\n\n [[-1.017276  ]\n  [-1.0176198 ]\n  [-1.0185472 ]\n  ...\n  [-1.0338676 ]\n  [-1.0427345 ]\n  [-1.051585  ]]\n\n [[-1.039985  ]\n  [-1.0463375 ]\n  [-1.0530899 ]\n  ...\n  [-0.91811097]\n  [-0.9222992 ]\n  [-0.9268466 ]]\n\n [[-0.86484635]\n  [-0.87112236]\n  [-0.8790098 ]\n  ...\n  [-0.850916  ]\n  [-0.8499488 ]\n  [-0.8496884 ]]]"}
{"time_total_s": 9.97873568534851, "pid": 7043, "time_this_iter_s": 2.5759241580963135, "experiment_id": "8f8a7e61c7ec410bb3790f174773713a", "timesteps_total": null, "timesteps_since_restore": 0, "training_iteration": 4, "config": {"workers": 2, "learning_rate": 0.01, "num_rnn_layers": 1, "hidden_dims": 64, "fold": 7, "dropout": 0.3, "epochs": 99999, "earliness_factor": 1, "switch_epoch": 9999, "batchsize": 96, "dataset": "Mallat"}, "loss": 2.185140371322632, "hostname": "e9379f55ba79", "timestamp": 1544558212, "confusion_matrix": "[[0. 0. 0. 1. 0. 0. 0. 0.]\n [0. 0. 0. 2. 0. 0. 0. 0.]\n [0. 0. 0. 0. 0. 0. 0. 0.]\n [0. 0. 0. 2. 0. 0. 0. 0.]\n [0. 0. 0. 1. 0. 0. 0. 0.]\n [0. 0. 0. 1. 0. 0. 0. 0.]\n [0. 0. 0. 1. 0. 0. 0. 0.]\n [0. 0. 0. 0. 0. 0. 0. 0.]]", "date": "2018-12-11_20-56-52", "targets": "[[6 6 6 ... 6 6 6]\n [5 5 5 ... 5 5 5]\n [1 1 1 ... 1 1 1]\n ...\n [0 0 0 ... 0 0 0]\n [3 3 3 ... 3 3 3]\n [4 4 4 ... 4 4 4]]", "weights": "[[4.2440028e-05 4.3005370e-05 4.3858636e-05 ... 4.5023891e-05\n  4.5023447e-05 9.5528507e-01]\n [4.2428292e-05 4.2915322e-05 4.3633660e-05 ... 4.5813242e-05\n  4.5777855e-05 9.5526981e-01]\n [4.2426145e-05 4.2901047e-05 4.3606495e-05 ... 4.6408975e-05\n  4.6390353e-05 9.5591193e-01]\n ...\n [4.2442291e-05 4.3022352e-05 4.3897180e-05 ... 4.6998146e-05\n  4.7110258e-05 9.5587581e-01]\n [4.2444724e-05 4.3041931e-05 4.3948945e-05 ... 4.6030142e-05\n  4.6067489e-05 9.5567381e-01]\n [4.2426269e-05 4.2903659e-05 4.3620428e-05 ... 4.5662731e-05\n  4.5631212e-05 9.5532501e-01]]", "done": false, "iterations_since_restore": 4, "episodes_total": null, "time_since_restore": 9.97873568534851, "node_ip": "172.17.0.2", "probas": "[[[0.10590805 0.12367602 0.12532891 ... 0.09851356 0.17492618 0.15406832]\n  [0.10590006 0.12385189 0.12544265 ... 0.09846983 0.1745927  0.15406705]\n  [0.10589841 0.12388408 0.12546368 ... 0.09846182 0.17453127 0.15406795]\n  ...\n  [0.10590937 0.12364147 0.12530677 ... 0.09852205 0.174991   0.15406963]\n  [0.10591064 0.12360513 0.12528352 ... 0.09853099 0.17505886 0.15407138]\n  [0.10589851 0.12388214 0.1254624  ... 0.09846229 0.17453495 0.15406787]]\n\n [[0.10550062 0.12289982 0.12605153 ... 0.0987935  0.17565563 0.15496616]\n  [0.10556493 0.12323508 0.12606695 ... 0.09867641 0.17520063 0.15482756]\n  [0.10557563 0.12327513 0.12606128 ... 0.09866156 0.17514881 0.15480657]\n  ...\n  [0.10548703 0.12284225 0.12605363 ... 0.09881465 0.17572948 0.15499371]\n  [0.10547192 0.12276543 0.12604922 ... 0.0988417  0.17583112 0.15502644]\n  [0.10557502 0.12325452 0.12605304 ... 0.09866763 0.1751812  0.15480992]]\n\n [[0.10482503 0.12219547 0.12714708 ... 0.09961317 0.17543408 0.15590079]\n  [0.10505389 0.12274312 0.12699316 ... 0.0992934  0.17487963 0.15562797]\n  [0.10507994 0.12278296 0.12696186 ... 0.09926171 0.17485574 0.15559667]\n  ...\n  [0.10478351 0.12211145 0.12718047 ... 0.09966762 0.17550962 0.15594824]\n  [0.10472649 0.12197466 0.12721366 ... 0.09974635 0.17564954 0.15601493]\n  [0.10506684 0.12272633 0.12695822 ... 0.09928583 0.17493032 0.15561342]]\n\n ...\n\n [[0.10124196 0.11807612 0.12544318 ... 0.10570485 0.17898834 0.15480855]\n  [0.09973378 0.11637819 0.12516575 ... 0.10740931 0.1810788  0.15523963]\n  [0.09862483 0.11515926 0.12503637 ... 0.10862733 0.18263425 0.15561673]\n  ...\n  [0.0974737  0.11392059 0.12511155 ... 0.10990271 0.18429078 0.1560141 ]\n  [0.09936831 0.11599093 0.12525116 ... 0.10782293 0.18160841 0.15534152]\n  [0.1000288  0.11670227 0.12520589 ... 0.10707998 0.18067464 0.15514843]]\n\n [[0.10123834 0.11807106 0.12544236 ... 0.10570849 0.17899588 0.15480967]\n  [0.09979776 0.11644777 0.12517434 ... 0.10733798 0.18099307 0.1552193 ]\n  [0.09865655 0.11519254 0.12503925 ... 0.10859215 0.18259229 0.15560617]\n  ...\n  [0.09724049 0.11366503 0.12507477 ... 0.11015271 0.18462177 0.15610847]\n  [0.09929024 0.11590372 0.12523906 ... 0.10790901 0.18171993 0.15536714]\n  [0.1000851  0.11676379 0.12521617 ... 0.10701661 0.18060037 0.15513127]]\n\n [[0.10123223 0.1180632  0.12544218 ... 0.10571497 0.17900714 0.15481168]\n  [0.09985819 0.11651353 0.1251836  ... 0.10727035 0.18091236 0.1552004 ]\n  [0.09868657 0.11522411 0.12504312 ... 0.10855889 0.18255277 0.1555962 ]\n  ...\n  [0.09700571 0.11340784 0.12503792 ... 0.11040343 0.18495551 0.15620591]\n  [0.09920982 0.11581378 0.12522724 ... 0.10799748 0.18183514 0.15539409]\n  [0.10013458 0.11681788 0.12522686 ... 0.10696071 0.18053578 0.1551165 ]]]", "accuracy": 0.25, "inputs": "[[[-0.99560374]\n  [-0.9983266 ]\n  [-1.0014445 ]\n  ...\n  [-0.8010217 ]\n  [-0.8020213 ]\n  [-0.8034348 ]]\n\n [[-0.884163  ]\n  [-0.8722339 ]\n  [-0.8617986 ]\n  ...\n  [-0.86358935]\n  [-0.8614071 ]\n  [-0.85974586]]\n\n [[-0.8636094 ]\n  [-0.8601534 ]\n  [-0.85754985]\n  ...\n  [-0.9232365 ]\n  [-0.9223625 ]\n  [-0.9218354 ]]\n\n ...\n\n [[-1.017276  ]\n  [-1.0176198 ]\n  [-1.0185472 ]\n  ...\n  [-1.0338676 ]\n  [-1.0427345 ]\n  [-1.051585  ]]\n\n [[-1.039985  ]\n  [-1.0463375 ]\n  [-1.0530899 ]\n  ...\n  [-0.91811097]\n  [-0.9222992 ]\n  [-0.9268466 ]]\n\n [[-0.86484635]\n  [-0.87112236]\n  [-0.8790098 ]\n  ...\n  [-0.850916  ]\n  [-0.8499488 ]\n  [-0.8496884 ]]]"}
{"time_total_s": 12.46144723892212, "pid": 7043, "time_this_iter_s": 2.4827115535736084, "experiment_id": "8f8a7e61c7ec410bb3790f174773713a", "timesteps_total": null, "timesteps_since_restore": 0, "training_iteration": 5, "config": {"workers": 2, "learning_rate": 0.01, "num_rnn_layers": 1, "hidden_dims": 64, "fold": 7, "dropout": 0.3, "epochs": 99999, "earliness_factor": 1, "switch_epoch": 9999, "batchsize": 96, "dataset": "Mallat"}, "loss": 2.2170894145965576, "hostname": "e9379f55ba79", "timestamp": 1544558214, "confusion_matrix": "[[0. 0. 0. 1. 0. 0. 0. 0.]\n [0. 0. 0. 2. 0. 0. 0. 0.]\n [0. 0. 0. 0. 0. 0. 0. 0.]\n [0. 0. 0. 2. 0. 0. 0. 0.]\n [0. 0. 0. 1. 0. 0. 0. 0.]\n [0. 0. 0. 1. 0. 0. 0. 0.]\n [0. 0. 0. 1. 0. 0. 0. 0.]\n [0. 0. 0. 0. 0. 0. 0. 0.]]", "date": "2018-12-11_20-56-54", "targets": "[[6 6 6 ... 6 6 6]\n [5 5 5 ... 5 5 5]\n [1 1 1 ... 1 1 1]\n ...\n [0 0 0 ... 0 0 0]\n [3 3 3 ... 3 3 3]\n [4 4 4 ... 4 4 4]]", "weights": "[[4.1088038e-05 4.1790969e-05 4.2788626e-05 ... 4.2419462e-05\n  4.2418840e-05 9.5834959e-01]\n [4.1073032e-05 4.1681593e-05 4.2526412e-05 ... 4.2772102e-05\n  4.2754287e-05 9.5832181e-01]\n [4.1070292e-05 4.1664149e-05 4.2494710e-05 ... 4.3074357e-05\n  4.3064127e-05 9.5852250e-01]\n ...\n [4.1090938e-05 4.1811538e-05 4.2833333e-05 ... 4.3541164e-05\n  4.3590335e-05 9.5850247e-01]\n [4.1093997e-05 4.1835152e-05 4.2893338e-05 ... 4.2977172e-05\n  4.2994510e-05 9.5842701e-01]\n [4.1070445e-05 4.1667328e-05 4.2511128e-05 ... 4.2698957e-05\n  4.2685089e-05 9.5836055e-01]]", "done": false, "iterations_since_restore": 5, "episodes_total": null, "time_since_restore": 12.46144723892212, "node_ip": "172.17.0.2", "probas": "[[[0.11181099 0.13227282 0.12971665 ... 0.1093565  0.1686316  0.15524758]\n  [0.11188366 0.13235718 0.12970537 ... 0.10933178 0.1683231  0.15529308]\n  [0.11189689 0.13237223 0.1297033  ... 0.10932698 0.16826603 0.15530264]\n  ...\n  [0.11179665 0.13225588 0.12971886 ... 0.10936104 0.16869143 0.15523997]\n  [0.11178157 0.13223796 0.12972118 ... 0.10936567 0.16875403 0.15523243]\n  [0.11189611 0.13237135 0.12970345 ... 0.1093273  0.16826949 0.15530208]]\n\n [[0.11065987 0.1326057  0.13184462 ... 0.10915944 0.16840118 0.15595599]\n  [0.11089647 0.13274093 0.13154483 ... 0.10912141 0.16808231 0.15590177]\n  [0.11093126 0.13275109 0.13149522 ... 0.10911836 0.16805246 0.15589108]\n  ...\n  [0.11061646 0.13258237 0.13190207 ... 0.10916618 0.16845025 0.15596947]\n  [0.11056425 0.13254672 0.13196652 ... 0.10917585 0.16852336 0.1559836 ]\n  [0.11092206 0.13273966 0.13150218 ... 0.10912152 0.16808061 0.15588902]]\n\n [[0.10949443 0.13292204 0.13395558 ... 0.10946598 0.1671897  0.15638398]\n  [0.10998145 0.13317257 0.13330942 ... 0.10927979 0.16687736 0.15630673]\n  [0.11003042 0.13317925 0.13323377 ... 0.10926381 0.16688375 0.15629314]\n  ...\n  [0.10941366 0.13288277 0.13406454 ... 0.10949876 0.16722605 0.1564007 ]\n  [0.1092966  0.13280854 0.13421312 ... 0.10954756 0.167314   0.15642108]\n  [0.10999268 0.1331478  0.13327612 ... 0.10927854 0.16694218 0.15629213]]\n\n ...\n\n [[0.11026662 0.13406399 0.13026771 ... 0.11080703 0.16725877 0.15111476]\n  [0.1097217  0.13385297 0.13025305 ... 0.11127748 0.16789283 0.15046066]\n  [0.10919754 0.1336226  0.13033575 ... 0.11169163 0.16845125 0.15001614]\n  ...\n  [0.10823769 0.1331473  0.1306873  ... 0.1123978  0.16937594 0.14950973]\n  [0.10930757 0.1336659  0.13045858 ... 0.11157296 0.16825558 0.15025648]\n  [0.10984417 0.13390484 0.13024631 ... 0.11117465 0.16775844 0.15058571]]\n\n [[0.11026307 0.13406287 0.13027032 ... 0.11080875 0.1672627  0.15111329]\n  [0.10974681 0.13386376 0.1302527  ... 0.11125563 0.1678659  0.15048714]\n  [0.10921103 0.13362925 0.1303365  ... 0.11167978 0.1684362  0.15002936]\n  ...\n  [0.10814347 0.13309994 0.13068792 ... 0.1124728  0.16948658 0.1494324 ]\n  [0.10927325 0.13365062 0.13046178 ... 0.11160009 0.16829506 0.15022515]\n  [0.10986057 0.1339118  0.13025099 ... 0.11115864 0.16773881 0.15060894]]\n\n [[0.11025666 0.13406079 0.13027488 ... 0.11081229 0.16726847 0.15111062]\n  [0.10976811 0.13387312 0.13025498 ... 0.11123632 0.16784163 0.15051232]\n  [0.10922158 0.13363467 0.13033916 ... 0.11166993 0.16842322 0.15004165]\n  ...\n  [0.1080488  0.1330522  0.13068901 ... 0.11254775 0.16959722 0.14935657]\n  [0.10923642 0.13363436 0.13046685 ... 0.11162883 0.16833621 0.15019333]\n  [0.10987151 0.13391666 0.13025855 ... 0.11114645 0.16772342 0.1506293 ]]]", "accuracy": 0.25, "inputs": "[[[-0.99560374]\n  [-0.9983266 ]\n  [-1.0014445 ]\n  ...\n  [-0.8010217 ]\n  [-0.8020213 ]\n  [-0.8034348 ]]\n\n [[-0.884163  ]\n  [-0.8722339 ]\n  [-0.8617986 ]\n  ...\n  [-0.86358935]\n  [-0.8614071 ]\n  [-0.85974586]]\n\n [[-0.8636094 ]\n  [-0.8601534 ]\n  [-0.85754985]\n  ...\n  [-0.9232365 ]\n  [-0.9223625 ]\n  [-0.9218354 ]]\n\n ...\n\n [[-1.017276  ]\n  [-1.0176198 ]\n  [-1.0185472 ]\n  ...\n  [-1.0338676 ]\n  [-1.0427345 ]\n  [-1.051585  ]]\n\n [[-1.039985  ]\n  [-1.0463375 ]\n  [-1.0530899 ]\n  ...\n  [-0.91811097]\n  [-0.9222992 ]\n  [-0.9268466 ]]\n\n [[-0.86484635]\n  [-0.87112236]\n  [-0.8790098 ]\n  ...\n  [-0.850916  ]\n  [-0.8499488 ]\n  [-0.8496884 ]]]"}
{"time_total_s": 14.773804426193237, "pid": 7043, "time_this_iter_s": 2.312357187271118, "experiment_id": "8f8a7e61c7ec410bb3790f174773713a", "timesteps_total": null, "timesteps_since_restore": 0, "training_iteration": 6, "config": {"workers": 2, "learning_rate": 0.01, "num_rnn_layers": 1, "hidden_dims": 64, "fold": 7, "dropout": 0.3, "epochs": 99999, "earliness_factor": 1, "switch_epoch": 9999, "batchsize": 96, "dataset": "Mallat"}, "loss": 2.2286489009857178, "hostname": "e9379f55ba79", "timestamp": 1544558217, "confusion_matrix": "[[0. 0. 0. 1. 0. 0. 0. 0.]\n [0. 0. 0. 2. 0. 0. 0. 0.]\n [0. 0. 0. 0. 0. 0. 0. 0.]\n [0. 0. 0. 2. 0. 0. 0. 0.]\n [0. 0. 0. 1. 0. 0. 0. 0.]\n [0. 0. 0. 1. 0. 0. 0. 0.]\n [0. 0. 0. 1. 0. 0. 0. 0.]\n [0. 0. 0. 0. 0. 0. 0. 0.]]", "date": "2018-12-11_20-56-57", "targets": "[[6 6 6 ... 6 6 6]\n [5 5 5 ... 5 5 5]\n [1 1 1 ... 1 1 1]\n ...\n [0 0 0 ... 0 0 0]\n [3 3 3 ... 3 3 3]\n [4 4 4 ... 4 4 4]]", "weights": "[[4.1481147e-05 4.2224510e-05 4.3121338e-05 ... 4.1397881e-05\n  4.1397161e-05 9.5919305e-01]\n [4.1465566e-05 4.2115415e-05 4.2887987e-05 ... 4.1527295e-05\n  4.1519794e-05 9.5911860e-01]\n [4.1462641e-05 4.2097745e-05 4.2859654e-05 ... 4.1656989e-05\n  4.1652558e-05 9.5934969e-01]\n ...\n [4.1484152e-05 4.2244854e-05 4.3160417e-05 ... 4.1869429e-05\n  4.1885494e-05 9.5931280e-01]\n [4.1487281e-05 4.2268068e-05 4.3212927e-05 ... 4.1634321e-05\n  4.1640178e-05 9.5921820e-01]\n [4.1462834e-05 4.2100877e-05 4.2874697e-05 ... 4.1502815e-05\n  4.1497500e-05 9.5920813e-01]]", "done": false, "iterations_since_restore": 6, "episodes_total": null, "time_since_restore": 14.773804426193237, "node_ip": "172.17.0.2", "probas": "[[[0.10941356 0.12800954 0.12349847 ... 0.10553724 0.17476392 0.15843377]\n  [0.1095357  0.12825185 0.12354171 ... 0.10539071 0.17444134 0.15836477]\n  [0.10955796 0.12829626 0.12354989 ... 0.10536326 0.17438146 0.15835336]\n  ...\n  [0.10938951 0.12796213 0.12349029 ... 0.10556529 0.17482623 0.15844856]\n  [0.10936419 0.12791231 0.12348178 ... 0.10559446 0.17489135 0.1584646 ]\n  [0.10955663 0.12829359 0.12354941 ... 0.1053649  0.17438506 0.15835404]]\n\n [[0.10817555 0.12712227 0.12531069 ... 0.10610992 0.17385197 0.16046864]\n  [0.10848674 0.12756886 0.12509383 ... 0.10584593 0.17360514 0.16013971]\n  [0.10852963 0.12762088 0.12505548 ... 0.10581356 0.17358822 0.16009012]\n  ...\n  [0.10811964 0.12704608 0.12535456 ... 0.10615456 0.17388651 0.16052993]\n  [0.10805015 0.1269433  0.12540182 ... 0.10621335 0.17394413 0.16060337]\n  [0.10851517 0.12759231 0.12505747 ... 0.10582996 0.17361571 0.16010119]]\n\n [[0.10723215 0.1264444  0.12707955 ... 0.10688394 0.17198052 0.16183603]\n  [0.10778618 0.12714052 0.12654841 ... 0.1063894  0.1718198  0.16137578]\n  [0.1078343  0.12718673 0.12648416 ... 0.10635056 0.17184664 0.16132511]\n  ...\n  [0.10714389 0.12633975 0.12717177 ... 0.10696044 0.1719903  0.16191036]\n  [0.10700842 0.12616462 0.1272958  ... 0.10708115 0.17204413 0.1620171 ]\n  [0.10778431 0.12711072 0.12651534 ... 0.1063998  0.17189755 0.16135931]]\n\n ...\n\n [[0.10941139 0.1268611  0.12394938 ... 0.10683374 0.17236963 0.158467  ]\n  [0.10909988 0.12639955 0.12406535 ... 0.10722519 0.1727293  0.15834312]\n  [0.10877784 0.12597959 0.12421566 ... 0.10758594 0.17304415 0.15827875]\n  ...\n  [0.10814483 0.12522978 0.12455539 ... 0.10823978 0.17357543 0.15824555]\n  [0.10881346 0.1260665  0.12422863 ... 0.10752428 0.17294379 0.15834141]\n  [0.10916844 0.12649776 0.12403741 ... 0.10714173 0.1726548  0.15836704]]\n\n [[0.1094074  0.12685747 0.12395198 ... 0.10683718 0.17237239 0.15846822]\n  [0.10911265 0.12641914 0.12406068 ... 0.10720871 0.17271468 0.15834919]\n  [0.10878388 0.12598929 0.12421384 ... 0.10757809 0.17303632 0.15828238]\n  ...\n  [0.10808985 0.12515832 0.12457895 ... 0.10829859 0.17363581 0.15823315]\n  [0.1087916  0.12603828 0.12423843 ... 0.10754829 0.17296644 0.15833722]\n  [0.10917485 0.12651046 0.12403665 ... 0.10713159 0.17264453 0.15837361]]\n\n [[0.10940122 0.12685148 0.12395599 ... 0.10684281 0.17237604 0.15846965]\n  [0.10912248 0.12643568 0.12405799 ... 0.10719511 0.17270139 0.15835562]\n  [0.10878777 0.12599668 0.1242134  ... 0.10757229 0.1730295  0.15828614]\n  ...\n  [0.10803433 0.12508678 0.12460298 ... 0.10835735 0.1736959  0.1582213 ]\n  [0.10876767 0.12600799 0.12424981 ... 0.1075743  0.17298986 0.15833353]\n  [0.10917731 0.12651873 0.12403829 ... 0.10712545 0.17263643 0.15838028]]]", "accuracy": 0.25, "inputs": "[[[-0.99560374]\n  [-0.9983266 ]\n  [-1.0014445 ]\n  ...\n  [-0.8010217 ]\n  [-0.8020213 ]\n  [-0.8034348 ]]\n\n [[-0.884163  ]\n  [-0.8722339 ]\n  [-0.8617986 ]\n  ...\n  [-0.86358935]\n  [-0.8614071 ]\n  [-0.85974586]]\n\n [[-0.8636094 ]\n  [-0.8601534 ]\n  [-0.85754985]\n  ...\n  [-0.9232365 ]\n  [-0.9223625 ]\n  [-0.9218354 ]]\n\n ...\n\n [[-1.017276  ]\n  [-1.0176198 ]\n  [-1.0185472 ]\n  ...\n  [-1.0338676 ]\n  [-1.0427345 ]\n  [-1.051585  ]]\n\n [[-1.039985  ]\n  [-1.0463375 ]\n  [-1.0530899 ]\n  ...\n  [-0.91811097]\n  [-0.9222992 ]\n  [-0.9268466 ]]\n\n [[-0.86484635]\n  [-0.87112236]\n  [-0.8790098 ]\n  ...\n  [-0.850916  ]\n  [-0.8499488 ]\n  [-0.8496884 ]]]"}
{"time_total_s": 17.250426530838013, "pid": 7043, "time_this_iter_s": 2.4766221046447754, "experiment_id": "8f8a7e61c7ec410bb3790f174773713a", "timesteps_total": null, "timesteps_since_restore": 0, "training_iteration": 7, "config": {"workers": 2, "learning_rate": 0.01, "num_rnn_layers": 1, "hidden_dims": 64, "fold": 7, "dropout": 0.3, "epochs": 99999, "earliness_factor": 1, "switch_epoch": 9999, "batchsize": 96, "dataset": "Mallat"}, "loss": 2.2660539150238037, "hostname": "e9379f55ba79", "timestamp": 1544558219, "confusion_matrix": "[[0. 0. 0. 1. 0. 0. 0. 0.]\n [0. 0. 0. 2. 0. 0. 0. 0.]\n [0. 0. 0. 0. 0. 0. 0. 0.]\n [0. 0. 0. 2. 0. 0. 0. 0.]\n [0. 0. 0. 1. 0. 0. 0. 0.]\n [0. 0. 0. 1. 0. 0. 0. 0.]\n [0. 0. 0. 1. 0. 0. 0. 0.]\n [0. 0. 0. 0. 0. 0. 0. 0.]]", "date": "2018-12-11_20-56-59", "targets": "[[6 6 6 ... 6 6 6]\n [5 5 5 ... 5 5 5]\n [1 1 1 ... 1 1 1]\n ...\n [0 0 0 ... 0 0 0]\n [3 3 3 ... 3 3 3]\n [4 4 4 ... 4 4 4]]", "weights": "[[4.2070755e-05 4.3161148e-05 4.4376888e-05 ... 4.2422878e-05\n  4.2422500e-05 9.6067071e-01]\n [4.2034342e-05 4.2990054e-05 4.4044464e-05 ... 4.2572075e-05\n  4.2564061e-05 9.6064979e-01]\n [4.2027528e-05 4.2963133e-05 4.4005461e-05 ... 4.2713549e-05\n  4.2709042e-05 9.6078402e-01]\n ...\n [4.2077776e-05 4.3192438e-05 4.4431337e-05 ... 4.2956268e-05\n  4.2973443e-05 9.6078718e-01]\n [4.2085077e-05 4.3228782e-05 4.4505803e-05 ... 4.2704076e-05\n  4.2710933e-05 9.6090448e-01]\n [4.2027968e-05 4.2968866e-05 4.4028628e-05 ... 4.2545136e-05\n  4.2539723e-05 9.6075541e-01]]", "done": false, "iterations_since_restore": 7, "episodes_total": null, "time_since_restore": 17.250426530838013, "node_ip": "172.17.0.2", "probas": "[[[0.11079238 0.12593633 0.12616012 ... 0.09237601 0.1728162  0.15973394]\n  [0.11110581 0.1262792  0.12603858 ... 0.0920658  0.17237294 0.16011289]\n  [0.11116357 0.12634245 0.12601614 ... 0.09200785 0.17229012 0.16018519]\n  ...\n  [0.11073139 0.12586969 0.12618378 ... 0.09243558 0.17290135 0.15966283]\n  [0.11066744 0.12579985 0.12620854 ... 0.09249773 0.17299016 0.15958917]\n  [0.11116007 0.12633863 0.12601745 ... 0.09201134 0.17229508 0.16018078]]\n\n [[0.10843637 0.12373664 0.13038193 ... 0.0944716  0.1723548  0.15830365]\n  [0.10906839 0.12442447 0.12970218 ... 0.0938665  0.17198169 0.15879877]\n  [0.10915319 0.12451226 0.12959616 ... 0.09378682 0.17194788 0.1588618 ]\n  ...\n  [0.10832707 0.12361878 0.1305077  ... 0.09457445 0.17240824 0.15822689]\n  [0.10818841 0.12346561 0.13065416 ... 0.09470598 0.17249024 0.15812564]\n  [0.10911972 0.12447271 0.12961835 ... 0.09382094 0.1719842  0.15882725]]\n\n [[0.1070024  0.12169488 0.13441387 ... 0.0965011  0.17090201 0.15732253]\n  [0.10794944 0.1227757  0.13310163 ... 0.09551311 0.17062551 0.15795544]\n  [0.10802616 0.12286463 0.13295653 ... 0.09542828 0.17064057 0.15799953]\n  ...\n  [0.10685924 0.12153094 0.13462907 ... 0.09665082 0.17092538 0.15723982]\n  [0.10663289 0.12127255 0.13493101 ... 0.09688257 0.17099902 0.1571017 ]\n  [0.10793101 0.12275711 0.1330524  ... 0.09552505 0.17070556 0.15792002]]\n\n ...\n\n [[0.10954414 0.12091672 0.13185896 ... 0.09652433 0.17313394 0.15599531]\n  [0.1090461  0.12018596 0.13248204 ... 0.09714358 0.17361678 0.15552065]\n  [0.10856936 0.11955117 0.13305683 ... 0.09769512 0.17400895 0.15512261]\n  ...\n  [0.10768875 0.11846565 0.1340905  ... 0.09866451 0.174626   0.15446462]\n  [0.10863868 0.11968604 0.13296925 ... 0.09760334 0.17388688 0.1551839 ]\n  [0.10915101 0.12033838 0.13235052 ... 0.09701459 0.17351893 0.15561652]]\n\n [[0.10953785 0.12091115 0.13186553 ... 0.09653015 0.17313689 0.15599057]\n  [0.10906534 0.1202164  0.13245706 ... 0.09711855 0.17359696 0.15553902]\n  [0.10857809 0.11956568 0.13304563 ... 0.09768373 0.17399892 0.15513054]\n  ...\n  [0.10761055 0.11836389 0.13418077 ... 0.09874936 0.17469285 0.15441103]\n  [0.10860576 0.11964364 0.13300782 ... 0.09764019 0.17391388 0.15515752]\n  [0.10916126 0.1203585  0.13233607 ... 0.09699926 0.17350437 0.1556278 ]]\n\n [[0.10952856 0.12090188 0.1318761  ... 0.09653953 0.17314135 0.15598321]\n  [0.10908061 0.12024211 0.13243723 ... 0.09709806 0.17357902 0.15555428]\n  [0.10858402 0.11957674 0.13303801 ... 0.09767552 0.17399028 0.15513624]\n  ...\n  [0.10753214 0.11826252 0.13427122 ... 0.09883393 0.17475897 0.15435822]\n  [0.10857004 0.11959824 0.13304992 ... 0.09768005 0.17394191 0.15512928]\n  [0.10916609 0.12037179 0.13232858 ... 0.09699026 0.17349295 0.15563457]]]", "accuracy": 0.25, "inputs": "[[[-0.99560374]\n  [-0.9983266 ]\n  [-1.0014445 ]\n  ...\n  [-0.8010217 ]\n  [-0.8020213 ]\n  [-0.8034348 ]]\n\n [[-0.884163  ]\n  [-0.8722339 ]\n  [-0.8617986 ]\n  ...\n  [-0.86358935]\n  [-0.8614071 ]\n  [-0.85974586]]\n\n [[-0.8636094 ]\n  [-0.8601534 ]\n  [-0.85754985]\n  ...\n  [-0.9232365 ]\n  [-0.9223625 ]\n  [-0.9218354 ]]\n\n ...\n\n [[-1.017276  ]\n  [-1.0176198 ]\n  [-1.0185472 ]\n  ...\n  [-1.0338676 ]\n  [-1.0427345 ]\n  [-1.051585  ]]\n\n [[-1.039985  ]\n  [-1.0463375 ]\n  [-1.0530899 ]\n  ...\n  [-0.91811097]\n  [-0.9222992 ]\n  [-0.9268466 ]]\n\n [[-0.86484635]\n  [-0.87112236]\n  [-0.8790098 ]\n  ...\n  [-0.850916  ]\n  [-0.8499488 ]\n  [-0.8496884 ]]]"}
{"time_total_s": 19.53463864326477, "pid": 7043, "time_this_iter_s": 2.284212112426758, "experiment_id": "8f8a7e61c7ec410bb3790f174773713a", "timesteps_total": null, "timesteps_since_restore": 0, "training_iteration": 8, "config": {"workers": 2, "learning_rate": 0.01, "num_rnn_layers": 1, "hidden_dims": 64, "fold": 7, "dropout": 0.3, "epochs": 99999, "earliness_factor": 1, "switch_epoch": 9999, "batchsize": 96, "dataset": "Mallat"}, "loss": 2.2225804328918457, "hostname": "e9379f55ba79", "timestamp": 1544558221, "confusion_matrix": "[[0. 0. 0. 0. 0. 0. 1. 0.]\n [0. 0. 0. 0. 0. 0. 2. 0.]\n [0. 0. 0. 0. 0. 0. 0. 0.]\n [0. 0. 0. 0. 0. 0. 2. 0.]\n [0. 0. 0. 0. 0. 0. 1. 0.]\n [0. 0. 0. 0. 0. 0. 1. 0.]\n [0. 0. 0. 0. 0. 0. 1. 0.]\n [0. 0. 0. 0. 0. 0. 0. 0.]]", "date": "2018-12-11_20-57-01", "targets": "[[6 6 6 ... 6 6 6]\n [5 5 5 ... 5 5 5]\n [1 1 1 ... 1 1 1]\n ...\n [0 0 0 ... 0 0 0]\n [3 3 3 ... 3 3 3]\n [4 4 4 ... 4 4 4]]", "weights": "[[4.3606680e-05 4.4692079e-05 4.6004716e-05 ... 4.3748045e-05\n  4.3747503e-05 9.5798242e-01]\n [4.3585023e-05 4.4527747e-05 4.5656740e-05 ... 4.3879420e-05\n  4.3872056e-05 9.5795876e-01]\n [4.3581033e-05 4.4501510e-05 4.5615139e-05 ... 4.4011082e-05\n  4.4006876e-05 9.5814371e-01]\n ...\n [4.3610886e-05 4.4722819e-05 4.6062836e-05 ... 4.4238397e-05\n  4.4253025e-05 9.5810598e-01]\n [4.3615295e-05 4.4758104e-05 4.6141660e-05 ... 4.4003555e-05\n  4.4009470e-05 9.5814157e-01]\n [4.3581240e-05 4.4506392e-05 4.5638026e-05 ... 4.3852764e-05\n  4.3847918e-05 9.5799243e-01]]", "done": false, "iterations_since_restore": 8, "episodes_total": null, "time_since_restore": 19.53463864326477, "node_ip": "172.17.0.2", "probas": "[[[0.10860576 0.13308986 0.12403812 ... 0.09303501 0.1798819  0.1589981 ]\n  [0.10881156 0.1330617  0.12438864 ... 0.09309079 0.17932935 0.15898621]\n  [0.10884905 0.13305569 0.12445426 ... 0.09310055 0.17922652 0.1589858 ]\n  ...\n  [0.10856522 0.13309443 0.12397095 ... 0.09302361 0.1799884  0.15900227]\n  [0.10852262 0.13309893 0.123901   ... 0.09301148 0.18009974 0.15900737]\n  [0.10884679 0.13305604 0.12445028 ... 0.09309997 0.17923273 0.1589858 ]]\n\n [[0.10757273 0.1340806  0.12521029 ... 0.09191808 0.17973949 0.16154544]\n  [0.1079552  0.13404629 0.12534645 ... 0.09206964 0.17922473 0.16117463]\n  [0.10800371 0.13403414 0.12534812 ... 0.09209269 0.17917359 0.16111639]\n  ...\n  [0.107506   0.13408436 0.12520055 ... 0.09189188 0.1798159  0.16161783]\n  [0.10741937 0.13408391 0.12517262 ... 0.09186005 0.17992884 0.16170225]\n  [0.10798231 0.13403347 0.12532237 ... 0.0920864  0.17921938 0.16112538]]\n\n [[0.10692997 0.1332961  0.12823871 ... 0.09231426 0.1788172  0.16300836]\n  [0.10752188 0.13350837 0.12787388 ... 0.09232403 0.17834975 0.16243345]\n  [0.10756671 0.13352954 0.12779357 ... 0.09231859 0.17834751 0.16237108]\n  ...\n  [0.1068383  0.13325241 0.1283262  ... 0.09232053 0.17886816 0.16310455]\n  [0.106691   0.13318925 0.12841123 ... 0.0923213  0.17898431 0.16324316]\n  [0.10750728 0.13351983 0.12777461 ... 0.0923084  0.17843199 0.16241111]]\n\n ...\n\n [[0.10796076 0.1292953  0.12963556 ... 0.0950308  0.18213272 0.15987352]\n  [0.10754412 0.1287675  0.13007116 ... 0.09528343 0.18282807 0.15998678]\n  [0.107164   0.12833744 0.1304316  ... 0.09548076 0.18339491 0.16011204]\n  ...\n  [0.10649645 0.1276454  0.13101344 ... 0.09578814 0.18429448 0.16035846]\n  [0.10725633 0.12848769 0.13030417 ... 0.09541033 0.18323207 0.16008979]\n  [0.10763187 0.12888032 0.12997685 ... 0.09522912 0.18268593 0.15996301]]\n\n [[0.10795714 0.12929516 0.12963578 ... 0.09503021 0.18213667 0.15987605]\n  [0.10756125 0.12879281 0.1300503  ... 0.09527068 0.18279889 0.15998344]\n  [0.10717254 0.12835105 0.13042054 ... 0.09547393 0.18338041 0.1601107 ]\n  ...\n  [0.10642848 0.12756744 0.1310798  ... 0.09582195 0.18438762 0.16038401]\n  [0.10723004 0.12846017 0.13032733 ... 0.0954223  0.18327022 0.16009966]\n  [0.10764293 0.12890054 0.12996034 ... 0.09521861 0.18266474 0.15996215]]\n\n [[0.10795153 0.1292931  0.12963787 ... 0.09503062 0.18214326 0.15987925]\n  [0.10757571 0.1288155  0.13003197 ... 0.09525926 0.18277298 0.1599811 ]\n  [0.10717911 0.12836249 0.1304114  ... 0.09546816 0.18336827 0.16010995]\n  ...\n  [0.10636026 0.12748954 0.13114622 ... 0.09585556 0.18447976 0.16040987]\n  [0.10720187 0.12843092 0.13035215 ... 0.09543504 0.18331017 0.16011031]\n  [0.10765014 0.12891671 0.12994756 ... 0.09521005 0.18264863 0.15996258]]]", "accuracy": 0.125, "inputs": "[[[-0.99560374]\n  [-0.9983266 ]\n  [-1.0014445 ]\n  ...\n  [-0.8010217 ]\n  [-0.8020213 ]\n  [-0.8034348 ]]\n\n [[-0.884163  ]\n  [-0.8722339 ]\n  [-0.8617986 ]\n  ...\n  [-0.86358935]\n  [-0.8614071 ]\n  [-0.85974586]]\n\n [[-0.8636094 ]\n  [-0.8601534 ]\n  [-0.85754985]\n  ...\n  [-0.9232365 ]\n  [-0.9223625 ]\n  [-0.9218354 ]]\n\n ...\n\n [[-1.017276  ]\n  [-1.0176198 ]\n  [-1.0185472 ]\n  ...\n  [-1.0338676 ]\n  [-1.0427345 ]\n  [-1.051585  ]]\n\n [[-1.039985  ]\n  [-1.0463375 ]\n  [-1.0530899 ]\n  ...\n  [-0.91811097]\n  [-0.9222992 ]\n  [-0.9268466 ]]\n\n [[-0.86484635]\n  [-0.87112236]\n  [-0.8790098 ]\n  ...\n  [-0.850916  ]\n  [-0.8499488 ]\n  [-0.8496884 ]]]"}
{"time_total_s": 21.76210331916809, "pid": 7043, "time_this_iter_s": 2.2274646759033203, "experiment_id": "8f8a7e61c7ec410bb3790f174773713a", "timesteps_total": null, "timesteps_since_restore": 0, "training_iteration": 9, "config": {"workers": 2, "learning_rate": 0.01, "num_rnn_layers": 1, "hidden_dims": 64, "fold": 7, "dropout": 0.3, "epochs": 99999, "earliness_factor": 1, "switch_epoch": 9999, "batchsize": 96, "dataset": "Mallat"}, "loss": 2.182516574859619, "hostname": "e9379f55ba79", "timestamp": 1544558224, "confusion_matrix": "[[0. 0. 0. 0. 0. 0. 1. 0.]\n [0. 0. 0. 0. 0. 0. 2. 0.]\n [0. 0. 0. 0. 0. 0. 0. 0.]\n [0. 0. 0. 0. 0. 0. 2. 0.]\n [0. 0. 0. 0. 0. 0. 1. 0.]\n [0. 0. 0. 0. 0. 0. 1. 0.]\n [0. 0. 0. 0. 0. 0. 1. 0.]\n [0. 0. 0. 0. 0. 0. 0. 0.]]", "date": "2018-12-11_20-57-04", "targets": "[[6 6 6 ... 6 6 6]\n [5 5 5 ... 5 5 5]\n [1 1 1 ... 1 1 1]\n ...\n [0 0 0 ... 0 0 0]\n [3 3 3 ... 3 3 3]\n [4 4 4 ... 4 4 4]]", "weights": "[[4.4488344e-05 4.6006251e-05 4.7825692e-05 ... 4.5097611e-05\n  4.5097979e-05 9.5684177e-01]\n [4.4436656e-05 4.5739271e-05 4.7278103e-05 ... 4.5283494e-05\n  4.5274057e-05 9.5683998e-01]\n [4.4427208e-05 4.5699158e-05 4.7217953e-05 ... 4.5465637e-05\n  4.5460572e-05 9.5685083e-01]\n ...\n [4.4498483e-05 4.6055407e-05 4.7915713e-05 ... 4.5819554e-05\n  4.5841924e-05 9.5683575e-01]\n [4.4509179e-05 4.6113950e-05 4.8042730e-05 ... 4.5464512e-05\n  4.5474186e-05 9.5687455e-01]\n [4.4427758e-05 4.5708795e-05 4.7258047e-05 ... 4.5243814e-05\n  4.5238266e-05 9.5684439e-01]]", "done": false, "iterations_since_restore": 9, "episodes_total": null, "time_since_restore": 21.76210331916809, "node_ip": "172.17.0.2", "probas": "[[[0.10570332 0.13929006 0.12169989 ... 0.10327128 0.17533197 0.14924718]\n  [0.10622614 0.13929574 0.1216938  ... 0.10314561 0.1749961  0.14942761]\n  [0.10632201 0.13929547 0.12169389 ... 0.10312183 0.1749336  0.14946319]\n  ...\n  [0.10560105 0.13928755 0.12170236 ... 0.10329506 0.1753967  0.14921455]\n  [0.10549373 0.13928442 0.12170538 ... 0.10331976 0.17546432 0.14918125]\n  [0.10631625 0.13929552 0.12169389 ... 0.10312328 0.17493738 0.14946106]]\n\n [[0.1030342  0.14078788 0.12600778 ... 0.10281046 0.17282239 0.15123232]\n  [0.10397422 0.14077435 0.1253227  ... 0.10266679 0.1728292  0.15110107]\n  [0.1040929  0.14075999 0.12521493 ... 0.10265374 0.1728499  0.1510709 ]\n  ...\n  [0.10287356 0.140788   0.12614113 ... 0.10283372 0.17280903 0.15126795]\n  [0.10266388 0.14077924 0.12629502 ... 0.10286745 0.17280939 0.15130156]\n  [0.1040379  0.14075552 0.12523222 ... 0.10266605 0.1728689  0.15106176]]\n\n [[0.10172638 0.1395156  0.13153665 ... 0.10412793 0.17070796 0.15282258]\n  [0.10304967 0.13989432 0.12985414 ... 0.10363168 0.17094287 0.15246831]\n  [0.10314394 0.1399308  0.12966211 ... 0.1035845  0.17099729 0.15241112]\n  ...\n  [0.10153058 0.13944128 0.13182601 ... 0.10421163 0.170657   0.15289548]\n  [0.10120805 0.13933273 0.13222606 ... 0.10433327 0.17061006 0.1529834 ]\n  [0.10300035 0.13990961 0.12977038 ... 0.10362439 0.17100783 0.1524134 ]]\n\n ...\n\n [[0.1044421  0.13263625 0.13177831 ... 0.10778286 0.17705025 0.15127666]\n  [0.10361977 0.13166462 0.13292332 ... 0.10853349 0.17772196 0.15143208]\n  [0.10286994 0.13087532 0.13392767 ... 0.10915519 0.17822407 0.15156156]\n  ...\n  [0.1015555  0.12961444 0.13566174 ... 0.1101716  0.17893086 0.15175085]\n  [0.10303105 0.13114694 0.13369417 ... 0.10898117 0.17800757 0.15148452]\n  [0.10379064 0.13187069 0.13268147 ... 0.10837553 0.17758399 0.15139933]]\n\n [[0.10443351 0.1326352  0.13178617 ... 0.10778554 0.1770503  0.15127699]\n  [0.10365204 0.13171011 0.1328748  ... 0.10849975 0.17769109 0.15142536]\n  [0.10288524 0.1308995  0.13390404 ... 0.10913812 0.17820732 0.15155764]\n  ...\n  [0.10142737 0.12947337 0.13583046 ... 0.1102744  0.17901972 0.15178281]\n  [0.10297874 0.1310958  0.13376151 ... 0.10902146 0.17804036 0.15149426]\n  [0.10381027 0.13190663 0.1326487  ... 0.10835047 0.17755793 0.15139355]]\n\n [[0.1044208  0.13263053 0.1317998  ... 0.10779157 0.17705198 0.15127748]\n  [0.10367885 0.13175082 0.13283381 ... 0.10847032 0.17766209 0.15141901]\n  [0.1028967  0.13091984 0.13388598 ... 0.1091243  0.17819217 0.15155402]\n  ...\n  [0.10129923 0.12933274 0.13599917 ... 0.11037675 0.17910747 0.15181506]\n  [0.10292273 0.13104166 0.13383402 ... 0.10906453 0.17807408 0.15150435]\n  [0.10382217 0.13193521 0.13262676 ... 0.10833184 0.17753547 0.15138848]]]", "accuracy": 0.125, "inputs": "[[[-0.99560374]\n  [-0.9983266 ]\n  [-1.0014445 ]\n  ...\n  [-0.8010217 ]\n  [-0.8020213 ]\n  [-0.8034348 ]]\n\n [[-0.884163  ]\n  [-0.8722339 ]\n  [-0.8617986 ]\n  ...\n  [-0.86358935]\n  [-0.8614071 ]\n  [-0.85974586]]\n\n [[-0.8636094 ]\n  [-0.8601534 ]\n  [-0.85754985]\n  ...\n  [-0.9232365 ]\n  [-0.9223625 ]\n  [-0.9218354 ]]\n\n ...\n\n [[-1.017276  ]\n  [-1.0176198 ]\n  [-1.0185472 ]\n  ...\n  [-1.0338676 ]\n  [-1.0427345 ]\n  [-1.051585  ]]\n\n [[-1.039985  ]\n  [-1.0463375 ]\n  [-1.0530899 ]\n  ...\n  [-0.91811097]\n  [-0.9222992 ]\n  [-0.9268466 ]]\n\n [[-0.86484635]\n  [-0.87112236]\n  [-0.8790098 ]\n  ...\n  [-0.850916  ]\n  [-0.8499488 ]\n  [-0.8496884 ]]]"}
{"time_total_s": 23.93617057800293, "pid": 7043, "time_this_iter_s": 2.174067258834839, "experiment_id": "8f8a7e61c7ec410bb3790f174773713a", "timesteps_total": null, "timesteps_since_restore": 0, "training_iteration": 10, "config": {"workers": 2, "learning_rate": 0.01, "num_rnn_layers": 1, "hidden_dims": 64, "fold": 7, "dropout": 0.3, "epochs": 99999, "earliness_factor": 1, "switch_epoch": 9999, "batchsize": 96, "dataset": "Mallat"}, "loss": 2.176525592803955, "hostname": "e9379f55ba79", "timestamp": 1544558226, "confusion_matrix": "[[0. 0. 0. 0. 0. 0. 1. 0.]\n [0. 0. 0. 0. 0. 0. 2. 0.]\n [0. 0. 0. 0. 0. 0. 0. 0.]\n [0. 0. 0. 0. 0. 0. 2. 0.]\n [0. 0. 0. 0. 0. 0. 1. 0.]\n [0. 0. 0. 0. 0. 0. 1. 0.]\n [0. 0. 0. 0. 0. 0. 1. 0.]\n [0. 0. 0. 0. 0. 0. 0. 0.]]", "date": "2018-12-11_20-57-06", "targets": "[[6 6 6 ... 6 6 6]\n [5 5 5 ... 5 5 5]\n [1 1 1 ... 1 1 1]\n ...\n [0 0 0 ... 0 0 0]\n [3 3 3 ... 3 3 3]\n [4 4 4 ... 4 4 4]]", "weights": "[[4.5240038e-05 4.7364214e-05 4.9813480e-05 ... 4.6184563e-05\n  4.6186164e-05 9.5636284e-01]\n [4.5141522e-05 4.6952464e-05 4.9001843e-05 ... 4.6394700e-05\n  4.6384666e-05 9.5633548e-01]\n [4.5123485e-05 4.6892816e-05 4.8918228e-05 ... 4.6616427e-05\n  4.6611534e-05 9.5629179e-01]\n ...\n [4.5259367e-05 4.7439160e-05 4.9944752e-05 ... 4.7081459e-05\n  4.7107878e-05 9.5625973e-01]\n [4.5279619e-05 4.7530088e-05 5.0135292e-05 ... 4.6634708e-05\n  4.6647161e-05 9.5629644e-01]\n [4.5124609e-05 4.6909587e-05 4.8982416e-05 ... 4.6350946e-05\n  4.6346358e-05 9.5637888e-01]]", "done": true, "iterations_since_restore": 10, "episodes_total": null, "time_since_restore": 23.93617057800293, "node_ip": "172.17.0.2", "probas": "[[[0.10568333 0.1316349  0.11636129 ... 0.10124513 0.17642814 0.14909433]\n  [0.10631147 0.13191427 0.11642805 ... 0.10106836 0.17587198 0.14924155]\n  [0.10642607 0.13196406 0.11644188 ... 0.10103498 0.17576966 0.14927185]\n  ...\n  [0.10555984 0.13157874 0.11634986 ... 0.10127866 0.17653659 0.14906903]\n  [0.10542998 0.1315193  0.11633843 ... 0.10131349 0.17665038 0.14904363]\n  [0.10641919 0.1319611  0.11644102 ... 0.101037   0.17577583 0.14927   ]]\n\n [[0.10284654 0.13218203 0.11986274 ... 0.1005118  0.17467543 0.15260279]\n  [0.10399293 0.13262132 0.11930934 ... 0.10031208 0.17431134 0.15219352]\n  [0.10413466 0.13266046 0.11922138 ... 0.10029395 0.17428704 0.152122  ]\n  ...\n  [0.10264929 0.13210613 0.11997438 ... 0.10054454 0.17472585 0.15269144]\n  [0.10238998 0.13199499 0.12010206 ... 0.10059173 0.1748108  0.15278848]\n  [0.10406695 0.13262671 0.1192321  ... 0.10031085 0.17432842 0.1521219 ]]\n\n [[0.10108241 0.13005854 0.12462404 ... 0.10217925 0.17373441 0.15572874]\n  [0.1027972  0.13111791 0.12310094 ... 0.10147052 0.17333743 0.15484639]\n  [0.10292096 0.13120292 0.12292845 ... 0.10140379 0.17333809 0.15473199]\n  ...\n  [0.10082391 0.12988333 0.12489088 ... 0.10229955 0.17378177 0.15588996]\n  [0.10040113 0.12960874 0.12526032 ... 0.10247435 0.17388709 0.15610357]\n  [0.10273974 0.13110779 0.12302283 ... 0.10146043 0.17340863 0.1547717 ]]\n\n ...\n\n [[0.10173402 0.12367978 0.12279751 ... 0.10662412 0.1834841  0.15483712]\n  [0.10035176 0.12229232 0.12364876 ... 0.10765582 0.18501215 0.15540619]\n  [0.09916314 0.12110814 0.12442669 ... 0.10851122 0.18621401 0.15587336]\n  ...\n  [0.09719057 0.11911189 0.12582329 ... 0.10991249 0.18804227 0.15659049]\n  [0.09948797 0.12142714 0.1242677  ... 0.10827571 0.18579608 0.15568775]\n  [0.10063635 0.12258781 0.12346696 ... 0.10743927 0.184696   0.15528817]]\n\n [[0.10172328 0.1236744  0.12280433 ... 0.10662811 0.18348776 0.15483953]\n  [0.10040776 0.12235514 0.12361303 ... 0.10760988 0.18494396 0.1553821 ]\n  [0.09919059 0.12114034 0.1244094  ... 0.10848817 0.1861785  0.15586074]\n  ...\n  [0.09698567 0.11890952 0.12595558 ... 0.11005301 0.18824601 0.15668048]\n  [0.09940558 0.12134992 0.1243203  ... 0.10833143 0.18587506 0.15572053]\n  [0.10067462 0.12263364 0.12344413 ... 0.10740541 0.18464221 0.15526949]]\n\n [[0.10170669 0.12366284 0.1228159  ... 0.10663681 0.1834966  0.15484378]\n  [0.1004561  0.12240976 0.12358347 ... 0.10756994 0.18488206 0.15536039]\n  [0.09921252 0.12116626 0.12439674 ... 0.10846963 0.18614797 0.15584996]\n  ...\n  [0.09678143 0.1187075  0.12608822 ... 0.11019277 0.18844762 0.15677032]\n  [0.09931818 0.12126732 0.12437728 ... 0.10839101 0.18595761 0.15575483]\n  [0.10070153 0.12266736 0.12342996 ... 0.1073804  0.18459885 0.15525465]]]", "accuracy": 0.125, "inputs": "[[[-0.99560374]\n  [-0.9983266 ]\n  [-1.0014445 ]\n  ...\n  [-0.8010217 ]\n  [-0.8020213 ]\n  [-0.8034348 ]]\n\n [[-0.884163  ]\n  [-0.8722339 ]\n  [-0.8617986 ]\n  ...\n  [-0.86358935]\n  [-0.8614071 ]\n  [-0.85974586]]\n\n [[-0.8636094 ]\n  [-0.8601534 ]\n  [-0.85754985]\n  ...\n  [-0.9232365 ]\n  [-0.9223625 ]\n  [-0.9218354 ]]\n\n ...\n\n [[-1.017276  ]\n  [-1.0176198 ]\n  [-1.0185472 ]\n  ...\n  [-1.0338676 ]\n  [-1.0427345 ]\n  [-1.051585  ]]\n\n [[-1.039985  ]\n  [-1.0463375 ]\n  [-1.0530899 ]\n  ...\n  [-0.91811097]\n  [-0.9222992 ]\n  [-0.9268466 ]]\n\n [[-0.86484635]\n  [-0.87112236]\n  [-0.8790098 ]\n  ...\n  [-0.850916  ]\n  [-0.8499488 ]\n  [-0.8496884 ]]]"}

{"experiment_id": "77aee375a9b64b3d98ab97ade8d2b775", "hostname": "156b637b6f20", "pid": 22794, "time_this_iter_s": 148.8038294315338, "done": true, "date": "2019-01-04_15-42-31", "iterations_since_restore": 1, "time_total_s": 148.8038294315338, "accuracy": 1.0, "timestamp": 1546612951, "targets": "[[0 0 0 ... 0 0 0]\n [0 0 0 ... 0 0 0]\n [2 2 2 ... 2 2 2]\n ...\n [1 1 1 ... 1 1 1]\n [0 0 0 ... 0 0 0]\n [0 0 0 ... 0 0 0]]", "timesteps_total": null, "inputs": "[[[ 0.64599204]\n  [ 0.5800948 ]\n  [ 0.61606413]\n  ...\n  [ 0.584139  ]\n  [ 0.64785445]\n  [ 0.59291995]]\n\n [[ 0.61712694]\n  [ 0.6210609 ]\n  [ 0.6639603 ]\n  ...\n  [ 0.5164287 ]\n  [ 0.5417239 ]\n  [ 0.56701905]]\n\n [[-1.5749352 ]\n  [-1.5900025 ]\n  [-1.5480025 ]\n  ...\n  [ 0.6946785 ]\n  [ 0.7385125 ]\n  [ 0.7672837 ]]\n\n ...\n\n [[ 0.65688705]\n  [ 0.69001895]\n  [ 0.714802  ]\n  ...\n  [ 0.7784925 ]\n  [ 0.7170294 ]\n  [ 0.6960937 ]]\n\n [[ 0.64586693]\n  [ 0.613016  ]\n  [ 0.6417431 ]\n  ...\n  [ 0.6038925 ]\n  [ 0.6130096 ]\n  [ 0.62869287]]\n\n [[ 0.6742355 ]\n  [ 0.69950056]\n  [ 0.72476554]\n  ...\n  [ 0.6809257 ]\n  [ 0.61272097]\n  [ 0.65019745]]]", "probas": "[[[8.43467236e-01 1.56419143e-01 4.98513218e-05 6.37506018e-05]\n  [8.33309889e-01 1.66614771e-01 3.32998243e-05 4.22678568e-05]\n  [3.44055456e-06 1.78065240e-09 3.65552366e-01 6.34444416e-01]\n  ...\n  [8.02003682e-01 1.97954863e-01 1.88967588e-05 2.26588163e-05]\n  [8.35011482e-01 1.64889500e-01 4.33801179e-05 5.54808430e-05]\n  [8.15085649e-01 1.84864387e-01 2.20963630e-05 2.76948103e-05]]\n\n [[8.53431702e-01 1.46505937e-01 3.00307966e-05 3.22580345e-05]\n  [8.41403663e-01 1.58554837e-01 2.01639341e-05 2.15835953e-05]\n  [5.05021262e-06 2.22133489e-09 4.40526932e-01 5.59467912e-01]\n  ...\n  [8.07506442e-01 1.92473158e-01 1.01731848e-05 1.02111899e-05]\n  [8.43242049e-01 1.56702757e-01 2.67017167e-05 2.85987189e-05]\n  [8.25387537e-01 1.74587205e-01 1.24010730e-05 1.28436877e-05]]\n\n [[8.67981911e-01 1.31978795e-01 2.15574473e-05 1.79802410e-05]\n  [8.56475830e-01 1.43498451e-01 1.41960045e-05 1.17799054e-05]\n  [9.34795662e-06 3.60454400e-09 5.16423464e-01 4.83567268e-01]\n  ...\n  [8.21364105e-01 1.78624257e-01 6.64040590e-06 5.09206984e-06]\n  [8.58140469e-01 1.41826004e-01 1.82694512e-05 1.51876793e-05]\n  [8.44429791e-01 1.55555367e-01 8.23666505e-06 6.41535780e-06]]\n\n ...\n\n [[9.99881744e-01 1.18151263e-04 1.62096356e-15 4.45971615e-18]\n  [9.99630034e-01 3.69123300e-04 3.96110705e-12 1.03901127e-14]\n  [1.93743210e-04 3.38669233e-05 5.26071787e-01 4.73700494e-01]\n  ...\n  [1.02319401e-02 9.89768267e-01 3.67164160e-10 2.89302360e-10]\n  [9.99912262e-01 8.86169655e-05 9.54300454e-14 2.33843747e-16]\n  [9.99860704e-01 1.39507421e-04 3.60094252e-13 7.21576515e-16]]\n\n [[9.99881744e-01 1.18151263e-04 1.62096356e-15 4.45971615e-18]\n  [9.99630034e-01 3.69123300e-04 3.96110705e-12 1.03901127e-14]\n  [1.93743210e-04 3.38669233e-05 5.26071787e-01 4.73700494e-01]\n  ...\n  [1.02319401e-02 9.89768267e-01 3.67164160e-10 2.89302360e-10]\n  [9.99912262e-01 8.86169655e-05 9.54300454e-14 2.33843747e-16]\n  [9.99860704e-01 1.39507421e-04 3.60094252e-13 7.21576515e-16]]\n\n [[9.99881744e-01 1.18151263e-04 1.62096356e-15 4.45971615e-18]\n  [9.99630034e-01 3.69123300e-04 3.96110705e-12 1.03901127e-14]\n  [1.93743210e-04 3.38669233e-05 5.26071787e-01 4.73700494e-01]\n  ...\n  [1.02319401e-02 9.89768267e-01 3.67164160e-10 2.89302360e-10]\n  [9.99912262e-01 8.86169655e-05 9.54300454e-14 2.33843747e-16]\n  [9.99860704e-01 1.39507421e-04 3.60094252e-13 7.21576515e-16]]]", "training_iteration": 1, "loss": 0.28983891010284424, "node_ip": "172.17.0.2", "timesteps_since_restore": 0, "time_since_restore": 148.8038294315338, "episodes_total": null, "config": {"drop_probability": 0.5, "dataset": "Trace", "num_layers": 7, "batchsize": 32, "hidden_dims": 25, "switch_epoch": 9999, "earliness_factor": 1, "workers": 2, "fold": 0, "epochs": 30, "learning_rate": 0.1, "shapelet_width_increment": 10}, "confusion_matrix": "[[5. 0. 0. 0.]\n [0. 5. 0. 0.]\n [0. 0. 1. 0.]\n [0. 0. 0. 4.]]", "weights": "[[0.00659179 0.00658298 0.00645249 ... 0.00122788 0.00122382 0.        ]\n [0.00496931 0.00497207 0.00488095 ... 0.00119151 0.00118768 0.        ]\n [0.00368984 0.00368384 0.00374606 ... 0.00126813 0.00126379 0.        ]\n ...\n [0.00451025 0.00451738 0.00443372 ... 0.00128446 0.00128001 0.        ]\n [0.00584255 0.0058413  0.0057264  ... 0.00119826 0.0011944  0.        ]\n [0.00529963 0.0052995  0.00518944 ... 0.00120508 0.00120117 0.        ]]"}

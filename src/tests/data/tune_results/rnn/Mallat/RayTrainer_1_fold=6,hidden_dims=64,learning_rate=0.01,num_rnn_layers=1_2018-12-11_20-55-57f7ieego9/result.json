{"time_total_s": 2.3424413204193115, "hostname": "e9379f55ba79", "time_this_iter_s": 2.3424413204193115, "experiment_id": "0902a19a136a489999e16e40b7e7dc5b", "timesteps_total": null, "timesteps_since_restore": 0, "training_iteration": 1, "config": {"workers": 2, "dataset": "Mallat", "num_rnn_layers": 1, "hidden_dims": 64, "learning_rate": 0.01, "dropout": 0.3, "epochs": 99999, "earliness_factor": 1, "switch_epoch": 9999, "batchsize": 96, "fold": 6}, "loss": 2.108794927597046, "timestamp": 1544558204, "confusion_matrix": "[[0. 0. 0. 2. 0. 0. 0. 0.]\n [0. 0. 0. 4. 0. 0. 0. 0.]\n [0. 0. 0. 1. 0. 0. 0. 0.]\n [0. 0. 0. 1. 0. 0. 0. 0.]\n [0. 0. 0. 1. 0. 0. 0. 0.]\n [0. 0. 0. 1. 0. 0. 0. 0.]\n [0. 0. 0. 0. 0. 0. 0. 0.]\n [0. 0. 0. 1. 0. 0. 0. 0.]]", "date": "2018-12-11_20-56-44", "targets": "[[5 5 5 ... 5 5 5]\n [7 7 7 ... 7 7 7]\n [1 1 1 ... 1 1 1]\n ...\n [2 2 2 ... 2 2 2]\n [0 0 0 ... 0 0 0]\n [3 3 3 ... 3 3 3]]", "episodes_total": null, "done": false, "iterations_since_restore": 1, "weights": "[[5.3750678e-05 5.3770251e-05 5.3750897e-05 ... 5.0881044e-05\n  5.0876610e-05 9.4647235e-01]\n [5.3839485e-05 5.3878804e-05 5.3858232e-05 ... 5.0979681e-05\n  5.0979121e-05 9.4647843e-01]\n [5.3811458e-05 5.3847056e-05 5.3829892e-05 ... 5.0897324e-05\n  5.0894345e-05 9.4647819e-01]\n ...\n [5.3924723e-05 5.3988810e-05 5.3974465e-05 ... 5.0864666e-05\n  5.0857660e-05 9.4647282e-01]\n [5.3849188e-05 5.3895044e-05 5.3879758e-05 ... 5.0962957e-05\n  5.0964300e-05 9.4647568e-01]\n [5.3848471e-05 5.3897715e-05 5.3886743e-05 ... 5.0956329e-05\n  5.0956260e-05 9.4647527e-01]]", "time_since_restore": 2.3424413204193115, "node_ip": "172.17.0.2", "probas": "[[[0.12325803 0.12096541 0.11385611 ... 0.1164877  0.14349718 0.12763947]\n  [0.1231353  0.12085081 0.11394338 ... 0.11637258 0.1439561  0.12785108]\n  [0.12317221 0.12088538 0.11391551 ... 0.11640982 0.14381461 0.12778853]\n  ...\n  [0.12303171 0.12075309 0.11402973 ... 0.11625511 0.14437054 0.12802142]\n  [0.12312289 0.12083913 0.11395311 ... 0.11635954 0.14400443 0.12787198]\n  [0.12312379 0.12083997 0.11395244 ... 0.11636049 0.14400096 0.12787047]]\n\n [[0.12320299 0.12075622 0.11388138 ... 0.11665598 0.14384864 0.1281561 ]\n  [0.12305879 0.12053614 0.1140037  ... 0.11661708 0.14447795 0.12859392]\n  [0.12309829 0.12059949 0.11396664 ... 0.11662781 0.14429843 0.12847027]\n  ...\n  [0.12293668 0.12034132 0.11413643 ... 0.11655937 0.1450539  0.12895148]\n  [0.12303966 0.12050856 0.11402246 ... 0.11660635 0.14456306 0.12864493]\n  [0.12303665 0.12050603 0.11402529 ... 0.11660212 0.1445747  0.12864842]]\n\n [[0.12324958 0.12060277 0.11389295 ... 0.11686719 0.14397304 0.12848215]\n  [0.12313037 0.12030531 0.11403834 ... 0.11693389 0.14466456 0.12905048]\n  [0.12315824 0.12038571 0.11399735 ... 0.11691128 0.14448395 0.12890126]\n  ...\n  [0.12302728 0.12003556 0.11420554 ... 0.11696724 0.14531621 0.12951425]\n  [0.12310854 0.12026031 0.11406673 ... 0.1169321  0.14478195 0.1291296 ]\n  [0.12310097 0.12025054 0.11407503 ... 0.11692552 0.14481473 0.12914556]]\n\n ...\n\n [[0.12342258 0.11989599 0.11422673 ... 0.11759254 0.14498119 0.12878105]\n  [0.12333596 0.11955365 0.11442718 ... 0.1178118  0.14582402 0.12910938]\n  [0.12340749 0.1198486  0.11425347 ... 0.1176175  0.14509769 0.1288443 ]\n  ...\n  [0.12344009 0.11990985 0.11421742 ... 0.11760275 0.14493142 0.12871094]\n  [0.12335025 0.11964498 0.11437432 ... 0.11773536 0.14560176 0.12907325]\n  [0.12335569 0.1196431  0.11437329 ... 0.11774746 0.14560018 0.12904629]]\n\n [[0.12342397 0.11990479 0.11422221 ... 0.11758564 0.14496182 0.12877358]\n  [0.12333398 0.11954328 0.11443334 ... 0.11782002 0.14585006 0.12911403]\n  [0.12340758 0.11985034 0.1142526  ... 0.1176157  0.14509413 0.12884314]\n  ...\n  [0.12344372 0.11993432 0.114205   ... 0.11758285 0.14487763 0.12869127]\n  [0.12334692 0.1196269  0.11438498 ... 0.11774915 0.14564574 0.12908408]\n  [0.12335336 0.11963229 0.11437974 ... 0.11775507 0.145627   0.12905331]]\n\n [[0.12342517 0.1199132  0.11421785 ... 0.11757886 0.14494346 0.12876672]\n  [0.12333211 0.11953346 0.11443923 ... 0.11782781 0.14587493 0.12911831]\n  [0.12340755 0.1198518  0.11425192 ... 0.11761405 0.14509135 0.1288425 ]\n  ...\n  [0.12344687 0.11995754 0.11419334 ... 0.11756376 0.1448274  0.1286731 ]\n  [0.12334357 0.11960933 0.11439542 ... 0.11776245 0.14568883 0.1290943 ]\n  [0.12335092 0.1196214  0.11438629 ... 0.11776257 0.14565425 0.12906054]]]", "accuracy": 0.09090909090909091, "pid": 7051, "inputs": "[[[-0.6441754 ]\n  [-0.6316425 ]\n  [-0.62136537]\n  ...\n  [-0.8751152 ]\n  [-0.86900634]\n  [-0.86335516]]\n\n [[-0.960383  ]\n  [-0.9472135 ]\n  [-0.9349204 ]\n  ...\n  [-1.1757457 ]\n  [-1.1830101 ]\n  [-1.1899081 ]]\n\n [[-0.8636094 ]\n  [-0.8601534 ]\n  [-0.85754985]\n  ...\n  [-0.9232365 ]\n  [-0.9223625 ]\n  [-0.9218354 ]]\n\n ...\n\n [[-1.240437  ]\n  [-1.2371773 ]\n  [-1.234423  ]\n  ...\n  [-0.8358586 ]\n  [-0.81954443]\n  [-0.8044844 ]]\n\n [[-0.99330217]\n  [-0.9936384 ]\n  [-0.994552  ]\n  ...\n  [-1.1170374 ]\n  [-1.130305  ]\n  [-1.1432737 ]]\n\n [[-0.9909409 ]\n  [-1.0027453 ]\n  [-1.0147117 ]\n  ...\n  [-1.1046433 ]\n  [-1.1131419 ]\n  [-1.1218793 ]]]"}
{"time_total_s": 4.6080405712127686, "hostname": "e9379f55ba79", "time_this_iter_s": 2.265599250793457, "experiment_id": "0902a19a136a489999e16e40b7e7dc5b", "timesteps_total": null, "timesteps_since_restore": 0, "training_iteration": 2, "config": {"workers": 2, "dataset": "Mallat", "num_rnn_layers": 1, "hidden_dims": 64, "learning_rate": 0.01, "dropout": 0.3, "epochs": 99999, "earliness_factor": 1, "switch_epoch": 9999, "batchsize": 96, "fold": 6}, "loss": 2.2038512229919434, "timestamp": 1544558206, "confusion_matrix": "[[0. 0. 0. 2. 0. 0. 0. 0.]\n [0. 0. 0. 4. 0. 0. 0. 0.]\n [0. 0. 0. 1. 0. 0. 0. 0.]\n [0. 0. 0. 1. 0. 0. 0. 0.]\n [0. 0. 0. 1. 0. 0. 0. 0.]\n [0. 0. 0. 1. 0. 0. 0. 0.]\n [0. 0. 0. 0. 0. 0. 0. 0.]\n [0. 0. 0. 1. 0. 0. 0. 0.]]", "date": "2018-12-11_20-56-46", "targets": "[[5 5 5 ... 5 5 5]\n [7 7 7 ... 7 7 7]\n [1 1 1 ... 1 1 1]\n ...\n [2 2 2 ... 2 2 2]\n [0 0 0 ... 0 0 0]\n [3 3 3 ... 3 3 3]]", "episodes_total": null, "done": false, "iterations_since_restore": 2, "weights": "[[5.3304142e-05 5.3311720e-05 5.3294192e-05 ... 5.0609357e-05\n  5.0603659e-05 9.4677961e-01]\n [5.3407126e-05 5.3438609e-05 5.3429176e-05 ... 5.0770628e-05\n  5.0772789e-05 9.4678122e-01]\n [5.3374239e-05 5.3400712e-05 5.3392254e-05 ... 5.0631381e-05\n  5.0628241e-05 9.4677621e-01]\n ...\n [5.3508931e-05 5.3574742e-05 5.3585045e-05 ... 5.0593779e-05\n  5.0583312e-05 9.4677711e-01]\n [5.3418535e-05 5.3458385e-05 5.3457108e-05 ... 5.0731134e-05\n  5.0736442e-05 9.4677049e-01]\n [5.3417716e-05 5.3461750e-05 5.3466083e-05 ... 5.0726816e-05\n  5.0729133e-05 9.4677484e-01]]", "time_since_restore": 4.6080405712127686, "node_ip": "172.17.0.2", "probas": "[[[0.10782672 0.10517017 0.11233824 ... 0.10800152 0.17288706 0.12667121]\n  [0.10770827 0.10505443 0.11263712 ... 0.10773487 0.1731774  0.1269313 ]\n  [0.10774404 0.10509046 0.11254453 ... 0.10781807 0.17308782 0.12685339]\n  ...\n  [0.10760675 0.10494681 0.11291005 ... 0.10748649 0.17344032 0.12714797]\n  [0.10769617 0.10504204 0.1126688  ... 0.10770626 0.173208   0.1269574 ]\n  [0.10769702 0.10504291 0.11266652 ... 0.10770832 0.17320581 0.12695552]]\n\n [[0.10797852 0.10516014 0.11253289 ... 0.10807199 0.17262559 0.12708113]\n  [0.10792504 0.10501277 0.11293428 ... 0.10786346 0.17274506 0.12752879]\n  [0.10793811 0.10505611 0.11281936 ... 0.10791931 0.17271788 0.12740263]\n  ...\n  [0.10787166 0.10486003 0.1133074  ... 0.1076743  0.17284793 0.12790677]\n  [0.10791439 0.10499026 0.1129896  ... 0.10783108 0.17276725 0.1275841 ]\n  [0.10791061 0.10498644 0.11299752 ... 0.10782339 0.17277549 0.12758973]]\n\n [[0.10826582 0.10524351 0.11257757 ... 0.10827067 0.17217402 0.12717642]\n  [0.10831253 0.10511264 0.1129828  ... 0.10821512 0.17204483 0.1276498 ]\n  [0.10829583 0.10514703 0.11287937 ... 0.10821602 0.17209515 0.12753028]\n  ...\n  [0.10831808 0.10495777 0.11335721 ... 0.10818942 0.17193499 0.12804623]\n  [0.10830671 0.105083   0.11305325 ... 0.10819533 0.17204319 0.1277239 ]\n  [0.10829926 0.10507233 0.11307427 ... 0.10818183 0.17205471 0.12774372]]\n\n ...\n\n [[0.10887417 0.10537128 0.11279035 ... 0.10996324 0.1724965  0.12593715]\n  [0.1084802  0.10520054 0.11293326 ... 0.11066    0.17312708 0.12582517]\n  [0.10883164 0.10535304 0.11281713 ... 0.11002576 0.17252392 0.12595528]\n  ...\n  [0.10888354 0.10536631 0.11277427 ... 0.11003336 0.17266898 0.12582393]\n  [0.10861825 0.10526123 0.11291374 ... 0.11037459 0.17276081 0.12595862]\n  [0.10860574 0.10525307 0.11290695 ... 0.11043345 0.1728824  0.12589578]]\n\n [[0.10888152 0.10537466 0.11278674 ... 0.10994326 0.17247811 0.12594384]\n  [0.1084635  0.10519344 0.11293555 ... 0.11069123 0.17316724 0.12581177]\n  [0.10883309 0.10535338 0.11281681 ... 0.11002091 0.17252026 0.12595753]\n  ...\n  [0.10890517 0.10537606 0.11276429 ... 0.10997548 0.17260943 0.12584579]\n  [0.10859409 0.10525081 0.11291888 ... 0.11042342 0.17281531 0.12594005]\n  [0.10859091 0.10524645 0.11291053 ... 0.11046121 0.17291492 0.12588626]]\n\n [[0.10888835 0.10537776 0.11278333 ... 0.10992365 0.17245983 0.12595086]\n  [0.10844728 0.10518645 0.11293762 ... 0.11072102 0.17320634 0.1257988 ]\n  [0.10883426 0.10535365 0.11281665 ... 0.11001637 0.17251654 0.12596008]\n  ...\n  [0.10892431 0.10538505 0.11275454 ... 0.10992031 0.17255248 0.12586762]\n  [0.10856972 0.10524023 0.11292376 ... 0.11047135 0.17287032 0.12592168]\n  [0.10857573 0.10523952 0.11291422 ... 0.11048885 0.1729477  0.12587705]]]", "accuracy": 0.09090909090909091, "pid": 7051, "inputs": "[[[-0.6441754 ]\n  [-0.6316425 ]\n  [-0.62136537]\n  ...\n  [-0.8751152 ]\n  [-0.86900634]\n  [-0.86335516]]\n\n [[-0.960383  ]\n  [-0.9472135 ]\n  [-0.9349204 ]\n  ...\n  [-1.1757457 ]\n  [-1.1830101 ]\n  [-1.1899081 ]]\n\n [[-0.8636094 ]\n  [-0.8601534 ]\n  [-0.85754985]\n  ...\n  [-0.9232365 ]\n  [-0.9223625 ]\n  [-0.9218354 ]]\n\n ...\n\n [[-1.240437  ]\n  [-1.2371773 ]\n  [-1.234423  ]\n  ...\n  [-0.8358586 ]\n  [-0.81954443]\n  [-0.8044844 ]]\n\n [[-0.99330217]\n  [-0.9936384 ]\n  [-0.994552  ]\n  ...\n  [-1.1170374 ]\n  [-1.130305  ]\n  [-1.1432737 ]]\n\n [[-0.9909409 ]\n  [-1.0027453 ]\n  [-1.0147117 ]\n  ...\n  [-1.1046433 ]\n  [-1.1131419 ]\n  [-1.1218793 ]]]"}
{"time_total_s": 6.842620849609375, "hostname": "e9379f55ba79", "time_this_iter_s": 2.2345802783966064, "experiment_id": "0902a19a136a489999e16e40b7e7dc5b", "timesteps_total": null, "timesteps_since_restore": 0, "training_iteration": 3, "config": {"workers": 2, "dataset": "Mallat", "num_rnn_layers": 1, "hidden_dims": 64, "learning_rate": 0.01, "dropout": 0.3, "epochs": 99999, "earliness_factor": 1, "switch_epoch": 9999, "batchsize": 96, "fold": 6}, "loss": 2.392554998397827, "timestamp": 1544558208, "confusion_matrix": "[[0. 0. 0. 2. 0. 0. 0. 0.]\n [0. 0. 0. 4. 0. 0. 0. 0.]\n [0. 0. 0. 1. 0. 0. 0. 0.]\n [0. 0. 0. 1. 0. 0. 0. 0.]\n [0. 0. 0. 1. 0. 0. 0. 0.]\n [0. 0. 0. 1. 0. 0. 0. 0.]\n [0. 0. 0. 0. 0. 0. 0. 0.]\n [0. 0. 0. 1. 0. 0. 0. 0.]]", "date": "2018-12-11_20-56-48", "targets": "[[5 5 5 ... 5 5 5]\n [7 7 7 ... 7 7 7]\n [1 1 1 ... 1 1 1]\n ...\n [2 2 2 ... 2 2 2]\n [0 0 0 ... 0 0 0]\n [3 3 3 ... 3 3 3]]", "episodes_total": null, "done": false, "iterations_since_restore": 3, "weights": "[[5.3188523e-05 5.3213593e-05 5.3253098e-05 ... 5.1100105e-05\n  5.1092484e-05 9.4791746e-01]\n [5.3309428e-05 5.3368083e-05 5.3432810e-05 ... 5.1348732e-05\n  5.1356434e-05 9.4778645e-01]\n [5.3270553e-05 5.3321844e-05 5.3383610e-05 ... 5.1115516e-05\n  5.1111787e-05 9.4766617e-01]\n ...\n [5.3430816e-05 5.3533837e-05 5.3629483e-05 ... 5.1088435e-05\n  5.1071947e-05 9.4786716e-01]\n [5.3323009e-05 5.3392007e-05 5.3467262e-05 ... 5.1256451e-05\n  5.1268591e-05 9.4762379e-01]\n [5.3321986e-05 5.3395976e-05 5.3477561e-05 ... 5.1265473e-05\n  5.1271938e-05 9.4772363e-01]]", "time_since_restore": 6.842620849609375, "node_ip": "172.17.0.2", "probas": "[[[0.0834545  0.08363622 0.10950803 ... 0.10402986 0.21335873 0.12531167]\n  [0.08333584 0.08354302 0.11001272 ... 0.10376024 0.21376264 0.12547632]\n  [0.08337204 0.08357351 0.10985758 ... 0.10384503 0.21363886 0.12542702]\n  ...\n  [0.08323138 0.08344489 0.11046442 ... 0.10350382 0.21412241 0.1256135 ]\n  [0.08332352 0.08353225 0.1100656  ... 0.10373092 0.21380483 0.12549286]\n  [0.0833244  0.08353303 0.1100618  ... 0.10373303 0.21380177 0.1254917 ]]\n\n [[0.0836684  0.0837625  0.10985173 ... 0.10428341 0.21281718 0.12531376]\n  [0.0836102  0.08367141 0.11049829 ... 0.10418172 0.21290787 0.12546578]\n  [0.08362712 0.08370122 0.11031689 ... 0.10420442 0.21289177 0.12542684]\n  ...\n  [0.0835296  0.08354026 0.11106942 ... 0.10409196 0.21299681 0.12558289]\n  [0.08359674 0.08365265 0.11058497 ... 0.10416105 0.21293122 0.12548691]\n  [0.0835925  0.08364838 0.11059758 ... 0.10415273 0.21294284 0.1254916 ]]\n\n [[0.08393944 0.08391049 0.10984187 ... 0.10466017 0.21203597 0.1248759 ]\n  [0.08387548 0.08382186 0.11040036 ... 0.10485205 0.21185142 0.1247552 ]\n  [0.0838991  0.08385039 0.11026762 ... 0.10477846 0.21190977 0.12480709]\n  ...\n  [0.08370394 0.08365195 0.11086189 ... 0.10508001 0.21181525 0.12459641]\n  [0.08384747 0.0837926  0.11049602 ... 0.10486773 0.21185872 0.12474878]\n  [0.08383652 0.08378141 0.1105273  ... 0.1048586  0.21187617 0.1247583 ]]\n\n ...\n\n [[0.08037011 0.08137275 0.10840401 ... 0.1075711  0.2201217  0.11900334]\n  [0.07831724 0.08028902 0.10802132 ... 0.10878982 0.22451043 0.11717496]\n  [0.0801874  0.08129341 0.10839339 ... 0.10770064 0.22045335 0.1188421 ]\n  ...\n  [0.08010579 0.08115884 0.10829084 ... 0.10764937 0.2209364  0.11872584]\n  [0.07917785 0.0807963  0.10824928 ... 0.10835104 0.22246712 0.11795101]\n  [0.07897788 0.08065522 0.10817606 ... 0.10842559 0.22303101 0.11775937]]\n\n [[0.08042993 0.08140643 0.10841659 ... 0.10753641 0.2199862  0.11906222]\n  [0.07822404 0.08023509 0.10799683 ... 0.10883734 0.22472894 0.11709243]\n  [0.08020038 0.08130062 0.1083968  ... 0.10769289 0.2204239  0.11885586]\n  ...\n  [0.08028305 0.0812593  0.10832968 ... 0.10755038 0.22052777 0.11890081]\n  [0.07903336 0.08071347 0.10821459 ... 0.10842927 0.22279893 0.11782056]\n  [0.07889383 0.08060734 0.10815658 ... 0.10847058 0.22322322 0.11768499]]\n\n [[0.08048858 0.0814398  0.10842916 ... 0.10750259 0.21985248 0.11912043]\n  [0.07813452 0.08018317 0.10797309 ... 0.10888255 0.22493917 0.11701348]\n  [0.08021256 0.08130764 0.10840029 ... 0.1076859  0.22039542 0.11886898]\n  ...\n  [0.08045314 0.08135705 0.10836687 ... 0.10745572 0.2201328  0.11907034]\n  [0.07889092 0.08063167 0.10818011 ... 0.1085056  0.22312692 0.11769293]\n  [0.07880975 0.08055956 0.1081373  ... 0.10851561 0.22341527 0.11761122]]]", "accuracy": 0.09090909090909091, "pid": 7051, "inputs": "[[[-0.6441754 ]\n  [-0.6316425 ]\n  [-0.62136537]\n  ...\n  [-0.8751152 ]\n  [-0.86900634]\n  [-0.86335516]]\n\n [[-0.960383  ]\n  [-0.9472135 ]\n  [-0.9349204 ]\n  ...\n  [-1.1757457 ]\n  [-1.1830101 ]\n  [-1.1899081 ]]\n\n [[-0.8636094 ]\n  [-0.8601534 ]\n  [-0.85754985]\n  ...\n  [-0.9232365 ]\n  [-0.9223625 ]\n  [-0.9218354 ]]\n\n ...\n\n [[-1.240437  ]\n  [-1.2371773 ]\n  [-1.234423  ]\n  ...\n  [-0.8358586 ]\n  [-0.81954443]\n  [-0.8044844 ]]\n\n [[-0.99330217]\n  [-0.9936384 ]\n  [-0.994552  ]\n  ...\n  [-1.1170374 ]\n  [-1.130305  ]\n  [-1.1432737 ]]\n\n [[-0.9909409 ]\n  [-1.0027453 ]\n  [-1.0147117 ]\n  ...\n  [-1.1046433 ]\n  [-1.1131419 ]\n  [-1.1218793 ]]]"}
{"time_total_s": 9.434302568435669, "hostname": "e9379f55ba79", "time_this_iter_s": 2.591681718826294, "experiment_id": "0902a19a136a489999e16e40b7e7dc5b", "timesteps_total": null, "timesteps_since_restore": 0, "training_iteration": 4, "config": {"workers": 2, "dataset": "Mallat", "num_rnn_layers": 1, "hidden_dims": 64, "learning_rate": 0.01, "dropout": 0.3, "epochs": 99999, "earliness_factor": 1, "switch_epoch": 9999, "batchsize": 96, "fold": 6}, "loss": 2.474125862121582, "timestamp": 1544558211, "confusion_matrix": "[[0. 0. 0. 2. 0. 0. 0. 0.]\n [0. 0. 0. 4. 0. 0. 0. 0.]\n [0. 0. 0. 1. 0. 0. 0. 0.]\n [0. 0. 0. 1. 0. 0. 0. 0.]\n [0. 0. 0. 1. 0. 0. 0. 0.]\n [0. 0. 0. 1. 0. 0. 0. 0.]\n [0. 0. 0. 0. 0. 0. 0. 0.]\n [0. 0. 0. 0. 0. 0. 1. 0.]]", "date": "2018-12-11_20-56-51", "targets": "[[5 5 5 ... 5 5 5]\n [7 7 7 ... 7 7 7]\n [1 1 1 ... 1 1 1]\n ...\n [2 2 2 ... 2 2 2]\n [0 0 0 ... 0 0 0]\n [3 3 3 ... 3 3 3]]", "episodes_total": null, "done": false, "iterations_since_restore": 4, "weights": "[[5.4302516e-05 5.4311062e-05 5.4357646e-05 ... 5.1790077e-05\n  5.1784184e-05 9.4763416e-01]\n [5.4441167e-05 5.4481930e-05 5.4552991e-05 ... 5.1984403e-05\n  5.1989387e-05 9.4722033e-01]\n [5.4396172e-05 5.4430213e-05 5.4499225e-05 ... 5.1781764e-05\n  5.1778337e-05 9.4698071e-01]\n ...\n [5.4584019e-05 5.4672357e-05 5.4773787e-05 ... 5.1752340e-05\n  5.1741572e-05 9.4744337e-01]\n [5.4457003e-05 5.4509313e-05 5.4591605e-05 ... 5.1911917e-05\n  5.1920160e-05 9.4693393e-01]\n [5.4455857e-05 5.4514101e-05 5.4603526e-05 ... 5.1913055e-05\n  5.1917192e-05 9.4711548e-01]]", "time_since_restore": 9.434302568435669, "node_ip": "172.17.0.2", "probas": "[[[0.07595834 0.07652714 0.1156064  ... 0.11050769 0.2190894  0.13587281]\n  [0.07570447 0.0764017  0.11644327 ... 0.11034465 0.21975487 0.1361775 ]\n  [0.07578098 0.07644289 0.1161865  ... 0.11039825 0.21955277 0.13608345]\n  ...\n  [0.075489   0.07626878 0.11718884 ... 0.1101717  0.22033337 0.13645372]\n  [0.0756787  0.07638714 0.11653072 ... 0.11032568 0.21982335 0.13620967]\n  [0.07568054 0.0763882  0.11652444 ... 0.11032705 0.21981843 0.13620736]]\n\n [[0.07599606 0.07670773 0.11620207 ... 0.11121795 0.21883656 0.13591556]\n  [0.07571781 0.07659002 0.11727404 ... 0.11148392 0.21931249 0.13628158]\n  [0.07579708 0.0766288  0.11697423 ... 0.11139668 0.2191876  0.13617721]\n  ...\n  [0.07544822 0.07641771 0.11821164 ... 0.11173292 0.21973586 0.13663591]\n  [0.07567706 0.07656536 0.11741658 ... 0.1115073  0.21938428 0.136336  ]\n  [0.07567007 0.07655966 0.11743702 ... 0.11150046 0.21940103 0.13634571]]\n\n [[0.07612122 0.07689746 0.11618587 ... 0.11198683 0.21850775 0.13539965]\n  [0.07571691 0.07677478 0.11712381 ... 0.11285117 0.21905647 0.13550252]\n  [0.07583541 0.07681511 0.11689948 ... 0.11258137 0.21890415 0.13549073]\n  ...\n  [0.0752194  0.0765388  0.11790203 ... 0.1137588  0.21974558 0.13562748]\n  [0.07563695 0.07673529 0.11728298 ... 0.11296762 0.21917325 0.13554493]\n  [0.07561557 0.07672077 0.11733397 ... 0.11297525 0.21920949 0.13557002]]\n\n ...\n\n [[0.07265809 0.07420933 0.11661808 ... 0.11651759 0.22966148 0.13338287]\n  [0.0705039  0.0729691  0.11714382 ... 0.11901551 0.23456444 0.13285728]\n  [0.07240932 0.07408495 0.11669821 ... 0.11681565 0.23021153 0.13331753]\n  ...\n  [0.07261688 0.07411472 0.11661293 ... 0.11653034 0.22989686 0.13338457]\n  [0.07121472 0.07343455 0.11700483 ... 0.11822311 0.23287651 0.13301735]\n  [0.07113637 0.07335576 0.11701892 ... 0.11829453 0.23312177 0.1330044 ]]\n\n [[0.07271412 0.07424324 0.11660337 ... 0.11645282 0.22952347 0.1334001 ]\n  [0.0704235  0.0729173  0.11715884 ... 0.11910529 0.2347506  0.13283966]\n  [0.07242218 0.07409302 0.11669604 ... 0.11680101 0.23017904 0.13332266]\n  ...\n  [0.07277783 0.07421377 0.11656976 ... 0.11634689 0.2294975  0.13343425]\n  [0.07108369 0.07335155 0.1170322  ... 0.11837073 0.23318541 0.13298734]\n  [0.07105988 0.07330786 0.11703611 ... 0.11838075 0.23329979 0.13298838]]\n\n [[0.07276841 0.07427652 0.11658923 ... 0.1163904  0.22938849 0.13341695]\n  [0.07034694 0.0728679  0.11717312 ... 0.11919078 0.23492733 0.13282324]\n  [0.07243358 0.07410055 0.11669429 ... 0.11678828 0.23014939 0.13332726]\n  ...\n  [0.07292997 0.07430851 0.1165278  ... 0.11617368 0.22911525 0.13348122]\n  [0.0709556  0.07327028 0.11705871 ... 0.11851492 0.23348588 0.13295884]\n  [0.07098333 0.07326014 0.11705335 ... 0.11846732 0.23347665 0.13297276]]]", "accuracy": 0.09090909090909091, "pid": 7051, "inputs": "[[[-0.6441754 ]\n  [-0.6316425 ]\n  [-0.62136537]\n  ...\n  [-0.8751152 ]\n  [-0.86900634]\n  [-0.86335516]]\n\n [[-0.960383  ]\n  [-0.9472135 ]\n  [-0.9349204 ]\n  ...\n  [-1.1757457 ]\n  [-1.1830101 ]\n  [-1.1899081 ]]\n\n [[-0.8636094 ]\n  [-0.8601534 ]\n  [-0.85754985]\n  ...\n  [-0.9232365 ]\n  [-0.9223625 ]\n  [-0.9218354 ]]\n\n ...\n\n [[-1.240437  ]\n  [-1.2371773 ]\n  [-1.234423  ]\n  ...\n  [-0.8358586 ]\n  [-0.81954443]\n  [-0.8044844 ]]\n\n [[-0.99330217]\n  [-0.9936384 ]\n  [-0.994552  ]\n  ...\n  [-1.1170374 ]\n  [-1.130305  ]\n  [-1.1432737 ]]\n\n [[-0.9909409 ]\n  [-1.0027453 ]\n  [-1.0147117 ]\n  ...\n  [-1.1046433 ]\n  [-1.1131419 ]\n  [-1.1218793 ]]]"}
{"time_total_s": 11.994787454605103, "hostname": "e9379f55ba79", "time_this_iter_s": 2.5604848861694336, "experiment_id": "0902a19a136a489999e16e40b7e7dc5b", "timesteps_total": null, "timesteps_since_restore": 0, "training_iteration": 5, "config": {"workers": 2, "dataset": "Mallat", "num_rnn_layers": 1, "hidden_dims": 64, "learning_rate": 0.01, "dropout": 0.3, "epochs": 99999, "earliness_factor": 1, "switch_epoch": 9999, "batchsize": 96, "fold": 6}, "loss": 2.4180471897125244, "timestamp": 1544558213, "confusion_matrix": "[[0. 0. 0. 2. 0. 0. 0. 0.]\n [0. 0. 0. 4. 0. 0. 0. 0.]\n [0. 0. 0. 1. 0. 0. 0. 0.]\n [0. 0. 0. 1. 0. 0. 0. 0.]\n [0. 0. 0. 1. 0. 0. 0. 0.]\n [0. 0. 0. 1. 0. 0. 0. 0.]\n [0. 0. 0. 0. 0. 0. 0. 0.]\n [0. 0. 0. 1. 0. 0. 0. 0.]]", "date": "2018-12-11_20-56-53", "targets": "[[5 5 5 ... 5 5 5]\n [7 7 7 ... 7 7 7]\n [1 1 1 ... 1 1 1]\n ...\n [2 2 2 ... 2 2 2]\n [0 0 0 ... 0 0 0]\n [3 3 3 ... 3 3 3]]", "episodes_total": null, "done": false, "iterations_since_restore": 5, "weights": "[[5.6246343e-05 5.6211975e-05 5.6192795e-05 ... 5.2430107e-05\n  5.2428455e-05 9.4675738e-01]\n [5.6419703e-05 5.6407644e-05 5.6378864e-05 ... 5.2519641e-05\n  5.2520983e-05 9.4594961e-01]\n [5.6363126e-05 5.6347966e-05 5.6328463e-05 ... 5.2387852e-05\n  5.2385498e-05 9.4563353e-01]\n ...\n [5.6600933e-05 5.6634923e-05 5.6608988e-05 ... 5.2358817e-05\n  5.2360661e-05 9.4644260e-01]\n [5.6439665e-05 5.6440625e-05 5.6421184e-05 ... 5.2479627e-05\n  5.2481068e-05 9.4554627e-01]\n [5.6438210e-05 5.6446923e-05 5.6436202e-05 ... 5.2469695e-05\n  5.2470343e-05 9.4579941e-01]]", "time_since_restore": 11.994787454605103, "node_ip": "172.17.0.2", "probas": "[[[0.09229667 0.09041425 0.12369587 ... 0.11353784 0.18742894 0.15235044]\n  [0.09180656 0.09012604 0.12478819 ... 0.11349091 0.18781036 0.15282457]\n  [0.09195403 0.09021823 0.12445369 ... 0.1135105  0.18769445 0.1526765 ]\n  ...\n  [0.09139186 0.08983982 0.1257561  ... 0.11340906 0.18814285 0.15326735]\n  [0.09175687 0.09009388 0.12490198 ... 0.11348317 0.18784963 0.15287551]\n  [0.09176043 0.09009618 0.1248938  ... 0.11348374 0.1878468  0.15287185]]\n\n [[0.09200807 0.09057643 0.1242018  ... 0.11481345 0.18690594 0.15221727]\n  [0.0912846  0.09021186 0.12543003 ... 0.11549576 0.1870335  0.15272464]\n  [0.09149459 0.09032586 0.12509282 ... 0.11528461 0.18700147 0.15257744]\n  ...\n  [0.09059884 0.08977217 0.12647955 ... 0.116121   0.18718688 0.15325633]\n  [0.0911862  0.0901497  0.1255949  ... 0.11556794 0.1870615  0.15280627]\n  [0.0911739  0.09013866 0.12562141 ... 0.11556245 0.18707149 0.15282264]]\n\n [[0.0916932  0.09075518 0.12387593 ... 0.1161253  0.18709688 0.15123215]\n  [0.09045042 0.09024355 0.1247724  ... 0.11775783 0.18772513 0.15129583]\n  [0.09081239 0.09040004 0.12457437 ... 0.11726643 0.18752083 0.15129776]\n  ...\n  [0.08909894 0.08954078 0.12547252 ... 0.11941259 0.18857157 0.15148395]\n  [0.09024061 0.09013079 0.12493254 ... 0.11798538 0.18784073 0.15135843]\n  [0.09019551 0.09009835 0.12499133 ... 0.11801057 0.18786177 0.15139922]]\n\n ...\n\n [[0.08303069 0.08502587 0.1254459  ... 0.12253202 0.20439188 0.14765243]\n  [0.07920019 0.0826248  0.1260907  ... 0.12608992 0.20916872 0.14737934]\n  [0.08255848 0.08475487 0.12553221 ... 0.12297752 0.20497125 0.14761022]\n  ...\n  [0.08301133 0.08493962 0.12550284 ... 0.12246975 0.20457087 0.14762063]\n  [0.08038077 0.08343071 0.12587534 ... 0.12502807 0.20765512 0.14745545]\n  [0.08027616 0.08333122 0.12592517 ... 0.12508726 0.20784667 0.1474338 ]]\n\n [[0.08313373 0.08509069 0.1254246  ... 0.12244245 0.20424715 0.14766973]\n  [0.07906785 0.08253484 0.12611298 ... 0.12621173 0.20933132 0.14737394]\n  [0.08258189 0.08477    0.12552838 ... 0.12295767 0.2049364  0.14761566]\n  ...\n  [0.08330425 0.08512522 0.1254384  ... 0.12221829 0.20415828 0.14767116]\n  [0.08015741 0.08328146 0.12591499 ... 0.12522998 0.2079429  0.14744088]\n  [0.08014608 0.08324488 0.12594901 ... 0.1252061  0.20800999 0.14742795]]\n\n [[0.08323365 0.085154   0.12540358 ... 0.12235646 0.20410497 0.14768714]\n  [0.07894233 0.08244935 0.1261341  ... 0.12632754 0.20948413 0.14736946]\n  [0.08260246 0.08478373 0.12552476 ... 0.12294091 0.20490469 0.14762075]\n  ...\n  [0.08358293 0.08530251 0.12537467 ... 0.12198164 0.20375901 0.1477212 ]\n  [0.07994038 0.08313607 0.12595306 ... 0.12542711 0.20821916 0.14742844]\n  [0.08001614 0.08315879 0.12597239 ... 0.12532564 0.20817098 0.14742304]]]", "accuracy": 0.09090909090909091, "pid": 7051, "inputs": "[[[-0.6441754 ]\n  [-0.6316425 ]\n  [-0.62136537]\n  ...\n  [-0.8751152 ]\n  [-0.86900634]\n  [-0.86335516]]\n\n [[-0.960383  ]\n  [-0.9472135 ]\n  [-0.9349204 ]\n  ...\n  [-1.1757457 ]\n  [-1.1830101 ]\n  [-1.1899081 ]]\n\n [[-0.8636094 ]\n  [-0.8601534 ]\n  [-0.85754985]\n  ...\n  [-0.9232365 ]\n  [-0.9223625 ]\n  [-0.9218354 ]]\n\n ...\n\n [[-1.240437  ]\n  [-1.2371773 ]\n  [-1.234423  ]\n  ...\n  [-0.8358586 ]\n  [-0.81954443]\n  [-0.8044844 ]]\n\n [[-0.99330217]\n  [-0.9936384 ]\n  [-0.994552  ]\n  ...\n  [-1.1170374 ]\n  [-1.130305  ]\n  [-1.1432737 ]]\n\n [[-0.9909409 ]\n  [-1.0027453 ]\n  [-1.0147117 ]\n  ...\n  [-1.1046433 ]\n  [-1.1131419 ]\n  [-1.1218793 ]]]"}
{"time_total_s": 14.576343536376953, "hostname": "e9379f55ba79", "time_this_iter_s": 2.5815560817718506, "experiment_id": "0902a19a136a489999e16e40b7e7dc5b", "timesteps_total": null, "timesteps_since_restore": 0, "training_iteration": 6, "config": {"workers": 2, "dataset": "Mallat", "num_rnn_layers": 1, "hidden_dims": 64, "learning_rate": 0.01, "dropout": 0.3, "epochs": 99999, "earliness_factor": 1, "switch_epoch": 9999, "batchsize": 96, "fold": 6}, "loss": 2.4089906215667725, "timestamp": 1544558216, "confusion_matrix": "[[0. 0. 0. 2. 0. 0. 0. 0.]\n [0. 0. 0. 4. 0. 0. 0. 0.]\n [0. 0. 0. 1. 0. 0. 0. 0.]\n [0. 0. 0. 1. 0. 0. 0. 0.]\n [0. 0. 0. 1. 0. 0. 0. 0.]\n [0. 0. 0. 1. 0. 0. 0. 0.]\n [0. 0. 0. 0. 0. 0. 0. 0.]\n [0. 0. 0. 1. 0. 0. 0. 0.]]", "date": "2018-12-11_20-56-56", "targets": "[[5 5 5 ... 5 5 5]\n [7 7 7 ... 7 7 7]\n [1 1 1 ... 1 1 1]\n ...\n [2 2 2 ... 2 2 2]\n [0 0 0 ... 0 0 0]\n [3 3 3 ... 3 3 3]]", "episodes_total": null, "done": false, "iterations_since_restore": 6, "weights": "[[5.7540095e-05 5.7444900e-05 5.7307007e-05 ... 5.2310632e-05\n  5.2309180e-05 9.4607854e-01]\n [5.7766505e-05 5.7682195e-05 5.7485522e-05 ... 5.2564483e-05\n  5.2572341e-05 9.4637895e-01]\n [5.7692403e-05 5.7609410e-05 5.7437970e-05 ... 5.2341671e-05\n  5.2339565e-05 9.4614160e-01]\n ...\n [5.8004476e-05 5.7968151e-05 5.7741796e-05 ... 5.2249765e-05\n  5.2250911e-05 9.4610310e-01]\n [5.7792677e-05 5.7724068e-05 5.7535268e-05 ... 5.2473511e-05\n  5.2481413e-05 9.4585007e-01]\n [5.7790745e-05 5.7732650e-05 5.7555619e-05 ... 5.2465395e-05\n  5.2470696e-05 9.4610703e-01]]", "time_since_restore": 14.576343536376953, "node_ip": "172.17.0.2", "probas": "[[[0.11060541 0.10813233 0.11607973 ... 0.10228945 0.17133409 0.15038852]\n  [0.11008529 0.10761511 0.11749051 ... 0.10216238 0.17145732 0.15090293]\n  [0.11024226 0.10777708 0.11705863 ... 0.10220657 0.17141937 0.15074071]\n  ...\n  [0.10964178 0.1071286  0.11873968 ... 0.10200996 0.17156982 0.1513955 ]\n  [0.11003236 0.10755927 0.11763742 ... 0.10214632 0.17147033 0.15095904]\n  [0.11003614 0.10756329 0.1176269  ... 0.10214749 0.17146939 0.150955  ]]\n\n [[0.11027091 0.10830303 0.11669201 ... 0.10364544 0.1703775  0.1497946 ]\n  [0.10940547 0.10766372 0.11828163 ... 0.10433986 0.17008922 0.15018848]\n  [0.10966325 0.10785705 0.1178436  ... 0.10411932 0.170172   0.15007159]\n  ...\n  [0.10854331 0.10695551 0.11965237 ... 0.10500946 0.16990499 0.15067579]\n  [0.10928588 0.10756148 0.11849582 ... 0.10441367 0.17006634 0.15026574]\n  [0.10927236 0.10754397 0.11853004 ... 0.10440627 0.1700706  0.15028594]]\n\n [[0.10949305 0.10853408 0.11628671 ... 0.10515909 0.17090058 0.14815368]\n  [0.10766778 0.10763752 0.11755594 ... 0.10701632 0.1714029  0.14788537]\n  [0.10821321 0.10790466 0.11726059 ... 0.10644691 0.17121099 0.14797512]\n  ...\n  [0.10566195 0.10649295 0.11861855 ... 0.10897148 0.17217556 0.14790912]\n  [0.10736875 0.10745244 0.11778206 ... 0.10727946 0.1714871  0.14792633]\n  [0.10731229 0.10740114 0.11785989 ... 0.10730729 0.17148949 0.1479728 ]]\n\n ...\n\n [[0.09557512 0.09961795 0.12088887 ... 0.1134553  0.19389994 0.14270642]\n  [0.09043334 0.09601938 0.122388   ... 0.11789921 0.19771945 0.14285716]\n  [0.0949415  0.09920625 0.12107149 ... 0.11398159 0.19439825 0.14269203]\n  ...\n  [0.09550264 0.09949405 0.12102138 ... 0.11346737 0.19413894 0.14265367]\n  [0.09202647 0.09721682 0.1218676  ... 0.11648112 0.19659498 0.14275306]\n  [0.09187111 0.09707124 0.12197506 ... 0.11660081 0.19676064 0.14274018]]\n\n [[0.09571774 0.09971549 0.12084127 ... 0.11334362 0.19376303 0.14272186]\n  [0.09025592 0.09588542 0.12244327 ... 0.11806276 0.19782956 0.14287634]\n  [0.09497408 0.09922879 0.12106184 ... 0.11395665 0.19436474 0.14269708]\n  ...\n  [0.09590963 0.09977385 0.12087925 ... 0.11314908 0.19375275 0.1426982 ]\n  [0.09172606 0.09699547 0.12196184 ... 0.11674301 0.1968201  0.14276797]\n  [0.0916964  0.09694262 0.12203062 ... 0.1167552  0.19688372 0.1427529 ]]\n\n [[0.09585641 0.09981064 0.12079423 ... 0.11323608 0.19362687 0.14273798]\n  [0.0900877  0.09575805 0.12249585 ... 0.11821906 0.19793086 0.14289607]\n  [0.09500279 0.09924907 0.12105278 ... 0.1139351  0.19433351 0.1427019 ]\n  ...\n  [0.09629862 0.10004114 0.12073986 ... 0.11284965 0.19336997 0.14274651]\n  [0.09143467 0.09677976 0.12205297 ... 0.11699995 0.19703096 0.14278646]\n  [0.09152214 0.09681429 0.12208548 ... 0.11691069 0.19700287 0.1427675 ]]]", "accuracy": 0.09090909090909091, "pid": 7051, "inputs": "[[[-0.6441754 ]\n  [-0.6316425 ]\n  [-0.62136537]\n  ...\n  [-0.8751152 ]\n  [-0.86900634]\n  [-0.86335516]]\n\n [[-0.960383  ]\n  [-0.9472135 ]\n  [-0.9349204 ]\n  ...\n  [-1.1757457 ]\n  [-1.1830101 ]\n  [-1.1899081 ]]\n\n [[-0.8636094 ]\n  [-0.8601534 ]\n  [-0.85754985]\n  ...\n  [-0.9232365 ]\n  [-0.9223625 ]\n  [-0.9218354 ]]\n\n ...\n\n [[-1.240437  ]\n  [-1.2371773 ]\n  [-1.234423  ]\n  ...\n  [-0.8358586 ]\n  [-0.81954443]\n  [-0.8044844 ]]\n\n [[-0.99330217]\n  [-0.9936384 ]\n  [-0.994552  ]\n  ...\n  [-1.1170374 ]\n  [-1.130305  ]\n  [-1.1432737 ]]\n\n [[-0.9909409 ]\n  [-1.0027453 ]\n  [-1.0147117 ]\n  ...\n  [-1.1046433 ]\n  [-1.1131419 ]\n  [-1.1218793 ]]]"}
{"time_total_s": 17.130764484405518, "hostname": "e9379f55ba79", "time_this_iter_s": 2.5544209480285645, "experiment_id": "0902a19a136a489999e16e40b7e7dc5b", "timesteps_total": null, "timesteps_since_restore": 0, "training_iteration": 7, "config": {"workers": 2, "dataset": "Mallat", "num_rnn_layers": 1, "hidden_dims": 64, "learning_rate": 0.01, "dropout": 0.3, "epochs": 99999, "earliness_factor": 1, "switch_epoch": 9999, "batchsize": 96, "fold": 6}, "loss": 2.319347858428955, "timestamp": 1544558219, "confusion_matrix": "[[0. 0. 0. 2. 0. 0. 0. 0.]\n [0. 0. 0. 4. 0. 0. 0. 0.]\n [0. 0. 0. 1. 0. 0. 0. 0.]\n [0. 0. 0. 1. 0. 0. 0. 0.]\n [0. 0. 0. 1. 0. 0. 0. 0.]\n [0. 0. 0. 1. 0. 0. 0. 0.]\n [0. 0. 0. 0. 0. 0. 0. 0.]\n [0. 0. 0. 1. 0. 0. 0. 0.]]", "date": "2018-12-11_20-56-59", "targets": "[[5 5 5 ... 5 5 5]\n [7 7 7 ... 7 7 7]\n [1 1 1 ... 1 1 1]\n ...\n [2 2 2 ... 2 2 2]\n [0 0 0 ... 0 0 0]\n [3 3 3 ... 3 3 3]]", "episodes_total": null, "done": false, "iterations_since_restore": 7, "weights": "[[5.7498029e-05 5.7428966e-05 5.7207257e-05 ... 5.1543990e-05\n  5.1541563e-05 9.4388717e-01]\n [5.7863981e-05 5.7846788e-05 5.7548423e-05 ... 5.1885221e-05\n  5.1899297e-05 9.4280279e-01]\n [5.7745576e-05 5.7720219e-05 5.7457022e-05 ... 5.1510626e-05\n  5.1508647e-05 9.4240141e-01]\n ...\n [5.8238256e-05 5.8324174e-05 5.8002523e-05 ... 5.1443454e-05\n  5.1442461e-05 9.4363427e-01]\n [5.7905541e-05 5.7916448e-05 5.7634476e-05 ... 5.1765292e-05\n  5.1781459e-05 9.4250482e-01]\n [5.7902562e-05 5.7929643e-05 5.7667461e-05 ... 5.1750943e-05\n  5.1761777e-05 9.4281346e-01]]", "time_since_restore": 17.130764484405518, "node_ip": "172.17.0.2", "probas": "[[[0.10935725 0.10951124 0.10964346 ... 0.0970177  0.18287943 0.14009386]\n  [0.10920811 0.10897335 0.11134522 ... 0.09655636 0.18298425 0.1406536 ]\n  [0.10925345 0.10913955 0.11082421 ... 0.09670067 0.18295297 0.14047584]\n  ...\n  [0.10907774 0.10848501 0.11285208 ... 0.09612647 0.18307313 0.14119911]\n  [0.10919275 0.10891651 0.11152244 ... 0.09650674 0.1829948  0.14071535]\n  [0.10919385 0.10892059 0.11150971 ... 0.09651031 0.18299402 0.14071089]]\n\n [[0.10975783 0.11010149 0.1103256  ... 0.09820002 0.18188345 0.13911265]\n  [0.10957118 0.10967273 0.11219881 ... 0.0985893  0.18146166 0.13945527]\n  [0.10963803 0.10979825 0.11168444 ... 0.0984431  0.1815884  0.13934934]\n  ...\n  [0.10927057 0.10918143 0.11380514 ... 0.09907031 0.1811129  0.13995974]\n  [0.10953325 0.10959563 0.1124512  ... 0.0986268  0.18141715 0.13953607]\n  [0.10952711 0.10957742 0.11249208 ... 0.09861229 0.18141872 0.13956033]]\n\n [[0.1092848  0.11085309 0.10974617 ... 0.09975158 0.1831405  0.13671555]\n  [0.10816626 0.11039294 0.11116442 ... 0.10154027 0.18379809 0.13614568]\n  [0.10853674 0.11053315 0.11084104 ... 0.10095546 0.18356077 0.13631569]\n  ...\n  [0.10670549 0.10964393 0.11232753 ... 0.10363924 0.18458736 0.13605031]\n  [0.1079698  0.11026488 0.11141854 ... 0.10180026 0.18387488 0.13617468]\n  [0.10793924 0.11022002 0.11150838 ... 0.10181909 0.18386249 0.1362311 ]]\n\n ...\n\n [[0.09795428 0.10456856 0.11291575 ... 0.10745085 0.20944747 0.12792006]\n  [0.09371469 0.10170482 0.11420157 ... 0.11240988 0.21298641 0.12781288]\n  [0.09742458 0.10424422 0.11308613 ... 0.10802063 0.209973   0.12785569]\n  ...\n  [0.09795608 0.10450403 0.11297982 ... 0.10744622 0.20959637 0.12783805]\n  [0.09498114 0.10265236 0.11378897 ... 0.11080999 0.2121052  0.12776065]\n  [0.09488981 0.10255376 0.1138596  ... 0.11092646 0.21221837 0.12772553]]\n\n [[0.09807031 0.10464264 0.11287633 ... 0.10733144 0.20930518 0.12795179]\n  [0.09357312 0.10159669 0.11424699 ... 0.11259741 0.2130629  0.12783109]\n  [0.09745166 0.10426165 0.11307831 ... 0.10799322 0.20993766 0.12786454]\n  ...\n  [0.09828294 0.10471578 0.11286074 ... 0.10710733 0.20919974 0.12792787]\n  [0.09473876 0.10247719 0.11386463 ... 0.1111042  0.21229552 0.12776315]\n  [0.09474967 0.10245181 0.11390514 ... 0.11109979 0.2123188  0.12773284]]\n\n [[0.09818279 0.10471472 0.11283747 ... 0.10721678 0.20916346 0.12798412]\n  [0.09343913 0.10149363 0.11429028 ... 0.11277693 0.21313047 0.12785067]\n  [0.09747536 0.10427729 0.11307112 ... 0.1079697  0.20990525 0.12787288]\n  ...\n  [0.0985941  0.10491664 0.11274458 ... 0.10679098 0.20880364 0.12802245]\n  [0.09450408 0.10230604 0.1139379  ... 0.11139383 0.21246877 0.12777156]\n  [0.09460976 0.10234985 0.11395012 ... 0.11127478 0.21241419 0.12774268]]]", "accuracy": 0.09090909090909091, "pid": 7051, "inputs": "[[[-0.6441754 ]\n  [-0.6316425 ]\n  [-0.62136537]\n  ...\n  [-0.8751152 ]\n  [-0.86900634]\n  [-0.86335516]]\n\n [[-0.960383  ]\n  [-0.9472135 ]\n  [-0.9349204 ]\n  ...\n  [-1.1757457 ]\n  [-1.1830101 ]\n  [-1.1899081 ]]\n\n [[-0.8636094 ]\n  [-0.8601534 ]\n  [-0.85754985]\n  ...\n  [-0.9232365 ]\n  [-0.9223625 ]\n  [-0.9218354 ]]\n\n ...\n\n [[-1.240437  ]\n  [-1.2371773 ]\n  [-1.234423  ]\n  ...\n  [-0.8358586 ]\n  [-0.81954443]\n  [-0.8044844 ]]\n\n [[-0.99330217]\n  [-0.9936384 ]\n  [-0.994552  ]\n  ...\n  [-1.1170374 ]\n  [-1.130305  ]\n  [-1.1432737 ]]\n\n [[-0.9909409 ]\n  [-1.0027453 ]\n  [-1.0147117 ]\n  ...\n  [-1.1046433 ]\n  [-1.1131419 ]\n  [-1.1218793 ]]]"}
{"time_total_s": 19.61923098564148, "hostname": "e9379f55ba79", "time_this_iter_s": 2.488466501235962, "experiment_id": "0902a19a136a489999e16e40b7e7dc5b", "timesteps_total": null, "timesteps_since_restore": 0, "training_iteration": 8, "config": {"workers": 2, "dataset": "Mallat", "num_rnn_layers": 1, "hidden_dims": 64, "learning_rate": 0.01, "dropout": 0.3, "epochs": 99999, "earliness_factor": 1, "switch_epoch": 9999, "batchsize": 96, "fold": 6}, "loss": 2.368631362915039, "timestamp": 1544558221, "confusion_matrix": "[[0. 0. 0. 2. 0. 0. 0. 0.]\n [0. 0. 0. 4. 0. 0. 0. 0.]\n [0. 0. 0. 1. 0. 0. 0. 0.]\n [0. 0. 0. 1. 0. 0. 0. 0.]\n [0. 0. 0. 1. 0. 0. 0. 0.]\n [0. 0. 0. 1. 0. 0. 0. 0.]\n [0. 0. 0. 0. 0. 0. 0. 0.]\n [0. 0. 0. 1. 0. 0. 0. 0.]]", "date": "2018-12-11_20-57-01", "targets": "[[5 5 5 ... 5 5 5]\n [7 7 7 ... 7 7 7]\n [1 1 1 ... 1 1 1]\n ...\n [2 2 2 ... 2 2 2]\n [0 0 0 ... 0 0 0]\n [3 3 3 ... 3 3 3]]", "episodes_total": null, "done": false, "iterations_since_restore": 8, "weights": "[[5.7304744e-05 5.7600155e-05 5.7782458e-05 ... 5.8551988e-05\n  5.8386831e-05 9.4336194e-01]\n [5.7951122e-05 5.8511712e-05 5.8849902e-05 ... 6.3072730e-05\n  6.3392610e-05 9.4240034e-01]\n [5.7744528e-05 5.8238951e-05 5.8554248e-05 ... 5.8411078e-05\n  5.8389531e-05 9.4246668e-01]\n ...\n [5.8591821e-05 5.9472448e-05 6.0043250e-05 ... 6.1014369e-05\n  6.0474616e-05 9.4293380e-01]\n [5.8023117e-05 5.8649075e-05 5.9054528e-05 ... 6.0260889e-05\n  6.0624589e-05 9.4250327e-01]\n [5.8017918e-05 5.8670223e-05 5.9114420e-05 ... 6.1273284e-05\n  6.1517829e-05 9.4243503e-01]]", "time_since_restore": 19.61923098564148, "node_ip": "172.17.0.2", "probas": "[[[0.10433026 0.1010927  0.10909233 ... 0.09567916 0.18567276 0.14424583]\n  [0.10400826 0.10031044 0.11077029 ... 0.09533441 0.18571633 0.14528847]\n  [0.10410898 0.10054953 0.11025497 ... 0.0954411  0.18570305 0.14496344]\n  ...\n  [0.10370536 0.09962008 0.1122687  ... 0.09502506 0.1857578  0.14625691]\n  [0.10397355 0.10022919 0.11094593 ... 0.09529803 0.18572094 0.1454002 ]\n  [0.10397608 0.10023504 0.11093333 ... 0.09530067 0.18572065 0.1453922 ]]\n\n [[0.10489821 0.10163121 0.10917044 ... 0.0978268  0.1836055  0.1441419 ]\n  [0.10445463 0.10087951 0.11073589 ... 0.09904141 0.18255001 0.14543754]\n  [0.10460613 0.10109892 0.11031158 ... 0.09863047 0.18286766 0.14505291]\n  ...\n  [0.10381609 0.10007393 0.1120869  ... 0.10041963 0.18162376 0.14682885]\n  [0.10437168 0.10075754 0.11095516 ... 0.09918682 0.18243214 0.14564176]\n  [0.10435862 0.10073343 0.11099628 ... 0.09917501 0.18243293 0.1456779 ]]\n\n [[0.10464814 0.10264447 0.10820165 ... 0.10058171 0.18377839 0.14201024]\n  [0.10297756 0.10171734 0.1092054  ... 0.10441818 0.18333888 0.14254719]\n  [0.10352702 0.10200099 0.10898977 ... 0.1031934  0.18341671 0.14241132]\n  ...\n  [0.10074018 0.1003319  0.11003359 ... 0.1089121  0.18303233 0.14362496]\n  [0.10266422 0.10149293 0.10940208 ... 0.10500783 0.18325669 0.14276846]\n  [0.10260496 0.10142347 0.10947987 ... 0.1050776  0.18321885 0.14287396]]\n\n ...\n\n [[0.08920608 0.08979145 0.12185246 ... 0.12856811 0.19873148 0.13697915]\n  [0.08233977 0.08208854 0.12545744 ... 0.14586931 0.1900977  0.14433847]\n  [0.08878814 0.08978504 0.12137187 ... 0.12891828 0.1994914  0.13669081]\n  ...\n  [0.08755513 0.08624693 0.12584375 ... 0.13513452 0.19216238 0.14122014]\n  [0.08531489 0.0864145  0.12247974 ... 0.13678633 0.19687693 0.13948469]\n  [0.08457794 0.08491912 0.12396944 ... 0.13962519 0.19409885 0.14129987]]\n\n [[0.08942075 0.09006879 0.12163663 ... 0.1279947  0.19904147 0.1367318 ]\n  [0.08199748 0.08161058 0.1257468  ... 0.14690211 0.18931995 0.14489116]\n  [0.08882355 0.0898215  0.12134951 ... 0.12883747 0.19951344 0.13666983]\n  ...\n  [0.0881918  0.08707847 0.12521029 ... 0.13337657 0.19328025 0.14040196]\n  [0.08485772 0.08580727 0.12286349 ... 0.13807586 0.19606277 0.14010899]\n  [0.08428923 0.08452936 0.12421326 ... 0.14045747 0.19353178 0.14172485]]\n\n [[0.08963044 0.09034236 0.12141836 ... 0.12743323 0.19934371 0.13649048]\n  [0.08166153 0.08114048 0.12602872 ... 0.14792036 0.18854336 0.1454399 ]\n  [0.08885557 0.08985718 0.12132411 ... 0.12876119 0.19953851 0.13664816]\n  ...\n  [0.08881226 0.08790829 0.12454263 ... 0.13164632 0.19438465 0.13959244]\n  [0.08440168 0.08519476 0.12324709 ... 0.1393794  0.19521044 0.14075445]\n  [0.08399562 0.08413281 0.12445708 ... 0.1413075  0.19294566 0.14216287]]]", "accuracy": 0.09090909090909091, "pid": 7051, "inputs": "[[[-0.6441754 ]\n  [-0.6316425 ]\n  [-0.62136537]\n  ...\n  [-0.8751152 ]\n  [-0.86900634]\n  [-0.86335516]]\n\n [[-0.960383  ]\n  [-0.9472135 ]\n  [-0.9349204 ]\n  ...\n  [-1.1757457 ]\n  [-1.1830101 ]\n  [-1.1899081 ]]\n\n [[-0.8636094 ]\n  [-0.8601534 ]\n  [-0.85754985]\n  ...\n  [-0.9232365 ]\n  [-0.9223625 ]\n  [-0.9218354 ]]\n\n ...\n\n [[-1.240437  ]\n  [-1.2371773 ]\n  [-1.234423  ]\n  ...\n  [-0.8358586 ]\n  [-0.81954443]\n  [-0.8044844 ]]\n\n [[-0.99330217]\n  [-0.9936384 ]\n  [-0.994552  ]\n  ...\n  [-1.1170374 ]\n  [-1.130305  ]\n  [-1.1432737 ]]\n\n [[-0.9909409 ]\n  [-1.0027453 ]\n  [-1.0147117 ]\n  ...\n  [-1.1046433 ]\n  [-1.1131419 ]\n  [-1.1218793 ]]]"}
{"time_total_s": 21.75335669517517, "hostname": "e9379f55ba79", "time_this_iter_s": 2.1341257095336914, "experiment_id": "0902a19a136a489999e16e40b7e7dc5b", "timesteps_total": null, "timesteps_since_restore": 0, "training_iteration": 9, "config": {"workers": 2, "dataset": "Mallat", "num_rnn_layers": 1, "hidden_dims": 64, "learning_rate": 0.01, "dropout": 0.3, "epochs": 99999, "earliness_factor": 1, "switch_epoch": 9999, "batchsize": 96, "fold": 6}, "loss": 2.3634042739868164, "timestamp": 1544558223, "confusion_matrix": "[[0. 0. 0. 0. 0. 0. 2. 0.]\n [0. 0. 0. 0. 0. 0. 4. 0.]\n [0. 0. 0. 0. 0. 0. 1. 0.]\n [0. 0. 0. 0. 0. 0. 1. 0.]\n [0. 0. 0. 0. 0. 0. 1. 0.]\n [0. 0. 0. 0. 0. 0. 1. 0.]\n [0. 0. 0. 0. 0. 0. 0. 0.]\n [0. 0. 0. 0. 0. 0. 1. 0.]]", "date": "2018-12-11_20-57-03", "targets": "[[5 5 5 ... 5 5 5]\n [7 7 7 ... 7 7 7]\n [1 1 1 ... 1 1 1]\n ...\n [2 2 2 ... 2 2 2]\n [0 0 0 ... 0 0 0]\n [3 3 3 ... 3 3 3]]", "episodes_total": null, "done": false, "iterations_since_restore": 9, "weights": "[[5.7476096e-05 5.7902325e-05 5.8220379e-05 ... 5.9814007e-05\n  5.9657563e-05 9.4515163e-01]\n [5.8320569e-05 5.9068509e-05 5.9539652e-05 ... 6.2551226e-05\n  6.2785162e-05 9.4356477e-01]\n [5.8051290e-05 5.8723501e-05 5.9184695e-05 ... 5.8729598e-05\n  5.8722249e-05 9.4306833e-01]\n ...\n [5.9152506e-05 6.0265465e-05 6.0928487e-05 ... 6.2782361e-05\n  6.2510982e-05 9.4456136e-01]\n [5.8414353e-05 5.9242135e-05 5.9786336e-05 ... 6.0242735e-05\n  6.0533548e-05 9.4326782e-01]\n [5.8407564e-05 5.9269310e-05 5.9860151e-05 ... 6.1318955e-05\n  6.1521430e-05 9.4357651e-01]]", "time_since_restore": 21.75335669517517, "node_ip": "172.17.0.2", "probas": "[[[0.10469608 0.09774714 0.11053357 ... 0.09114808 0.16965601 0.15435252]\n  [0.10327709 0.09663595 0.11269952 ... 0.09124172 0.17028503 0.15515861]\n  [0.10370672 0.09697033 0.11203538 ... 0.0912154  0.17008242 0.15490563]\n  ...\n  [0.10205554 0.09569483 0.11462577 ... 0.09131321 0.17092267 0.15592025]\n  [0.10313183 0.09652331 0.11292564 ... 0.09125036 0.170356   0.15524589]\n  [0.10314224 0.09653138 0.11290943 ... 0.09124975 0.17035088 0.15523963]]\n\n [[0.10346276 0.09770092 0.11103065 ... 0.09475069 0.16844812 0.15390426]\n  [0.10109285 0.096346   0.11324815 ... 0.09722959 0.16866502 0.15495744]\n  [0.10179131 0.09673697 0.11264092 ... 0.09643883 0.16859029 0.1546306 ]\n  ...\n  [0.0988073  0.09502532 0.11515537 ... 0.09981311 0.16906254 0.1562265 ]\n  [0.10077296 0.0961522  0.11355013 ... 0.09753279 0.16872385 0.15513773]\n  [0.10073783 0.09612299 0.11360106 ... 0.09752955 0.16874114 0.1551707 ]]\n\n [[0.10196397 0.09842645 0.11045577 ... 0.09926572 0.17005645 0.1511726 ]\n  [0.0976323  0.09651445 0.11232713 ... 0.10561329 0.17199706 0.15140939]\n  [0.09889673 0.09708445 0.11188182 ... 0.10365221 0.1713776  0.1513265 ]\n  ...\n  [0.09303919 0.09407631 0.11386077 ... 0.11267302 0.17407571 0.15251942]\n  [0.09692223 0.09613208 0.11264536 ... 0.10658185 0.17227733 0.15161957]\n  [0.09677766 0.09603229 0.11274738 ... 0.10671499 0.17230292 0.15172632]]\n\n ...\n\n [[0.07983307 0.07603219 0.13721101 ... 0.13570416 0.2040088  0.15436962]\n  [0.07097333 0.06760173 0.13828482 ... 0.1505877  0.203069   0.16415152]\n  [0.08137264 0.07973668 0.13453029 ... 0.13315296 0.20656063 0.14798476]\n  ...\n  [0.07357105 0.06631155 0.14256012 ... 0.14530228 0.19872802 0.17114387]\n  [0.07671096 0.07575058 0.13520741 ... 0.1411354  0.20683081 0.15145814]\n  [0.07447227 0.07174484 0.13740703 ... 0.14477485 0.20451199 0.15808105]]\n\n [[0.08021209 0.07651769 0.13695735 ... 0.13508154 0.20414633 0.15372385]\n  [0.07030245 0.06673056 0.13847214 ... 0.15164846 0.2026808  0.165598  ]\n  [0.08139469 0.07974213 0.13452984 ... 0.13311474 0.20652714 0.1480084 ]\n  ...\n  [0.07443533 0.06718305 0.14240517 ... 0.1439999  0.19884004 0.16990077]\n  [0.07596999 0.07475066 0.13563265 ... 0.14240764 0.20647305 0.1528274 ]\n  [0.07393888 0.07104559 0.13764255 ... 0.14565529 0.2042158  0.15913908]]\n\n [[0.08059235 0.07701676 0.13668387 ... 0.13445608 0.2042896  0.15305914]\n  [0.06963119 0.0658674  0.13863125 ... 0.15269756 0.20229867 0.16705593]\n  [0.08141375 0.0797505  0.13452376 ... 0.13308161 0.20649847 0.14802362]\n  ...\n  [0.07532323 0.06811611 0.14216463 ... 0.14265949 0.19900219 0.16855094]\n  [0.07521711 0.0737329  0.13604134 ... 0.14369357 0.2060814  0.15426283]\n  [0.07338867 0.07033014 0.13786569 ... 0.14655861 0.20390743 0.16023782]]]", "accuracy": 0.0, "pid": 7051, "inputs": "[[[-0.6441754 ]\n  [-0.6316425 ]\n  [-0.62136537]\n  ...\n  [-0.8751152 ]\n  [-0.86900634]\n  [-0.86335516]]\n\n [[-0.960383  ]\n  [-0.9472135 ]\n  [-0.9349204 ]\n  ...\n  [-1.1757457 ]\n  [-1.1830101 ]\n  [-1.1899081 ]]\n\n [[-0.8636094 ]\n  [-0.8601534 ]\n  [-0.85754985]\n  ...\n  [-0.9232365 ]\n  [-0.9223625 ]\n  [-0.9218354 ]]\n\n ...\n\n [[-1.240437  ]\n  [-1.2371773 ]\n  [-1.234423  ]\n  ...\n  [-0.8358586 ]\n  [-0.81954443]\n  [-0.8044844 ]]\n\n [[-0.99330217]\n  [-0.9936384 ]\n  [-0.994552  ]\n  ...\n  [-1.1170374 ]\n  [-1.130305  ]\n  [-1.1432737 ]]\n\n [[-0.9909409 ]\n  [-1.0027453 ]\n  [-1.0147117 ]\n  ...\n  [-1.1046433 ]\n  [-1.1131419 ]\n  [-1.1218793 ]]]"}
{"time_total_s": 23.873889923095703, "hostname": "e9379f55ba79", "time_this_iter_s": 2.1205332279205322, "experiment_id": "0902a19a136a489999e16e40b7e7dc5b", "timesteps_total": null, "timesteps_since_restore": 0, "training_iteration": 10, "config": {"workers": 2, "dataset": "Mallat", "num_rnn_layers": 1, "hidden_dims": 64, "learning_rate": 0.01, "dropout": 0.3, "epochs": 99999, "earliness_factor": 1, "switch_epoch": 9999, "batchsize": 96, "fold": 6}, "loss": 2.352372884750366, "timestamp": 1544558226, "confusion_matrix": "[[0. 0. 0. 2. 0. 0. 0. 0.]\n [0. 0. 0. 4. 0. 0. 0. 0.]\n [0. 0. 0. 1. 0. 0. 0. 0.]\n [0. 0. 0. 1. 0. 0. 0. 0.]\n [0. 0. 0. 1. 0. 0. 0. 0.]\n [0. 0. 0. 1. 0. 0. 0. 0.]\n [0. 0. 0. 0. 0. 0. 0. 0.]\n [0. 0. 0. 1. 0. 0. 0. 0.]]", "date": "2018-12-11_20-57-06", "targets": "[[5 5 5 ... 5 5 5]\n [7 7 7 ... 7 7 7]\n [1 1 1 ... 1 1 1]\n ...\n [2 2 2 ... 2 2 2]\n [0 0 0 ... 0 0 0]\n [3 3 3 ... 3 3 3]]", "episodes_total": null, "done": true, "iterations_since_restore": 10, "weights": "[[5.9184156e-05 5.9464925e-05 5.9462636e-05 ... 5.4590444e-05\n  5.4581003e-05 9.4877571e-01]\n [6.0153965e-05 6.0658800e-05 6.0526392e-05 ... 5.5102770e-05\n  5.5107976e-05 9.4703752e-01]\n [5.9844257e-05 6.0309696e-05 6.0261562e-05 ... 5.4538650e-05\n  5.4537228e-05 9.4592220e-01]\n ...\n [6.1112849e-05 6.1879131e-05 6.1608065e-05 ... 5.4400291e-05\n  5.4386535e-05 9.4812751e-01]\n [6.0261853e-05 6.0840757e-05 6.0742968e-05 ... 5.5014960e-05\n  5.5030174e-05 9.4655603e-01]\n [6.0254093e-05 6.0872626e-05 6.0820759e-05 ... 5.4974851e-05\n  5.4986343e-05 9.4691926e-01]]", "time_since_restore": 23.873889923095703, "node_ip": "172.17.0.2", "probas": "[[[0.11266048 0.10043804 0.10338714 ... 0.0841439  0.15368554 0.15700541]\n  [0.11049296 0.09894106 0.10609439 ... 0.08462822 0.15451829 0.1567954 ]\n  [0.11114711 0.09938897 0.10526748 ... 0.08448365 0.15424392 0.15684974]\n  ...\n  [0.10864361 0.09769288 0.10847666 ... 0.0850367  0.15540847 0.1566861 ]\n  [0.11027224 0.09879067 0.10637525 ... 0.08467685 0.15461549 0.15677886]\n  [0.11028802 0.09880143 0.10635512 ... 0.08467335 0.15460844 0.15678   ]]\n\n [[0.11020867 0.09913711 0.10448029 ... 0.0883432  0.15247603 0.15495807]\n  [0.10651133 0.09679178 0.1074573  ... 0.09146769 0.15307584 0.15450934]\n  [0.10758904 0.09746949 0.10664006 ... 0.09049305 0.15287428 0.15459085]\n  ...\n  [0.10307616 0.0946268  0.10997956 ... 0.09462023 0.15395357 0.1546152 ]\n  [0.10602789 0.09648348 0.10785181 ... 0.09185243 0.15319769 0.15451065]\n  [0.1059782  0.0964493  0.10791285 ... 0.09185766 0.15322293 0.15452325]]\n\n [[0.1076039  0.09841636 0.10406911 ... 0.09338517 0.15467986 0.15142186]\n  [0.10124182 0.09471625 0.10675357 ... 0.10059308 0.1573758  0.15026003]\n  [0.10306444 0.09578892 0.10610764 ... 0.09840465 0.15652831 0.15048805]\n  ...\n  [0.09481032 0.09069074 0.10888272 ... 0.10839039 0.1602366  0.15054852]\n  [0.10023349 0.09409194 0.10718764 ... 0.10168899 0.1577709  0.15028398]\n  [0.10003074 0.09395702 0.10731829 ... 0.10185076 0.1578148  0.15033762]]\n\n ...\n\n [[0.09568194 0.09510688 0.11823591 ... 0.11429649 0.20007735 0.12319283]\n  [0.08786549 0.08905515 0.11922966 ... 0.12444097 0.20381612 0.12405427]\n  [0.09443039 0.09416406 0.11844642 ... 0.11577695 0.20069183 0.12329212]\n  ...\n  [0.09685492 0.09619224 0.11824442 ... 0.11320934 0.20021015 0.12230366]\n  [0.08925408 0.09007842 0.11905859 ... 0.12224624 0.20294137 0.12424137]\n  [0.08974083 0.09059747 0.11908931 ... 0.12184171 0.20307828 0.12363036]]\n\n [[0.09584992 0.09521352 0.11818684 ... 0.11407552 0.19990225 0.12326472]\n  [0.08768708 0.08890916 0.11924271 ... 0.12470986 0.20388901 0.12408201]\n  [0.09446682 0.09419055 0.11843468 ... 0.11573056 0.20064415 0.12330382]\n  ...\n  [0.09729154 0.09645715 0.11809552 ... 0.11263266 0.1997057  0.12254336]\n  [0.08891254 0.08980936 0.1191049  ... 0.12273285 0.20313163 0.12426317]\n  [0.0895366  0.09043897 0.1191145  ... 0.12213203 0.20317522 0.12364456]]\n\n [[0.09600707 0.09531173 0.11813664 ... 0.11386772 0.19972609 0.12334081]\n  [0.08752124 0.08877377 0.11925303 ... 0.12496284 0.20395224 0.12410799]\n  [0.09449343 0.0942096  0.11842314 ... 0.11569566 0.20059937 0.12331752]\n  ...\n  [0.09769227 0.09668933 0.11794285 ... 0.11209887 0.19919945 0.12280492]\n  [0.08858451 0.08954924 0.11914423 ... 0.12320472 0.20330037 0.12429217]\n  [0.08933    0.09027878 0.1191362  ... 0.12242725 0.20326412 0.1236629 ]]]", "accuracy": 0.09090909090909091, "pid": 7051, "inputs": "[[[-0.6441754 ]\n  [-0.6316425 ]\n  [-0.62136537]\n  ...\n  [-0.8751152 ]\n  [-0.86900634]\n  [-0.86335516]]\n\n [[-0.960383  ]\n  [-0.9472135 ]\n  [-0.9349204 ]\n  ...\n  [-1.1757457 ]\n  [-1.1830101 ]\n  [-1.1899081 ]]\n\n [[-0.8636094 ]\n  [-0.8601534 ]\n  [-0.85754985]\n  ...\n  [-0.9232365 ]\n  [-0.9223625 ]\n  [-0.9218354 ]]\n\n ...\n\n [[-1.240437  ]\n  [-1.2371773 ]\n  [-1.234423  ]\n  ...\n  [-0.8358586 ]\n  [-0.81954443]\n  [-0.8044844 ]]\n\n [[-0.99330217]\n  [-0.9936384 ]\n  [-0.994552  ]\n  ...\n  [-1.1170374 ]\n  [-1.130305  ]\n  [-1.1432737 ]]\n\n [[-0.9909409 ]\n  [-1.0027453 ]\n  [-1.0147117 ]\n  ...\n  [-1.1046433 ]\n  [-1.1131419 ]\n  [-1.1218793 ]]]"}

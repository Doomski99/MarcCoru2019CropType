{"time_total_s": 2.5145223140716553, "pid": 7048, "time_this_iter_s": 2.5145223140716553, "experiment_id": "c82d3f62007f4acf80e92badc93a7ea2", "timesteps_total": null, "timesteps_since_restore": 0, "training_iteration": 1, "config": {"workers": 2, "dataset": "Mallat", "num_rnn_layers": 1, "hidden_dims": 64, "learning_rate": 0.01, "fold": 9, "dropout": 0.3, "epochs": 99999, "earliness_factor": 1, "switch_epoch": 9999, "batchsize": 96}, "loss": 2.0891244411468506, "hostname": "e9379f55ba79", "timestamp": 1544558205, "confusion_matrix": "[[0. 0. 0. 2. 0. 0. 0. 0.]\n [0. 0. 0. 3. 0. 0. 0. 0.]\n [0. 0. 0. 1. 0. 0. 0. 0.]\n [0. 0. 0. 3. 0. 0. 0. 0.]\n [0. 0. 0. 1. 0. 0. 0. 0.]\n [0. 0. 0. 3. 0. 0. 0. 0.]\n [0. 0. 0. 1. 0. 0. 0. 0.]\n [0. 0. 0. 0. 0. 0. 0. 0.]]", "date": "2018-12-11_20-56-45", "targets": "[[5 5 5 ... 5 5 5]\n [5 5 5 ... 5 5 5]\n [1 1 1 ... 1 1 1]\n ...\n [0 0 0 ... 0 0 0]\n [5 5 5 ... 5 5 5]\n [1 1 1 ... 1 1 1]]", "episodes_total": null, "done": false, "iterations_since_restore": 1, "weights": "[[4.5051129e-05 4.4826083e-05 4.4739987e-05 ... 4.2613079e-05\n  4.2613003e-05 9.5410347e-01]\n [4.4876266e-05 4.4581007e-05 4.4474818e-05 ... 4.2513930e-05\n  4.2519943e-05 9.5410216e-01]\n [4.5100816e-05 4.4891833e-05 4.4806162e-05 ... 4.2610951e-05\n  4.2609776e-05 9.5409757e-01]\n ...\n [4.4990891e-05 4.4735898e-05 4.4635501e-05 ... 4.2442975e-05\n  4.2432057e-05 9.5409435e-01]\n [4.4940549e-05 4.4660279e-05 4.4547651e-05 ... 4.2369476e-05\n  4.2358584e-05 9.5410770e-01]\n [4.5108471e-05 4.4895729e-05 4.4801549e-05 ... 4.2607819e-05\n  4.2606644e-05 9.5409662e-01]]", "time_since_restore": 2.5145223140716553, "node_ip": "172.17.0.2", "probas": "[[[0.12203162 0.12535827 0.12243632 ... 0.10461768 0.13559607 0.13797851]\n  [0.12197972 0.12544508 0.12228246 ... 0.10488406 0.13532129 0.13769937]\n  [0.12204861 0.12533177 0.12247919 ... 0.10454298 0.13567504 0.13805404]\n  ...\n  [0.12201235 0.12538926 0.12238391 ... 0.10470874 0.13550091 0.13788475]\n  [0.12199732 0.12541428 0.12233956 ... 0.10478541 0.1354217  0.1378044 ]\n  [0.12205131 0.12532766 0.12248575 ... 0.10453151 0.13568723 0.13806555]]\n\n [[0.12195666 0.12543935 0.12241556 ... 0.10497572 0.1348824  0.13773395]\n  [0.1218849  0.12553607 0.12225011 ... 0.10538796 0.13435142 0.1373394 ]\n  [0.12197841 0.1254104  0.12245723 ... 0.10486905 0.13502608 0.13783188]\n  ...\n  [0.12192866 0.12547754 0.12235462 ... 0.10512452 0.13469014 0.13759314]\n  [0.1219068  0.12550758 0.12230235 ... 0.10525172 0.13452865 0.1374705 ]\n  [0.12197975 0.12540899 0.12245809 ... 0.10486263 0.13503766 0.13783672]]\n\n [[0.12189178 0.1254191  0.12247109 ... 0.10519593 0.13432173 0.13767336]\n  [0.12178139 0.1254981  0.12231676 ... 0.10570771 0.13359475 0.13724406]\n  [0.12192068 0.12539646 0.12250479 ... 0.10507392 0.13450739 0.13777024]\n  ...\n  [0.12184869 0.12545465 0.12240962 ... 0.10539043 0.13404581 0.1375099 ]\n  [0.12181343 0.12548152 0.12235584 ... 0.10555886 0.13381264 0.13736543]\n  [0.12191962 0.12539974 0.12249861 ... 0.10508034 0.13450591 0.13776137]]\n\n ...\n\n [[0.12154859 0.12513207 0.12260364 ... 0.10564679 0.13322039 0.13780703]\n  [0.12138039 0.12513284 0.12256009 ... 0.10593808 0.13274767 0.13767098]\n  [0.12154931 0.12513436 0.12260095 ... 0.10565029 0.13321817 0.13780203]\n  ...\n  [0.12133716 0.12516871 0.12249119 ... 0.10611453 0.13253503 0.13752162]\n  [0.12121613 0.12517303 0.12244277 ... 0.10634746 0.13219309 0.13739179]\n  [0.12154496 0.12513466 0.1225994  ... 0.10565865 0.13320477 0.13779768]]\n\n [[0.12155163 0.12513213 0.12260432 ... 0.10564137 0.13322957 0.13780938]\n  [0.12139399 0.12513237 0.12256434 ... 0.10591366 0.13278599 0.13768321]\n  [0.12155073 0.12513445 0.12260112 ... 0.10564782 0.13322243 0.13780293]\n  ...\n  [0.12132154 0.1251688  0.12248596 ... 0.10614302 0.13249171 0.13750692]\n  [0.12119936 0.12517291 0.12243688 ... 0.1063778  0.13214834 0.13737561]\n  [0.12154645 0.12513478 0.12259964 ... 0.10565618 0.13320912 0.13779862]]\n\n [[0.12155438 0.12513234 0.12260475 ... 0.10563675 0.13323762 0.13781112]\n  [0.12140704 0.12513201 0.12256817 ... 0.10589061 0.1328225  0.13769451]\n  [0.12155198 0.12513466 0.12260122 ... 0.10564593 0.13322592 0.1378035 ]\n  ...\n  [0.12130629 0.12516885 0.12248085 ... 0.10617076 0.1324497  0.13749252]\n  [0.12118301 0.12517282 0.12243112 ... 0.10640737 0.13210487 0.13735984]\n  [0.12154772 0.12513502 0.1225997  ... 0.10565427 0.13321267 0.13779916]]]", "accuracy": 0.21428571428571427, "inputs": "[[[-0.884163  ]\n  [-0.8722339 ]\n  [-0.8617986 ]\n  ...\n  [-0.86358935]\n  [-0.8614071 ]\n  [-0.85974586]]\n\n [[-1.2018661 ]\n  [-1.1984447 ]\n  [-1.1953816 ]\n  ...\n  [-0.9929527 ]\n  [-0.98181814]\n  [-0.97144604]]\n\n [[-0.7941958 ]\n  [-0.79026073]\n  [-0.78699857]\n  ...\n  [-0.867568  ]\n  [-0.8667153 ]\n  [-0.8661968 ]]\n\n ...\n\n [[-0.99330217]\n  [-0.9936384 ]\n  [-0.994552  ]\n  ...\n  [-1.1170374 ]\n  [-1.130305  ]\n  [-1.1432737 ]]\n\n [[-1.0847987 ]\n  [-1.0974002 ]\n  [-1.1098067 ]\n  ...\n  [-1.2315367 ]\n  [-1.2457271 ]\n  [-1.2595538 ]]\n\n [[-0.7803517 ]\n  [-0.7895152 ]\n  [-0.7991167 ]\n  ...\n  [-0.8716578 ]\n  [-0.8707964 ]\n  [-0.870276  ]]]"}
{"time_total_s": 4.893756866455078, "pid": 7048, "time_this_iter_s": 2.379234552383423, "experiment_id": "c82d3f62007f4acf80e92badc93a7ea2", "timesteps_total": null, "timesteps_since_restore": 0, "training_iteration": 2, "config": {"workers": 2, "dataset": "Mallat", "num_rnn_layers": 1, "hidden_dims": 64, "learning_rate": 0.01, "fold": 9, "dropout": 0.3, "epochs": 99999, "earliness_factor": 1, "switch_epoch": 9999, "batchsize": 96}, "loss": 2.1399970054626465, "hostname": "e9379f55ba79", "timestamp": 1544558207, "confusion_matrix": "[[0. 0. 0. 2. 0. 0. 0. 0.]\n [0. 0. 0. 3. 0. 0. 0. 0.]\n [0. 0. 0. 1. 0. 0. 0. 0.]\n [0. 0. 0. 3. 0. 0. 0. 0.]\n [0. 0. 0. 1. 0. 0. 0. 0.]\n [0. 0. 0. 3. 0. 0. 0. 0.]\n [0. 0. 0. 1. 0. 0. 0. 0.]\n [0. 0. 0. 0. 0. 0. 0. 0.]]", "date": "2018-12-11_20-56-47", "targets": "[[5 5 5 ... 5 5 5]\n [5 5 5 ... 5 5 5]\n [1 1 1 ... 1 1 1]\n ...\n [0 0 0 ... 0 0 0]\n [5 5 5 ... 5 5 5]\n [1 1 1 ... 1 1 1]]", "episodes_total": null, "done": false, "iterations_since_restore": 2, "weights": "[[4.3698641e-05 4.3386812e-05 4.3239826e-05 ... 4.0825693e-05\n  4.0827563e-05 9.5481604e-01]\n [4.3476302e-05 4.3070097e-05 4.2886593e-05 ... 4.0626997e-05\n  4.0640265e-05 9.5480645e-01]\n [4.3762073e-05 4.3472450e-05 4.3329099e-05 ... 4.0823375e-05\n  4.0823223e-05 9.5476180e-01]\n ...\n [4.3621949e-05 4.3270084e-05 4.3101012e-05 ... 4.0552768e-05\n  4.0533687e-05 9.5474142e-01]\n [4.3557895e-05 4.3172564e-05 4.2984771e-05 ... 4.0422052e-05\n  4.0403000e-05 9.5483768e-01]\n [4.3771841e-05 4.3477798e-05 4.3323893e-05 ... 4.0817027e-05\n  4.0816918e-05 9.5474547e-01]]", "time_since_restore": 4.893756866455078, "node_ip": "172.17.0.2", "probas": "[[[0.10174506 0.11962482 0.11944809 ... 0.08628453 0.16810526 0.14925319]\n  [0.1017259  0.11976365 0.11950783 ... 0.08669192 0.1675745  0.1489319 ]\n  [0.10175303 0.11958319 0.11942989 ... 0.08616994 0.16825809 0.14934078]\n  ...\n  [0.10173687 0.11967394 0.11946939 ... 0.08642399 0.16792123 0.14914484]\n  [0.10173133 0.11971401 0.11948666 ... 0.08654134 0.16776834 0.14905243]\n  [0.10175434 0.11957666 0.11942705 ... 0.08615234 0.16828167 0.1493541 ]]\n\n [[0.10169316 0.11960055 0.1200489  ... 0.08682439 0.1669505  0.14992365]\n  [0.10165789 0.11970913 0.12032189 ... 0.08744592 0.1660143  0.14982812]\n  [0.10170519 0.11956896 0.11997192 ... 0.08666283 0.16720398 0.14993712]\n  ...\n  [0.10167877 0.11964504 0.12014582 ... 0.08704938 0.16660923 0.1498838 ]\n  [0.10166831 0.1196801  0.12022644 ... 0.08724122 0.16632327 0.14984639]\n  [0.10170616 0.11956916 0.11996264 ... 0.08665328 0.1672229  0.14992774]]\n\n [[0.10158867 0.11941303 0.12048873 ... 0.08710027 0.16618377 0.15095149]\n  [0.10149276 0.11944529 0.1209247  ... 0.08784062 0.16498613 0.15123025]\n  [0.10161423 0.11940472 0.12037396 ... 0.08692358 0.16648781 0.15085845]\n  ...\n  [0.10155269 0.11943533 0.12065015 ... 0.0873835  0.16572404 0.15103905]\n  [0.10152315 0.1194507  0.120786   ... 0.08762815 0.16533644 0.15110783]\n  [0.10161478 0.11941297 0.1203694  ... 0.08693436 0.16648006 0.1508309 ]]\n\n ...\n\n [[0.10099779 0.1188846  0.12063038 ... 0.08727914 0.1655408  0.15393938]\n  [0.10079413 0.11883748 0.12094214 ... 0.08757062 0.16499995 0.1545602 ]\n  [0.10099947 0.11888746 0.12063242 ... 0.08728702 0.16552958 0.15392882]\n  ...\n  [0.10075565 0.11886697 0.12107985 ... 0.08783403 0.16459274 0.15459187]\n  [0.10061675 0.11884059 0.1213176  ... 0.08808836 0.16416232 0.15498286]\n  [0.10099427 0.11888658 0.1206408  ... 0.08729611 0.16551311 0.15394455]]\n\n [[0.10100169 0.11888588 0.12062449 ... 0.08727365 0.16555142 0.1539265 ]\n  [0.10081042 0.11884121 0.12091547 ... 0.08754507 0.1650464  0.15451238]\n  [0.1010014  0.11888829 0.12062966 ... 0.08728466 0.16553439 0.15392224]\n  ...\n  [0.10073722 0.11886281 0.12110945 ... 0.08786387 0.16454065 0.15464555]\n  [0.10059752 0.11883602 0.12134992 ... 0.08812036 0.16410792 0.15503772]\n  [0.10099624 0.11888743 0.12063798 ... 0.08729374 0.16551797 0.15393789]]\n\n [[0.10100532 0.11888732 0.12061939 ... 0.0872693  0.16556029 0.15391439]\n  [0.10082614 0.11884492 0.12089019 ... 0.08752123 0.16509002 0.15446588]\n  [0.1010031  0.11888914 0.12062745 ... 0.08728304 0.16553794 0.15391625]\n  ...\n  [0.10071936 0.11885881 0.12113832 ... 0.08789293 0.16449018 0.1546974 ]\n  [0.10057878 0.1188316  0.12138154 ... 0.08815152 0.16405521 0.15509103]\n  [0.10099798 0.11888832 0.1206357  ... 0.08729209 0.16552152 0.15393178]]]", "accuracy": 0.21428571428571427, "inputs": "[[[-0.884163  ]\n  [-0.8722339 ]\n  [-0.8617986 ]\n  ...\n  [-0.86358935]\n  [-0.8614071 ]\n  [-0.85974586]]\n\n [[-1.2018661 ]\n  [-1.1984447 ]\n  [-1.1953816 ]\n  ...\n  [-0.9929527 ]\n  [-0.98181814]\n  [-0.97144604]]\n\n [[-0.7941958 ]\n  [-0.79026073]\n  [-0.78699857]\n  ...\n  [-0.867568  ]\n  [-0.8667153 ]\n  [-0.8661968 ]]\n\n ...\n\n [[-0.99330217]\n  [-0.9936384 ]\n  [-0.994552  ]\n  ...\n  [-1.1170374 ]\n  [-1.130305  ]\n  [-1.1432737 ]]\n\n [[-1.0847987 ]\n  [-1.0974002 ]\n  [-1.1098067 ]\n  ...\n  [-1.2315367 ]\n  [-1.2457271 ]\n  [-1.2595538 ]]\n\n [[-0.7803517 ]\n  [-0.7895152 ]\n  [-0.7991167 ]\n  ...\n  [-0.8716578 ]\n  [-0.8707964 ]\n  [-0.870276  ]]]"}
{"time_total_s": 7.494665145874023, "pid": 7048, "time_this_iter_s": 2.6009082794189453, "experiment_id": "c82d3f62007f4acf80e92badc93a7ea2", "timesteps_total": null, "timesteps_since_restore": 0, "training_iteration": 3, "config": {"workers": 2, "dataset": "Mallat", "num_rnn_layers": 1, "hidden_dims": 64, "learning_rate": 0.01, "fold": 9, "dropout": 0.3, "epochs": 99999, "earliness_factor": 1, "switch_epoch": 9999, "batchsize": 96}, "loss": 2.243497610092163, "hostname": "e9379f55ba79", "timestamp": 1544558210, "confusion_matrix": "[[0. 0. 0. 2. 0. 0. 0. 0.]\n [0. 0. 0. 3. 0. 0. 0. 0.]\n [0. 0. 0. 1. 0. 0. 0. 0.]\n [0. 0. 0. 2. 0. 0. 1. 0.]\n [0. 0. 0. 1. 0. 0. 0. 0.]\n [0. 0. 0. 2. 0. 0. 1. 0.]\n [0. 0. 0. 1. 0. 0. 0. 0.]\n [0. 0. 0. 0. 0. 0. 0. 0.]]", "date": "2018-12-11_20-56-50", "targets": "[[5 5 5 ... 5 5 5]\n [5 5 5 ... 5 5 5]\n [1 1 1 ... 1 1 1]\n ...\n [0 0 0 ... 0 0 0]\n [5 5 5 ... 5 5 5]\n [1 1 1 ... 1 1 1]]", "episodes_total": null, "done": false, "iterations_since_restore": 3, "weights": "[[4.2495147e-05 4.2149280e-05 4.2024534e-05 ... 3.9773695e-05\n  3.9775259e-05 9.5517147e-01]\n [4.2229687e-05 4.1791438e-05 4.1650004e-05 ... 3.9588973e-05\n  3.9600320e-05 9.5500839e-01]\n [4.2571359e-05 4.2247349e-05 4.2120697e-05 ... 3.9739691e-05\n  3.9739436e-05 9.5436579e-01]\n ...\n [4.2403291e-05 4.2016174e-05 4.1874722e-05 ... 3.9487324e-05\n  3.9471044e-05 9.5420390e-01]\n [4.2326814e-05 4.1905812e-05 4.1750845e-05 ... 3.9422164e-05\n  3.9406710e-05 9.5534706e-01]\n [4.2583135e-05 4.2253272e-05 4.2113908e-05 ... 3.9729366e-05\n  3.9729115e-05 9.5424336e-01]]", "time_since_restore": 7.494665145874023, "node_ip": "172.17.0.2", "probas": "[[[0.08067842 0.11427854 0.11680961 ... 0.06466825 0.20756748 0.16512302]\n  [0.08066932 0.11442398 0.11711041 ... 0.06508973 0.20668802 0.16460738]\n  [0.08068352 0.11423392 0.11672412 ... 0.06455006 0.20782071 0.16526838]\n  ...\n  [0.08067375 0.1143307  0.11691318 ... 0.06481235 0.20726267 0.16494629]\n  [0.08067109 0.11437266 0.11699984 ... 0.06493374 0.20700924 0.16479778]\n  [0.08068439 0.11422689 0.11671093 ... 0.0645319  0.20785977 0.16529068]]\n\n [[0.08061448 0.11413529 0.11790141 ... 0.06510863 0.20573913 0.16621901]\n  [0.08056763 0.11417586 0.11864146 ... 0.06572974 0.20420685 0.16616476]\n  [0.08062821 0.11411869 0.11770505 ... 0.06495022 0.2061527  0.1662264 ]\n  ...\n  [0.08059729 0.11415907 0.11816391 ... 0.06533278 0.2051806  0.1661821 ]\n  [0.08058355 0.11417429 0.11838733 ... 0.06552527 0.20471197 0.1661522 ]\n  [0.08062952 0.11412111 0.11768707 ... 0.06494198 0.20618275 0.16621009]]\n\n [[0.08041586 0.11385488 0.11844029 ... 0.06523275 0.20466419 0.16774021]\n  [0.08024164 0.11372594 0.11946981 ... 0.06596977 0.20276394 0.1683363 ]\n  [0.08045847 0.11387999 0.11819223 ... 0.06506584 0.20514275 0.16757432]\n  ...\n  [0.0803544  0.1138244  0.11882178 ... 0.06551215 0.20393263 0.16792484]\n  [0.08030081 0.11378925 0.11915333 ... 0.06575827 0.20331457 0.16808645]\n  [0.08046057 0.11389004 0.11819557 ... 0.06508002 0.20512636 0.16753283]]\n\n ...\n\n [[0.07904944 0.11366055 0.11657686 ... 0.065285   0.20660569 0.16917205]\n  [0.07858194 0.11341143 0.11709329 ... 0.06581974 0.20664713 0.16961342]\n  [0.07905422 0.11366104 0.11659331 ... 0.06529132 0.20656179 0.16917893]\n  ...\n  [0.0785145  0.11333776 0.11756013 ... 0.06612933 0.20578088 0.16992392]\n  [0.07819427 0.11313614 0.11805859 ... 0.06659597 0.2056327  0.1702907 ]\n  [0.07904258 0.11365522 0.11660768 ... 0.06530562 0.2065553  0.16919166]]\n\n [[0.07905822 0.11366563 0.11656775 ... 0.065276   0.2066077  0.1691613 ]\n  [0.0786193  0.11343461 0.11704241 ... 0.06577274 0.20665666 0.16957124]\n  [0.07905856 0.11366373 0.11658929 ... 0.06528732 0.20656219 0.16917321]\n  ...\n  [0.07847204 0.11331216 0.11761722 ... 0.0661852  0.20577252 0.16996942]\n  [0.07814936 0.11310671 0.11812593 ... 0.06665973 0.20562619 0.17033981]\n  [0.079047   0.11365795 0.1166036  ... 0.06530157 0.20655565 0.16918588]]\n\n [[0.07906638 0.11367028 0.11656065 ... 0.06526843 0.20660718 0.1691518 ]\n  [0.07865535 0.11345655 0.11699543 ... 0.06572857 0.2066624  0.16953176]\n  [0.07906248 0.11366614 0.11658667 ... 0.06528432 0.20656085 0.16916862]\n  ...\n  [0.0784307  0.11328717 0.11767349 ... 0.0662402  0.20576553 0.17001314]\n  [0.07810546 0.11307775 0.11819217 ... 0.06672247 0.2056213  0.17038722]\n  [0.07905098 0.11366039 0.11660093 ... 0.06529848 0.20655413 0.16918121]]]", "accuracy": 0.14285714285714285, "inputs": "[[[-0.884163  ]\n  [-0.8722339 ]\n  [-0.8617986 ]\n  ...\n  [-0.86358935]\n  [-0.8614071 ]\n  [-0.85974586]]\n\n [[-1.2018661 ]\n  [-1.1984447 ]\n  [-1.1953816 ]\n  ...\n  [-0.9929527 ]\n  [-0.98181814]\n  [-0.97144604]]\n\n [[-0.7941958 ]\n  [-0.79026073]\n  [-0.78699857]\n  ...\n  [-0.867568  ]\n  [-0.8667153 ]\n  [-0.8661968 ]]\n\n ...\n\n [[-0.99330217]\n  [-0.9936384 ]\n  [-0.994552  ]\n  ...\n  [-1.1170374 ]\n  [-1.130305  ]\n  [-1.1432737 ]]\n\n [[-1.0847987 ]\n  [-1.0974002 ]\n  [-1.1098067 ]\n  ...\n  [-1.2315367 ]\n  [-1.2457271 ]\n  [-1.2595538 ]]\n\n [[-0.7803517 ]\n  [-0.7895152 ]\n  [-0.7991167 ]\n  ...\n  [-0.8716578 ]\n  [-0.8707964 ]\n  [-0.870276  ]]]"}
{"time_total_s": 10.089165210723877, "pid": 7048, "time_this_iter_s": 2.5945000648498535, "experiment_id": "c82d3f62007f4acf80e92badc93a7ea2", "timesteps_total": null, "timesteps_since_restore": 0, "training_iteration": 4, "config": {"workers": 2, "dataset": "Mallat", "num_rnn_layers": 1, "hidden_dims": 64, "learning_rate": 0.01, "fold": 9, "dropout": 0.3, "epochs": 99999, "earliness_factor": 1, "switch_epoch": 9999, "batchsize": 96}, "loss": 2.2966301441192627, "hostname": "e9379f55ba79", "timestamp": 1544558212, "confusion_matrix": "[[0. 0. 0. 0. 0. 0. 2. 0.]\n [0. 0. 0. 0. 0. 0. 3. 0.]\n [0. 0. 0. 0. 0. 0. 1. 0.]\n [0. 0. 0. 0. 0. 0. 3. 0.]\n [0. 0. 0. 0. 0. 0. 1. 0.]\n [0. 0. 0. 0. 0. 0. 3. 0.]\n [0. 0. 0. 0. 0. 0. 1. 0.]\n [0. 0. 0. 0. 0. 0. 0. 0.]]", "date": "2018-12-11_20-56-52", "targets": "[[5 5 5 ... 5 5 5]\n [5 5 5 ... 5 5 5]\n [1 1 1 ... 1 1 1]\n ...\n [0 0 0 ... 0 0 0]\n [5 5 5 ... 5 5 5]\n [1 1 1 ... 1 1 1]]", "episodes_total": null, "done": false, "iterations_since_restore": 4, "weights": "[[4.1783122e-05 4.1410447e-05 4.1363230e-05 ... 3.9936687e-05\n  3.9935134e-05 9.5701259e-01]\n [4.1456984e-05 4.0997096e-05 4.0971183e-05 ... 3.9960367e-05\n  3.9955878e-05 9.5696932e-01]\n [4.1877141e-05 4.1524727e-05 4.1464558e-05 ... 3.9914787e-05\n  3.9913004e-05 9.5665008e-01]\n ...\n [4.1669991e-05 4.1255469e-05 4.1202773e-05 ... 3.9805975e-05\n  3.9807732e-05 9.5639992e-01]\n [4.1576037e-05 4.1127649e-05 4.1071478e-05 ... 3.9855859e-05\n  3.9861839e-05 9.5705968e-01]\n [4.1891682e-05 4.1531184e-05 4.1454710e-05 ... 3.9911705e-05\n  3.9909846e-05 9.5660722e-01]]", "time_since_restore": 10.089165210723877, "node_ip": "172.17.0.2", "probas": "[[[0.08060599 0.12255236 0.12128065 ... 0.05760529 0.20997502 0.18183468]\n  [0.08068727 0.12272475 0.12164593 ... 0.05819383 0.20892186 0.18137792]\n  [0.08058484 0.12249799 0.12117761 ... 0.05744006 0.2102782  0.18196563]\n  ...\n  [0.08063279 0.12261508 0.12140595 ... 0.05780662 0.20961003 0.18167673]\n  [0.08065617 0.12266484 0.12151115 ... 0.0579761  0.20930651 0.18154512]\n  [0.08058167 0.12248944 0.12116177 ... 0.05741471 0.21032499 0.18198588]]\n\n [[0.08087812 0.12216835 0.12243827 ... 0.05830753 0.2078573  0.18440342]\n  [0.08099803 0.12209896 0.12329502 ... 0.05921249 0.20603871 0.18501724]\n  [0.08084195 0.12217627 0.12221421 ... 0.05807644 0.20834658 0.18423352]\n  ...\n  [0.08092354 0.12215921 0.12274134 ... 0.05863312 0.20719443 0.18459348]\n  [0.08095999 0.12214289 0.12300084 ... 0.05891288 0.20663771 0.18475947]\n  [0.08083837 0.12218308 0.12219477 ... 0.05806358 0.20838141 0.18419339]]\n\n [[0.08096389 0.12159798 0.12281089 ... 0.05861739 0.20677018 0.18735366]\n  [0.08097357 0.12114424 0.12396339 ... 0.05977679 0.20460534 0.18919486]\n  [0.08094759 0.12169389 0.12254277 ... 0.05835474 0.20731194 0.18687136]\n  ...\n  [0.08097849 0.12146156 0.12323631 ... 0.05905128 0.20593351 0.18798342]\n  [0.08098212 0.12132642 0.12361067 ... 0.05943513 0.20522586 0.18853045]\n  [0.08094779 0.12170991 0.1225511  ... 0.05837258 0.2072887  0.1868102 ]]\n\n ...\n\n [[0.08055765 0.11921348 0.12023156 ... 0.06035357 0.2119241  0.18890223]\n  [0.07999341 0.11749132 0.1210032  ... 0.06202082 0.21289198 0.19004272]\n  [0.0805614  0.11924299 0.12024444 ... 0.06034498 0.21185465 0.18891864]\n  ...\n  [0.07991853 0.11761256 0.12144706 ... 0.06235084 0.21178257 0.19072583]\n  [0.07947735 0.11642504 0.12214205 ... 0.0636521  0.2121286  0.19168584]\n  [0.08054923 0.11920683 0.12026332 ... 0.06038375 0.21186845 0.188949  ]]\n\n [[0.08056689 0.11924128 0.12021947 ... 0.0603271  0.21190996 0.1888787 ]\n  [0.0800433  0.11763147 0.12093001 ... 0.06188079 0.21283604 0.18993375]\n  [0.08056597 0.11925655 0.12023922 ... 0.06033286 0.21184687 0.18890698]\n  ...\n  [0.07986297 0.11745794 0.12152819 ... 0.06251244 0.21184626 0.19084199]\n  [0.07941146 0.11624558 0.1222404  ... 0.06384119 0.21219414 0.19181876]\n  [0.08055391 0.11922079 0.120258   ... 0.06037133 0.21186036 0.18893725]]\n\n [[0.08057537 0.11926755 0.12020966 ... 0.0603034  0.2118934  0.18885845]\n  [0.08009092 0.117767   0.12086178 ... 0.06174723 0.21277648 0.18983194]\n  [0.08057002 0.11926913 0.12023548 ... 0.0603225  0.21183738 0.18889777]\n  ...\n  [0.07980793 0.11730477 0.12160879 ... 0.06267259 0.21190937 0.19095542]\n  [0.07934599 0.11606717 0.12233791 ... 0.06402887 0.21225947 0.19194898]\n  [0.08055804 0.11923364 0.12025421 ... 0.06036073 0.21185055 0.18892792]]]", "accuracy": 0.07142857142857142, "inputs": "[[[-0.884163  ]\n  [-0.8722339 ]\n  [-0.8617986 ]\n  ...\n  [-0.86358935]\n  [-0.8614071 ]\n  [-0.85974586]]\n\n [[-1.2018661 ]\n  [-1.1984447 ]\n  [-1.1953816 ]\n  ...\n  [-0.9929527 ]\n  [-0.98181814]\n  [-0.97144604]]\n\n [[-0.7941958 ]\n  [-0.79026073]\n  [-0.78699857]\n  ...\n  [-0.867568  ]\n  [-0.8667153 ]\n  [-0.8661968 ]]\n\n ...\n\n [[-0.99330217]\n  [-0.9936384 ]\n  [-0.994552  ]\n  ...\n  [-1.1170374 ]\n  [-1.130305  ]\n  [-1.1432737 ]]\n\n [[-1.0847987 ]\n  [-1.0974002 ]\n  [-1.1098067 ]\n  ...\n  [-1.2315367 ]\n  [-1.2457271 ]\n  [-1.2595538 ]]\n\n [[-0.7803517 ]\n  [-0.7895152 ]\n  [-0.7991167 ]\n  ...\n  [-0.8716578 ]\n  [-0.8707964 ]\n  [-0.870276  ]]]"}
{"time_total_s": 12.683841228485107, "pid": 7048, "time_this_iter_s": 2.5946760177612305, "experiment_id": "c82d3f62007f4acf80e92badc93a7ea2", "timesteps_total": null, "timesteps_since_restore": 0, "training_iteration": 5, "config": {"workers": 2, "dataset": "Mallat", "num_rnn_layers": 1, "hidden_dims": 64, "learning_rate": 0.01, "fold": 9, "dropout": 0.3, "epochs": 99999, "earliness_factor": 1, "switch_epoch": 9999, "batchsize": 96}, "loss": 2.2401020526885986, "hostname": "e9379f55ba79", "timestamp": 1544558215, "confusion_matrix": "[[0. 0. 0. 0. 0. 0. 2. 0.]\n [0. 0. 0. 0. 0. 0. 3. 0.]\n [0. 0. 0. 0. 0. 0. 1. 0.]\n [0. 0. 0. 0. 0. 0. 3. 0.]\n [0. 0. 0. 0. 0. 0. 1. 0.]\n [0. 0. 0. 0. 0. 0. 3. 0.]\n [0. 0. 0. 0. 0. 0. 1. 0.]\n [0. 0. 0. 0. 0. 0. 0. 0.]]", "date": "2018-12-11_20-56-55", "targets": "[[5 5 5 ... 5 5 5]\n [5 5 5 ... 5 5 5]\n [1 1 1 ... 1 1 1]\n ...\n [0 0 0 ... 0 0 0]\n [5 5 5 ... 5 5 5]\n [1 1 1 ... 1 1 1]]", "episodes_total": null, "done": false, "iterations_since_restore": 5, "weights": "[[4.1227020e-05 4.0710482e-05 4.0640167e-05 ... 3.9325569e-05\n  3.9322895e-05 9.5671779e-01]\n [4.0799532e-05 4.0175113e-05 4.0151397e-05 ... 3.9445269e-05\n  3.9430743e-05 9.5654160e-01]\n [4.1351090e-05 4.0860843e-05 4.0770548e-05 ... 3.9188486e-05\n  3.9186129e-05 9.5359761e-01]\n ...\n [4.1078321e-05 4.0508377e-05 4.0436953e-05 ... 3.9111539e-05\n  3.9122617e-05 9.5255429e-01]\n [4.0955107e-05 4.0343035e-05 4.0273448e-05 ... 3.9386345e-05\n  3.9405422e-05 9.5685583e-01]\n [4.1370298e-05 4.0869611e-05 4.0758066e-05 ... 3.9204326e-05\n  3.9201925e-05 9.5398837e-01]]", "time_since_restore": 12.683841228485107, "node_ip": "172.17.0.2", "probas": "[[[0.09596518 0.13440561 0.12427816 ... 0.06451823 0.18464339 0.1797899 ]\n  [0.09569275 0.13465887 0.12468598 ... 0.06542898 0.18379116 0.17884669]\n  [0.09604644 0.13432664 0.12416171 ... 0.06426251 0.18488744 0.18006326]\n  ...\n  [0.09586905 0.13449721 0.12441895 ... 0.06482979 0.18434879 0.17946196]\n  [0.09579054 0.13457035 0.12453648 ... 0.06509209 0.18410324 0.17919022]\n  [0.09605911 0.13431418 0.12414374 ... 0.06422324 0.18492503 0.18010555]]\n\n [[0.09529203 0.13406472 0.12541696 ... 0.0656948  0.1836974  0.18200363]\n  [0.09468612 0.134067   0.1262599  ... 0.06714484 0.18243836 0.182117  ]\n  [0.09545033 0.13404973 0.1251913  ... 0.06532542 0.18402489 0.18197745]\n  ...\n  [0.09507675 0.1340863  0.12571968 ... 0.06621455 0.18323751 0.18199849]\n  [0.09489318 0.13409317 0.12597547 ... 0.06666202 0.18284687 0.18200754]\n  [0.09546292 0.13405629 0.12517244 ... 0.065304   0.18404137 0.18194292]]\n\n [[0.09448741 0.13364631 0.12533246 ... 0.0663811  0.18397789 0.18460087]\n  [0.09332761 0.13321672 0.12623273 ... 0.06837557 0.18279637 0.18594442]\n  [0.09475925 0.13372248 0.1251212  ... 0.06593119 0.18424413 0.18426172]\n  ...\n  [0.09407002 0.1335326  0.12567703 ... 0.06711829 0.18351097 0.18501733]\n  [0.0937013  0.13340694 0.12597486 ... 0.06777424 0.1831053  0.18539886]\n  [0.09476025 0.13374072 0.1251366  ... 0.06595589 0.18420504 0.18418911]]\n\n ...\n\n [[0.09004288 0.13133411 0.11902462 ... 0.07159989 0.19440468 0.18233903]\n  [0.08708247 0.12822065 0.11857621 ... 0.07575744 0.19631942 0.18385164]\n  [0.09007906 0.13139318 0.11905226 ... 0.07155506 0.19433242 0.18234141]\n  ...\n  [0.08706852 0.12876911 0.11892106 ... 0.07593106 0.1955767  0.18404701]\n  [0.08505126 0.12664498 0.11871395 ... 0.07900348 0.19641249 0.18534423]\n  [0.09001475 0.13133487 0.11904315 ... 0.07164398 0.19437632 0.18236789]]\n\n [[0.09009002 0.13137862 0.11903381 ... 0.07153744 0.19436722 0.182318  ]\n  [0.0873224  0.12847671 0.11860401 ... 0.07541326 0.19619855 0.1836978 ]\n  [0.0901014  0.13141432 0.11905766 ... 0.07152631 0.19431265 0.18233156]\n  ...\n  [0.08680844 0.12849651 0.11888573 ... 0.07631558 0.19571368 0.18419811]\n  [0.08475382 0.12631245 0.11867888 ... 0.07946389 0.19652824 0.18555018]\n  [0.09003764 0.1313567  0.11904866 ... 0.07161447 0.19435616 0.18235779]]\n\n [[0.09013365 0.13142088 0.11904401 ... 0.07148033 0.19432914 0.18229988]\n  [0.0875543  0.12872472 0.11863296 ... 0.07508291 0.19607463 0.18355398]\n  [0.09012147 0.13143416 0.11906367 ... 0.07150088 0.19429263 0.18232375]\n  ...\n  [0.08655122 0.12822382 0.11885164 ... 0.07669845 0.19584426 0.18435128]\n  [0.08445891 0.12597921 0.11864437 ... 0.07992335 0.19663797 0.18575822]\n  [0.09005817 0.13137709 0.11905476 ... 0.07158837 0.19433567 0.18234976]]]", "accuracy": 0.07142857142857142, "inputs": "[[[-0.884163  ]\n  [-0.8722339 ]\n  [-0.8617986 ]\n  ...\n  [-0.86358935]\n  [-0.8614071 ]\n  [-0.85974586]]\n\n [[-1.2018661 ]\n  [-1.1984447 ]\n  [-1.1953816 ]\n  ...\n  [-0.9929527 ]\n  [-0.98181814]\n  [-0.97144604]]\n\n [[-0.7941958 ]\n  [-0.79026073]\n  [-0.78699857]\n  ...\n  [-0.867568  ]\n  [-0.8667153 ]\n  [-0.8661968 ]]\n\n ...\n\n [[-0.99330217]\n  [-0.9936384 ]\n  [-0.994552  ]\n  ...\n  [-1.1170374 ]\n  [-1.130305  ]\n  [-1.1432737 ]]\n\n [[-1.0847987 ]\n  [-1.0974002 ]\n  [-1.1098067 ]\n  ...\n  [-1.2315367 ]\n  [-1.2457271 ]\n  [-1.2595538 ]]\n\n [[-0.7803517 ]\n  [-0.7895152 ]\n  [-0.7991167 ]\n  ...\n  [-0.8716578 ]\n  [-0.8707964 ]\n  [-0.870276  ]]]"}
{"time_total_s": 15.213799238204956, "pid": 7048, "time_this_iter_s": 2.5299580097198486, "experiment_id": "c82d3f62007f4acf80e92badc93a7ea2", "timesteps_total": null, "timesteps_since_restore": 0, "training_iteration": 6, "config": {"workers": 2, "dataset": "Mallat", "num_rnn_layers": 1, "hidden_dims": 64, "learning_rate": 0.01, "fold": 9, "dropout": 0.3, "epochs": 99999, "earliness_factor": 1, "switch_epoch": 9999, "batchsize": 96}, "loss": 2.2116971015930176, "hostname": "e9379f55ba79", "timestamp": 1544558217, "confusion_matrix": "[[0. 0. 0. 2. 0. 0. 0. 0.]\n [0. 0. 0. 3. 0. 0. 0. 0.]\n [0. 0. 0. 1. 0. 0. 0. 0.]\n [0. 0. 0. 2. 0. 0. 1. 0.]\n [0. 0. 0. 1. 0. 0. 0. 0.]\n [0. 0. 0. 2. 0. 0. 1. 0.]\n [0. 0. 0. 1. 0. 0. 0. 0.]\n [0. 0. 0. 0. 0. 0. 0. 0.]]", "date": "2018-12-11_20-56-57", "targets": "[[5 5 5 ... 5 5 5]\n [5 5 5 ... 5 5 5]\n [1 1 1 ... 1 1 1]\n ...\n [0 0 0 ... 0 0 0]\n [5 5 5 ... 5 5 5]\n [1 1 1 ... 1 1 1]]", "episodes_total": null, "done": false, "iterations_since_restore": 6, "weights": "[[4.0419432e-05 3.9825791e-05 3.9817103e-05 ... 3.8686318e-05\n  3.8685197e-05 9.5868683e-01]\n [3.9899060e-05 3.9189774e-05 3.9263090e-05 ... 3.8677914e-05\n  3.8672635e-05 9.5863503e-01]\n [4.0570892e-05 4.0005223e-05 3.9965413e-05 ... 3.8669034e-05\n  3.8667251e-05 9.5842761e-01]\n ...\n [4.0238101e-05 3.9584749e-05 3.9583567e-05 ... 3.8534807e-05\n  3.8537153e-05 9.5834446e-01]\n [4.0088154e-05 3.9388120e-05 3.9396822e-05 ... 3.8586400e-05\n  3.8596918e-05 9.5874202e-01]\n [4.0594347e-05 4.0015369e-05 3.9948951e-05 ... 3.8664428e-05\n  3.8662642e-05 9.5838469e-01]]", "time_since_restore": 15.213799238204956, "node_ip": "172.17.0.2", "probas": "[[[0.11085827 0.13039652 0.12022119 ... 0.07462616 0.17206997 0.1686495 ]\n  [0.11035091 0.13057838 0.12082692 ... 0.0759289  0.17103945 0.16750298]\n  [0.11100625 0.13033621 0.12004609 ... 0.07426043 0.17236604 0.16898309]\n  ...\n  [0.11068124 0.13046452 0.12043152 ... 0.07507177 0.17171311 0.16824996]\n  [0.11053504 0.13051713 0.12060611 ... 0.07544693 0.17141618 0.1679196 ]\n  [0.11102917 0.13032658 0.12001903 ... 0.07420427 0.17241171 0.16903475]]\n\n [[0.10992984 0.12959866 0.122013   ... 0.07616092 0.1713978  0.1713919 ]\n  [0.10891864 0.12933183 0.12321921 ... 0.07818182 0.17009434 0.17155851]\n  [0.1101886  0.12965266 0.12167996 ... 0.07564796 0.17173642 0.17135434]\n  ...\n  [0.1095712  0.12952882 0.12245168 ... 0.07688586 0.17091516 0.17139378]\n  [0.10926281 0.12945578 0.12281678 ... 0.07751063 0.17050669 0.17141299]\n  [0.1102068  0.12966712 0.12165095 ... 0.07561968 0.17174827 0.17131127]]\n\n [[0.1090534  0.12863876 0.1221967  ... 0.07692376 0.1725894  0.17435844]\n  [0.10727219 0.12764496 0.1234511  ... 0.07964391 0.17175592 0.17598127]\n  [0.10945671 0.12884904 0.12187833 ... 0.07631673 0.17275669 0.17395774]\n  ...\n  [0.10841171 0.12832908 0.12268844 ... 0.07793083 0.17223576 0.17485577]\n  [0.10783851 0.1280283  0.12309888 ... 0.07882954 0.17192623 0.17531729]\n  [0.1094491  0.1288745  0.12189465 ... 0.07635576 0.17269622 0.17387131]]\n\n ...\n\n [[0.1066447  0.1253674  0.11626245 ... 0.08047252 0.18615305 0.17107831]\n  [0.10383639 0.12198577 0.11578103 ... 0.08387344 0.18869145 0.17334963]\n  [0.10664979 0.12540998 0.11628239 ... 0.08046865 0.18609375 0.17107125]\n  ...\n  [0.10313956 0.12198853 0.11594189 ... 0.08484639 0.18843187 0.17360726]\n  [0.10089074 0.11938439 0.11559496 ... 0.08767299 0.1897276  0.17579491]\n  [0.10658538 0.12534244 0.11627279 ... 0.08054813 0.18615633 0.17110988]]\n\n [[0.10669082 0.1254194  0.11627335 ... 0.08041836 0.18609862 0.1710485 ]\n  [0.10408606 0.12228433 0.11582242 ... 0.08357534 0.18850507 0.17311561]\n  [0.10667162 0.12543546 0.11628915 ... 0.08044369 0.18606445 0.17105749]\n  ...\n  [0.1028626  0.12166284 0.11589205 ... 0.08518989 0.18863066 0.17385834]\n  [0.10056017 0.11897784 0.11553738 ... 0.08808737 0.18990134 0.17615536]\n  [0.1066077  0.1253686  0.1162797  ... 0.08052257 0.18612649 0.17109564]]\n\n [[0.10673196 0.1254679  0.11628505 ... 0.08037044 0.18604507 0.17102261]\n  [0.1043226  0.12256933 0.1158631  ... 0.08329319 0.18831937 0.17289849]\n  [0.10669003 0.12545851 0.11629622 ... 0.08042279 0.18603615 0.17104626]\n  ...\n  [0.10258827 0.12133774 0.1158435  ... 0.08553077 0.1888193  0.17411427]\n  [0.10023154 0.11857011 0.11548029 ... 0.08850004 0.19006553 0.17652252]\n  [0.1066265  0.1253923  0.1162869  ... 0.08050124 0.18609783 0.17108406]]]", "accuracy": 0.14285714285714285, "inputs": "[[[-0.884163  ]\n  [-0.8722339 ]\n  [-0.8617986 ]\n  ...\n  [-0.86358935]\n  [-0.8614071 ]\n  [-0.85974586]]\n\n [[-1.2018661 ]\n  [-1.1984447 ]\n  [-1.1953816 ]\n  ...\n  [-0.9929527 ]\n  [-0.98181814]\n  [-0.97144604]]\n\n [[-0.7941958 ]\n  [-0.79026073]\n  [-0.78699857]\n  ...\n  [-0.867568  ]\n  [-0.8667153 ]\n  [-0.8661968 ]]\n\n ...\n\n [[-0.99330217]\n  [-0.9936384 ]\n  [-0.994552  ]\n  ...\n  [-1.1170374 ]\n  [-1.130305  ]\n  [-1.1432737 ]]\n\n [[-1.0847987 ]\n  [-1.0974002 ]\n  [-1.1098067 ]\n  ...\n  [-1.2315367 ]\n  [-1.2457271 ]\n  [-1.2595538 ]]\n\n [[-0.7803517 ]\n  [-0.7895152 ]\n  [-0.7991167 ]\n  ...\n  [-0.8716578 ]\n  [-0.8707964 ]\n  [-0.870276  ]]]"}
{"time_total_s": 17.417936325073242, "pid": 7048, "time_this_iter_s": 2.204137086868286, "experiment_id": "c82d3f62007f4acf80e92badc93a7ea2", "timesteps_total": null, "timesteps_since_restore": 0, "training_iteration": 7, "config": {"workers": 2, "dataset": "Mallat", "num_rnn_layers": 1, "hidden_dims": 64, "learning_rate": 0.01, "fold": 9, "dropout": 0.3, "epochs": 99999, "earliness_factor": 1, "switch_epoch": 9999, "batchsize": 96}, "loss": 2.2189178466796875, "hostname": "e9379f55ba79", "timestamp": 1544558220, "confusion_matrix": "[[0. 0. 0. 2. 0. 0. 0. 0.]\n [0. 0. 0. 3. 0. 0. 0. 0.]\n [0. 0. 0. 1. 0. 0. 0. 0.]\n [0. 0. 0. 3. 0. 0. 0. 0.]\n [0. 0. 0. 1. 0. 0. 0. 0.]\n [0. 0. 0. 3. 0. 0. 0. 0.]\n [0. 0. 0. 1. 0. 0. 0. 0.]\n [0. 0. 0. 0. 0. 0. 0. 0.]]", "date": "2018-12-11_20-57-00", "targets": "[[5 5 5 ... 5 5 5]\n [5 5 5 ... 5 5 5]\n [1 1 1 ... 1 1 1]\n ...\n [0 0 0 ... 0 0 0]\n [5 5 5 ... 5 5 5]\n [1 1 1 ... 1 1 1]]", "episodes_total": null, "done": false, "iterations_since_restore": 7, "weights": "[[4.0727733e-05 4.0133189e-05 4.0339848e-05 ... 4.0172337e-05\n  4.0169733e-05 9.5832580e-01]\n [4.0069615e-05 3.9332346e-05 3.9644670e-05 ... 4.0181250e-05\n  4.0174280e-05 9.5828068e-01]\n [4.0918025e-05 4.0353003e-05 4.0513431e-05 ... 4.0153041e-05\n  4.0150095e-05 9.5815229e-01]\n ...\n [4.0499184e-05 3.9832128e-05 4.0049777e-05 ... 3.9957289e-05\n  3.9959436e-05 9.5800960e-01]\n [4.0309573e-05 3.9583545e-05 3.9811457e-05 ... 3.9992261e-05\n  4.0002531e-05 9.5839548e-01]\n [4.0947452e-05 4.0363968e-05 4.0487899e-05 ... 4.0147614e-05\n  4.0144627e-05 9.5808578e-01]]", "time_since_restore": 17.417936325073242, "node_ip": "172.17.0.2", "probas": "[[[0.10685443 0.12386899 0.11998826 ... 0.07814201 0.17724307 0.16715482]\n  [0.10556709 0.12401804 0.12104239 ... 0.08003298 0.17583513 0.16587597]\n  [0.1072223  0.12381779 0.1196847  ... 0.07761447 0.1776423  0.16752508]\n  ...\n  [0.10641003 0.12392588 0.12035368 ... 0.07878677 0.17675878 0.16671035]\n  [0.10603921 0.12396903 0.12065744 ... 0.07933126 0.17635316 0.16634187]\n  [0.10727904 0.12380955 0.11963779 ... 0.07753361 0.17770374 0.16758238]]\n\n [[0.10361401 0.12230535 0.12341926 ... 0.08063531 0.1759796  0.17125086]\n  [0.10094398 0.12172935 0.12567061 ... 0.08370416 0.17398623 0.17172731]\n  [0.10431616 0.12244532 0.12280044 ... 0.07985995 0.17648616 0.1711166 ]\n  ...\n  [0.10266109 0.12212936 0.12423367 ... 0.08173103 0.17525512 0.1713563 ]\n  [0.10184952 0.12196678 0.12491371 ... 0.08267864 0.17463338 0.17145929]\n  [0.10437243 0.1224722  0.12274447 ... 0.07981506 0.17650759 0.17105255]]\n\n [[0.10097032 0.12020196 0.12505488 ... 0.08194153 0.17700045 0.17529532]\n  [0.09689899 0.11847723 0.1278895  ... 0.08601356 0.17522424 0.17760158]\n  [0.10195481 0.12060666 0.12432421 ... 0.08102719 0.17735867 0.1747061 ]\n  ...\n  [0.09946247 0.11963474 0.12614127 ... 0.08345171 0.17631003 0.1760265 ]\n  [0.09815419 0.11911419 0.12705095 ... 0.08479786 0.17568581 0.17668562]\n  [0.10194434 0.12065098 0.1243334  ... 0.08108308 0.17728275 0.17459331]]\n\n ...\n\n [[0.10230035 0.11238249 0.12179037 ... 0.0822086  0.18629791 0.17581469]\n  [0.0994181  0.10541244 0.12302365 ... 0.08447621 0.1862249  0.18278654]\n  [0.1022419  0.11248533 0.1218071  ... 0.08226017 0.18626313 0.17574373]\n  ...\n  [0.0975577  0.10676515 0.12339984 ... 0.08638063 0.18600711 0.18169467]\n  [0.09479035 0.10196118 0.12415765 ... 0.08873014 0.18518332 0.18737887]\n  [0.10217021 0.1123656  0.12183657 ... 0.08232297 0.18627672 0.17584944]]\n\n [[0.10234746 0.11247452 0.1217737  ... 0.0821702  0.1862793  0.17573366]\n  [0.09971506 0.1060265  0.12292214 ... 0.08425341 0.186288   0.18209437]\n  [0.10226299 0.11252948 0.121801   ... 0.08224352 0.18625145 0.1757055 ]\n  ...\n  [0.09724191 0.1061721  0.12349049 ... 0.08664758 0.18595105 0.18235332]\n  [0.09438317 0.10117056 0.1242571  ... 0.08906116 0.18500537 0.18836837]\n  [0.10219163 0.11241106 0.12183036 ... 0.08230601 0.18626508 0.17580982]]\n\n [[0.10238541 0.1125612  0.12176084 ... 0.08213946 0.18625925 0.1756593 ]\n  [0.09998798 0.106617   0.12282524 ... 0.08404908 0.18633775 0.18144307]\n  [0.10227779 0.11257029 0.12179726 ... 0.08223197 0.18623938 0.1756714 ]\n  ...\n  [0.09692691 0.10557306 0.12358028 ... 0.08691233 0.18588254 0.18302971]\n  [0.09397408 0.10036561 0.12435547 ... 0.08939089 0.18480948 0.18939137]\n  [0.10220668 0.11245304 0.12182655 ... 0.08229434 0.186253   0.17577453]]]", "accuracy": 0.21428571428571427, "inputs": "[[[-0.884163  ]\n  [-0.8722339 ]\n  [-0.8617986 ]\n  ...\n  [-0.86358935]\n  [-0.8614071 ]\n  [-0.85974586]]\n\n [[-1.2018661 ]\n  [-1.1984447 ]\n  [-1.1953816 ]\n  ...\n  [-0.9929527 ]\n  [-0.98181814]\n  [-0.97144604]]\n\n [[-0.7941958 ]\n  [-0.79026073]\n  [-0.78699857]\n  ...\n  [-0.867568  ]\n  [-0.8667153 ]\n  [-0.8661968 ]]\n\n ...\n\n [[-0.99330217]\n  [-0.9936384 ]\n  [-0.994552  ]\n  ...\n  [-1.1170374 ]\n  [-1.130305  ]\n  [-1.1432737 ]]\n\n [[-1.0847987 ]\n  [-1.0974002 ]\n  [-1.1098067 ]\n  ...\n  [-1.2315367 ]\n  [-1.2457271 ]\n  [-1.2595538 ]]\n\n [[-0.7803517 ]\n  [-0.7895152 ]\n  [-0.7991167 ]\n  ...\n  [-0.8716578 ]\n  [-0.8707964 ]\n  [-0.870276  ]]]"}
{"time_total_s": 19.820732355117798, "pid": 7048, "time_this_iter_s": 2.4027960300445557, "experiment_id": "c82d3f62007f4acf80e92badc93a7ea2", "timesteps_total": null, "timesteps_since_restore": 0, "training_iteration": 8, "config": {"workers": 2, "dataset": "Mallat", "num_rnn_layers": 1, "hidden_dims": 64, "learning_rate": 0.01, "fold": 9, "dropout": 0.3, "epochs": 99999, "earliness_factor": 1, "switch_epoch": 9999, "batchsize": 96}, "loss": 2.2265374660491943, "hostname": "e9379f55ba79", "timestamp": 1544558222, "confusion_matrix": "[[0. 0. 0. 0. 0. 0. 2. 0.]\n [0. 0. 0. 0. 0. 0. 3. 0.]\n [0. 0. 0. 0. 0. 0. 1. 0.]\n [0. 0. 0. 0. 0. 0. 3. 0.]\n [0. 0. 0. 0. 0. 0. 1. 0.]\n [0. 0. 0. 0. 0. 0. 3. 0.]\n [0. 0. 0. 0. 0. 0. 1. 0.]\n [0. 0. 0. 0. 0. 0. 0. 0.]]", "date": "2018-12-11_20-57-02", "targets": "[[5 5 5 ... 5 5 5]\n [5 5 5 ... 5 5 5]\n [1 1 1 ... 1 1 1]\n ...\n [0 0 0 ... 0 0 0]\n [5 5 5 ... 5 5 5]\n [1 1 1 ... 1 1 1]]", "episodes_total": null, "done": false, "iterations_since_restore": 8, "weights": "[[4.0888342e-05 4.0292092e-05 4.0794937e-05 ... 4.1820069e-05\n  4.1811942e-05 9.5789033e-01]\n [4.0092738e-05 3.9337028e-05 4.0018847e-05 ... 4.2111751e-05\n  4.2083037e-05 9.5782709e-01]\n [4.1117633e-05 4.0550622e-05 4.0979812e-05 ... 4.1787789e-05\n  4.1781899e-05 9.5760936e-01]\n ...\n [4.0612464e-05 3.9934246e-05 4.0468705e-05 ... 4.1787072e-05\n  4.1810243e-05 9.5738935e-01]\n [4.0383256e-05 3.9636951e-05 4.0197370e-05 ... 4.1982123e-05\n  4.2015610e-05 9.5799655e-01]\n [4.1153093e-05 4.0562300e-05 4.0944185e-05 ... 4.1786188e-05\n  4.1780182e-05 9.5750147e-01]]", "time_since_restore": 19.820732355117798, "node_ip": "172.17.0.2", "probas": "[[[0.0997407  0.1290135  0.1234756  ... 0.07792281 0.18018238 0.16777174]\n  [0.09816653 0.12961063 0.12457048 ... 0.08030382 0.17878118 0.1659346 ]\n  [0.10018893 0.12883651 0.12315821 ... 0.07726067 0.18057562 0.16830122]\n  ...\n  [0.0991983  0.12922369 0.12385646 ... 0.07873335 0.17970288 0.16713484]\n  [0.09874487 0.12939592 0.12417204 ... 0.07941888 0.17929931 0.16660555]\n  [0.10025799 0.12880896 0.12310912 ... 0.07715926 0.18063596 0.16838303]]\n\n [[0.09600984 0.12856878 0.12715256 ... 0.08121557 0.1796421  0.17127527]\n  [0.09286908 0.12890531 0.12949052 ... 0.08512866 0.17787412 0.1708833 ]\n  [0.09683656 0.12847021 0.12650199 ... 0.08022771 0.1800729  0.1713616 ]\n  ...\n  [0.09488615 0.12871926 0.12800215 ... 0.08261108 0.17900024 0.17106767]\n  [0.09392999 0.12883563 0.12870705 ... 0.08381909 0.1784409  0.17090142]\n  [0.09690133 0.12847903 0.12644185 ... 0.08016955 0.18008132 0.17130871]]\n\n [[0.09354898 0.12750468 0.12888987 ... 0.08293103 0.18166974 0.17422378]\n  [0.0890999  0.12714718 0.1317996  ... 0.08800373 0.18048073 0.17512225]\n  [0.09462231 0.12757389 0.12812352 ... 0.08178646 0.18184474 0.1739734 ]\n  ...\n  [0.0918868  0.12745084 0.1300133  ... 0.0848182  0.18120043 0.1744282 ]\n  [0.09044756 0.127373   0.1309429  ... 0.08649785 0.18074585 0.17462988]\n  [0.09459791 0.12762329 0.12812957 ... 0.08185691 0.18174796 0.17385238]]\n\n ...\n\n [[0.09974299 0.12361162 0.12630537 ... 0.08255634 0.19171228 0.16921124]\n  [0.09780481 0.11965754 0.12748966 ... 0.08470368 0.19262722 0.1731739 ]\n  [0.09967227 0.12368139 0.12631685 ... 0.08261448 0.1916745  0.16916548]\n  ...\n  [0.09591553 0.12059358 0.12783356 ... 0.08674729 0.19238245 0.17239042]\n  [0.09373824 0.11753228 0.12849447 ... 0.08899054 0.19226462 0.17624946]\n  [0.09962127 0.12361922 0.12634736 ... 0.08267751 0.19170634 0.16921388]]\n\n [[0.09977042 0.12366223 0.1262884  ... 0.08252039 0.19168013 0.16917229]\n  [0.09801159 0.12002856 0.12739995 ... 0.08450264 0.19259323 0.17274061]\n  [0.09968228 0.12370643 0.12631065 ... 0.08259986 0.19165672 0.16914709]\n  ...\n  [0.09568201 0.12022689 0.12791695 ... 0.08699832 0.19240992 0.17281717]\n  [0.09342118 0.11699797 0.12857424 ... 0.08929725 0.19220307 0.17696323]\n  [0.09963144 0.1236451  0.126341   ... 0.08266267 0.19168842 0.16919453]]\n\n [[0.0997891  0.1237108  0.1262749  ... 0.0824926  0.19164838 0.16913655]\n  [0.09819777 0.1203812  0.12731354 ... 0.0843183  0.19255199 0.17233983]\n  [0.09968659 0.12373018 0.12630655 ... 0.08259062 0.19163965 0.16913053]\n  ...\n  [0.0954469  0.11985271 0.12799841 ... 0.08724688 0.19242609 0.17326216]\n  [0.09310071 0.11644724 0.12865146 ... 0.08960207 0.1921265  0.1777103 ]\n  [0.09963588 0.1236696  0.12633686 ... 0.08265333 0.19167128 0.16917719]]]", "accuracy": 0.07142857142857142, "inputs": "[[[-0.884163  ]\n  [-0.8722339 ]\n  [-0.8617986 ]\n  ...\n  [-0.86358935]\n  [-0.8614071 ]\n  [-0.85974586]]\n\n [[-1.2018661 ]\n  [-1.1984447 ]\n  [-1.1953816 ]\n  ...\n  [-0.9929527 ]\n  [-0.98181814]\n  [-0.97144604]]\n\n [[-0.7941958 ]\n  [-0.79026073]\n  [-0.78699857]\n  ...\n  [-0.867568  ]\n  [-0.8667153 ]\n  [-0.8661968 ]]\n\n ...\n\n [[-0.99330217]\n  [-0.9936384 ]\n  [-0.994552  ]\n  ...\n  [-1.1170374 ]\n  [-1.130305  ]\n  [-1.1432737 ]]\n\n [[-1.0847987 ]\n  [-1.0974002 ]\n  [-1.1098067 ]\n  ...\n  [-1.2315367 ]\n  [-1.2457271 ]\n  [-1.2595538 ]]\n\n [[-0.7803517 ]\n  [-0.7895152 ]\n  [-0.7991167 ]\n  ...\n  [-0.8716578 ]\n  [-0.8707964 ]\n  [-0.870276  ]]]"}
{"time_total_s": 21.887689113616943, "pid": 7048, "time_this_iter_s": 2.0669567584991455, "experiment_id": "c82d3f62007f4acf80e92badc93a7ea2", "timesteps_total": null, "timesteps_since_restore": 0, "training_iteration": 9, "config": {"workers": 2, "dataset": "Mallat", "num_rnn_layers": 1, "hidden_dims": 64, "learning_rate": 0.01, "fold": 9, "dropout": 0.3, "epochs": 99999, "earliness_factor": 1, "switch_epoch": 9999, "batchsize": 96}, "loss": 2.2045493125915527, "hostname": "e9379f55ba79", "timestamp": 1544558224, "confusion_matrix": "[[0. 0. 0. 0. 0. 0. 2. 0.]\n [0. 0. 0. 0. 0. 0. 3. 0.]\n [0. 0. 0. 0. 0. 0. 1. 0.]\n [0. 0. 0. 0. 0. 0. 3. 0.]\n [0. 0. 0. 0. 0. 0. 1. 0.]\n [0. 0. 0. 0. 0. 0. 3. 0.]\n [0. 0. 0. 0. 0. 0. 1. 0.]\n [0. 0. 0. 0. 0. 0. 0. 0.]]", "date": "2018-12-11_20-57-04", "targets": "[[5 5 5 ... 5 5 5]\n [5 5 5 ... 5 5 5]\n [1 1 1 ... 1 1 1]\n ...\n [0 0 0 ... 0 0 0]\n [5 5 5 ... 5 5 5]\n [1 1 1 ... 1 1 1]]", "episodes_total": null, "done": false, "iterations_since_restore": 9, "weights": "[[4.1379928e-05 4.0798855e-05 4.1700991e-05 ... 4.3105265e-05\n  4.3097694e-05 9.5796508e-01]\n [4.0387800e-05 3.9640199e-05 4.0807510e-05 ... 4.3189579e-05\n  4.3180378e-05 9.5756030e-01]\n [4.1665742e-05 4.1109059e-05 4.1901560e-05 ... 4.3018539e-05\n  4.3012707e-05 9.5643711e-01]\n ...\n [4.1036034e-05 4.0365045e-05 4.1323954e-05 ... 4.2827778e-05\n  4.2828720e-05 9.5587456e-01]\n [4.0750190e-05 4.0003230e-05 4.1005263e-05 ... 4.2924767e-05\n  4.2924148e-05 9.5861870e-01]\n [4.1709907e-05 4.1121326e-05 4.1851719e-05 ... 4.3006497e-05\n  4.3000629e-05 9.5615578e-01]]", "time_since_restore": 21.887689113616943, "node_ip": "172.17.0.2", "probas": "[[[0.09809618 0.13367186 0.12256088 ... 0.07338755 0.16970828 0.17510112]\n  [0.09595198 0.13410103 0.12363263 ... 0.07551175 0.168685   0.17322218]\n  [0.09870871 0.13354018 0.12224786 ... 0.07279789 0.16998863 0.17564514]\n  ...\n  [0.09735616 0.13382582 0.12293521 ... 0.07410998 0.1693623  0.1744482 ]\n  [0.09673847 0.13394971 0.12324419 ... 0.07472153 0.1690676  0.1739068 ]\n  [0.09880316 0.13351952 0.12219934 ... 0.07270764 0.17003135 0.17572933]]\n\n [[0.09277208 0.13186662 0.12675032 ... 0.07458391 0.17171879 0.18095046]\n  [0.08853997 0.13156468 0.12919503 ... 0.07740843 0.17112236 0.18138559]\n  [0.09390127 0.13194399 0.12605944 ... 0.07388816 0.17180662 0.18080722]\n  ...\n  [0.0912509  0.13179469 0.12764053 ... 0.07560004 0.17150146 0.18102148]\n  [0.08996454 0.13172321 0.1283741  ... 0.0764846  0.17128742 0.18109208]\n  [0.09399243 0.13197507 0.12599126 ... 0.07386348 0.17177369 0.18071704]]\n\n [[0.08950736 0.1295486  0.12917297 ... 0.07374492 0.17660627 0.18539801]\n  [0.08372799 0.12814598 0.13238129 ... 0.07664845 0.17750603 0.18769161]\n  [0.09092782 0.1298966  0.12830514 ... 0.07314656 0.17618999 0.18479124]\n  ...\n  [0.08733185 0.12911575 0.1304108  ... 0.07485302 0.17692329 0.18609   ]\n  [0.08546575 0.12871806 0.13142426 ... 0.0758573  0.17710628 0.18671577]\n  [0.09089821 0.12996513 0.12829694 ... 0.07324418 0.17605607 0.18464011]]\n\n ...\n\n [[0.09780267 0.12729521 0.13115875 ... 0.07090953 0.19288322 0.17185493]\n  [0.09604711 0.12564449 0.1328755  ... 0.07146994 0.19584505 0.17210141]\n  [0.09772472 0.12731962 0.13115682 ... 0.07093562 0.19284324 0.17188077]\n  ...\n  [0.09392661 0.1255339  0.133352   ... 0.07224172 0.19620411 0.17260374]\n  [0.09195357 0.12411737 0.13440116 ... 0.07291296 0.19775334 0.17375289]\n  [0.09767206 0.12728529 0.13120449 ... 0.07095408 0.19292547 0.17187442]]\n\n [[0.0978272  0.12732436 0.13112858 ... 0.07090573 0.19281471 0.17186043]\n  [0.0962185  0.12579398 0.1327484  ... 0.07142483 0.19562587 0.17202833]\n  [0.09773209 0.1273343  0.13114369 ... 0.07093622 0.19280806 0.17188478]\n  ...\n  [0.09371543 0.12536196 0.1334911  ... 0.07231171 0.19643274 0.17270337]\n  [0.09169036 0.12389099 0.13453352 ... 0.07299706 0.19794478 0.1739683 ]\n  [0.09767954 0.12730034 0.13119112 ... 0.07095464 0.19288987 0.17187832]]\n\n [[0.0978422  0.12735146 0.1311023  ... 0.07090463 0.1927507  0.17186873]\n  [0.09637278 0.12593514 0.13262556 ... 0.07138374 0.19541138 0.17196964]\n  [0.09773346 0.12734754 0.13113305 ... 0.07093829 0.19277664 0.1718906 ]\n  ...\n  [0.09350463 0.12519038 0.13362557 ... 0.07238187 0.19664836 0.1728122 ]\n  [0.0914288  0.12366314 0.13466127 ... 0.07308081 0.19812368 0.1741948 ]\n  [0.097681   0.12731387 0.13118027 ... 0.07095671 0.19285809 0.17188394]]]", "accuracy": 0.07142857142857142, "inputs": "[[[-0.884163  ]\n  [-0.8722339 ]\n  [-0.8617986 ]\n  ...\n  [-0.86358935]\n  [-0.8614071 ]\n  [-0.85974586]]\n\n [[-1.2018661 ]\n  [-1.1984447 ]\n  [-1.1953816 ]\n  ...\n  [-0.9929527 ]\n  [-0.98181814]\n  [-0.97144604]]\n\n [[-0.7941958 ]\n  [-0.79026073]\n  [-0.78699857]\n  ...\n  [-0.867568  ]\n  [-0.8667153 ]\n  [-0.8661968 ]]\n\n ...\n\n [[-0.99330217]\n  [-0.9936384 ]\n  [-0.994552  ]\n  ...\n  [-1.1170374 ]\n  [-1.130305  ]\n  [-1.1432737 ]]\n\n [[-1.0847987 ]\n  [-1.0974002 ]\n  [-1.1098067 ]\n  ...\n  [-1.2315367 ]\n  [-1.2457271 ]\n  [-1.2595538 ]]\n\n [[-0.7803517 ]\n  [-0.7895152 ]\n  [-0.7991167 ]\n  ...\n  [-0.8716578 ]\n  [-0.8707964 ]\n  [-0.870276  ]]]"}
{"time_total_s": 23.889479637145996, "pid": 7048, "time_this_iter_s": 2.0017905235290527, "experiment_id": "c82d3f62007f4acf80e92badc93a7ea2", "timesteps_total": null, "timesteps_since_restore": 0, "training_iteration": 10, "config": {"workers": 2, "dataset": "Mallat", "num_rnn_layers": 1, "hidden_dims": 64, "learning_rate": 0.01, "fold": 9, "dropout": 0.3, "epochs": 99999, "earliness_factor": 1, "switch_epoch": 9999, "batchsize": 96}, "loss": 2.248584508895874, "hostname": "e9379f55ba79", "timestamp": 1544558226, "confusion_matrix": "[[0. 0. 0. 2. 0. 0. 0. 0.]\n [0. 0. 0. 3. 0. 0. 0. 0.]\n [0. 0. 0. 1. 0. 0. 0. 0.]\n [0. 0. 0. 2. 0. 0. 0. 1.]\n [0. 0. 0. 1. 0. 0. 0. 0.]\n [0. 0. 0. 2. 0. 0. 0. 1.]\n [0. 0. 0. 1. 0. 0. 0. 0.]\n [0. 0. 0. 0. 0. 0. 0. 0.]]", "date": "2018-12-11_20-57-06", "targets": "[[5 5 5 ... 5 5 5]\n [5 5 5 ... 5 5 5]\n [1 1 1 ... 1 1 1]\n ...\n [0 0 0 ... 0 0 0]\n [5 5 5 ... 5 5 5]\n [1 1 1 ... 1 1 1]]", "episodes_total": null, "done": true, "iterations_since_restore": 10, "weights": "[[4.2859599e-05 4.2613443e-05 4.4410281e-05 ... 4.8796719e-05\n  4.8777209e-05 9.5878953e-01]\n [4.1714960e-05 4.1405317e-05 4.3730688e-05 ... 4.9553564e-05\n  4.9489139e-05 9.5878404e-01]\n [4.3188444e-05 4.2931541e-05 4.4537908e-05 ... 4.8767972e-05\n  4.8755770e-05 9.5884264e-01]\n ...\n [4.2463384e-05 4.2158692e-05 4.4101977e-05 ... 4.9207873e-05\n  4.9268638e-05 9.5889246e-01]\n [4.2133630e-05 4.1777850e-05 4.3836753e-05 ... 4.9651058e-05\n  4.9723440e-05 9.5889258e-01]\n [4.3239219e-05 4.2939238e-05 4.4467291e-05 ... 4.8775924e-05\n  4.8763588e-05 9.5871651e-01]]", "time_since_restore": 23.889479637145996, "node_ip": "172.17.0.2", "probas": "[[[0.10573708 0.13623132 0.12239975 ... 0.06912566 0.16373652 0.17624027]\n  [0.10324831 0.13628462 0.12473509 ... 0.07156261 0.1623181  0.17352036]\n  [0.10644015 0.13618383 0.12175182 ... 0.06845536 0.16411927 0.1770354 ]\n  ...\n  [0.10488293 0.13627009 0.12319386 ... 0.06995057 0.16326073 0.17529052]\n  [0.1041661  0.13628627 0.12386627 ... 0.07065201 0.16285247 0.17450678]\n  [0.10654819 0.13617526 0.12165264 ... 0.06835297 0.16417736 0.17715871]]\n\n [[0.09818932 0.1330058  0.13207996 ... 0.07163223 0.16604242 0.18083596]\n  [0.09258601 0.13119712 0.13843775 ... 0.07544891 0.16489029 0.18028575]\n  [0.09967025 0.13341002 0.1304147  ... 0.07069639 0.1662353  0.18099025]\n  ...\n  [0.09619648 0.13244857 0.13431022 ... 0.07298493 0.16564678 0.18051864]\n  [0.09449984 0.1319204  0.13622488 ... 0.07417037 0.1652587  0.180283  ]\n  [0.0997989  0.13346958 0.13025473 ... 0.07065026 0.16620293 0.180917  ]]\n\n [[0.09269901 0.12818646 0.1412989  ... 0.07190626 0.17042178 0.1850912 ]\n  [0.08423477 0.12339881 0.15194061 ... 0.0764667  0.17017798 0.18676762]\n  [0.09476359 0.12925099 0.13869229 ... 0.07093859 0.17020787 0.18468872]\n  ...\n  [0.08956441 0.12660761 0.14516829 ... 0.07359897 0.17037441 0.1854784 ]\n  [0.08685394 0.125131   0.14853887 ... 0.07513765 0.17018697 0.18588613]\n  [0.09475403 0.12933703 0.13864008 ... 0.0710356  0.17007037 0.18450716]]\n\n ...\n\n [[0.09928414 0.12154282 0.1519198  ... 0.06763647 0.17730428 0.17551938]\n  [0.09413984 0.11555278 0.16080098 ... 0.0691376  0.17760871 0.17754857]\n  [0.09919956 0.12156495 0.15196389 ... 0.067684   0.17733751 0.17547742]\n  ...\n  [0.09087289 0.11391554 0.16482018 ... 0.07062143 0.1784418  0.17717557]\n  [0.08625066 0.10893813 0.17216697 ... 0.07220734 0.17799903 0.17936654]\n  [0.0990634  0.12142528 0.15219423 ... 0.06772705 0.17736718 0.1755015 ]]\n\n [[0.09936797 0.12164861 0.15175793 ... 0.06761626 0.17727788 0.17549801]\n  [0.09460571 0.11608373 0.16002487 ... 0.06900092 0.17760289 0.17733972]\n  [0.09923492 0.12161618 0.15188828 ... 0.0676773  0.1773238  0.17546713]\n  ...\n  [0.09033421 0.1133067  0.16571535 ... 0.07079505 0.17841567 0.17742144]\n  [0.08561257 0.10820699 0.17318946 ... 0.0724199  0.17787124 0.1797557 ]\n  [0.09909942 0.12147757 0.15211733 ... 0.0677202  0.17735365 0.17549068]]\n\n [[0.09943502 0.12174319 0.15161784 ... 0.06760202 0.17725621 0.17547792]\n  [0.09503868 0.11658522 0.15929376 ... 0.06887523 0.17759585 0.17714612]\n  [0.09925922 0.12165953 0.15182757 ... 0.06767426 0.1773138  0.17545757]\n  ...\n  [0.08980118 0.11270475 0.1665946  ... 0.07096803 0.17837757 0.17767577]\n  [0.08498102 0.10748123 0.1741958  ... 0.07263128 0.17772871 0.18015662]\n  [0.09912426 0.12152181 0.1520557  ... 0.06771713 0.1773438  0.17548056]]]", "accuracy": 0.14285714285714285, "inputs": "[[[-0.884163  ]\n  [-0.8722339 ]\n  [-0.8617986 ]\n  ...\n  [-0.86358935]\n  [-0.8614071 ]\n  [-0.85974586]]\n\n [[-1.2018661 ]\n  [-1.1984447 ]\n  [-1.1953816 ]\n  ...\n  [-0.9929527 ]\n  [-0.98181814]\n  [-0.97144604]]\n\n [[-0.7941958 ]\n  [-0.79026073]\n  [-0.78699857]\n  ...\n  [-0.867568  ]\n  [-0.8667153 ]\n  [-0.8661968 ]]\n\n ...\n\n [[-0.99330217]\n  [-0.9936384 ]\n  [-0.994552  ]\n  ...\n  [-1.1170374 ]\n  [-1.130305  ]\n  [-1.1432737 ]]\n\n [[-1.0847987 ]\n  [-1.0974002 ]\n  [-1.1098067 ]\n  ...\n  [-1.2315367 ]\n  [-1.2457271 ]\n  [-1.2595538 ]]\n\n [[-0.7803517 ]\n  [-0.7895152 ]\n  [-0.7991167 ]\n  ...\n  [-0.8716578 ]\n  [-0.8707964 ]\n  [-0.870276  ]]]"}

{"time_total_s": 2.5011560916900635, "pid": 7040, "time_this_iter_s": 2.5011560916900635, "experiment_id": "cfbde1b0c87e48d5afbf09a3e7e7d1db", "timesteps_total": null, "timesteps_since_restore": 0, "training_iteration": 1, "config": {"workers": 2, "learning_rate": 0.01, "num_rnn_layers": 1, "hidden_dims": 128, "epochs": 99999, "dataset": "Mallat", "dropout": 0.3, "fold": 5, "earliness_factor": 1, "switch_epoch": 9999, "batchsize": 96}, "loss": 2.059753656387329, "hostname": "e9379f55ba79", "timestamp": 1544558204, "confusion_matrix": "[[0. 1. 0. 0. 0. 0. 0. 0.]\n [0. 1. 0. 0. 0. 0. 0. 0.]\n [0. 0. 0. 0. 0. 0. 0. 0.]\n [0. 4. 0. 0. 0. 0. 0. 0.]\n [0. 0. 0. 0. 0. 0. 0. 0.]\n [0. 1. 0. 0. 0. 0. 0. 0.]\n [0. 3. 0. 0. 0. 0. 0. 0.]\n [0. 1. 0. 0. 0. 0. 0. 0.]]", "date": "2018-12-11_20-56-44", "targets": "[[3 3 3 ... 3 3 3]\n [6 6 6 ... 6 6 6]\n [3 3 3 ... 3 3 3]\n ...\n [3 3 3 ... 3 3 3]\n [6 6 6 ... 6 6 6]\n [1 1 1 ... 1 1 1]]", "episodes_total": null, "done": false, "iterations_since_restore": 1, "weights": "[[4.5586236e-05 4.5399174e-05 4.5258621e-05 ... 4.3244829e-05\n  4.3242329e-05 9.5300728e-01]\n [4.5564724e-05 4.5349851e-05 4.5189576e-05 ... 4.3234064e-05\n  4.3233336e-05 9.5302540e-01]\n [4.5629513e-05 4.5496254e-05 4.5392735e-05 ... 4.3250042e-05\n  4.3247870e-05 9.5301032e-01]\n ...\n [4.5593973e-05 4.5414763e-05 4.5276789e-05 ... 4.3214095e-05\n  4.3209991e-05 9.5299590e-01]\n [4.5608544e-05 4.5449466e-05 4.5328368e-05 ... 4.3296830e-05\n  4.3294123e-05 9.5301741e-01]\n [4.5619854e-05 4.5472618e-05 4.5356384e-05 ... 4.3281001e-05\n  4.3279411e-05 9.5302886e-01]]", "time_since_restore": 2.5011560916900635, "node_ip": "172.17.0.2", "probas": "[[[0.10813031 0.13829562 0.13941564 ... 0.1196619  0.13191566 0.1298169 ]\n  [0.10791532 0.13841027 0.1395833  ... 0.11966258 0.13201939 0.12969854]\n  [0.10852485 0.13808064 0.13911791 ... 0.11965851 0.13172704 0.13002893]\n  ...\n  [0.10820401 0.1382559  0.13935906 ... 0.1196615  0.13188028 0.12985699]\n  [0.10833888 0.13818271 0.13925672 ... 0.11966047 0.1318157  0.12992977]\n  [0.10844025 0.13812728 0.13918075 ... 0.11965951 0.13176735 0.12998402]]\n\n [[0.10809498 0.13865468 0.13896398 ... 0.11955433 0.13162683 0.12988241]\n  [0.10787789 0.13883625 0.13905266 ... 0.11953664 0.1316632  0.12977691]\n  [0.10848364 0.13832635 0.13882314 ... 0.11958538 0.13155445 0.13006379]\n  ...\n  [0.1081464  0.13860516 0.13895275 ... 0.11956032 0.13162373 0.12990567]\n  [0.10830122 0.13848068 0.1388869  ... 0.11957099 0.13158979 0.12997966]\n  [0.10837927 0.13840862 0.13886777 ... 0.11957902 0.1315805  0.13001455]]\n\n [[0.10845889 0.13890271 0.13827622 ... 0.11946686 0.13106199 0.1302452 ]\n  [0.10833171 0.13912427 0.13823684 ... 0.11942796 0.13097629 0.13022073]\n  [0.10869228 0.13850667 0.13837081 ... 0.11953236 0.13119738 0.13028522]\n  ...\n  [0.1084634  0.13885741 0.1383145  ... 0.11947726 0.13109973 0.13023457]\n  [0.10858231 0.13869163 0.138323   ... 0.11950243 0.13113672 0.13026677]\n  [0.10860258 0.13862023 0.1383703  ... 0.11951683 0.131182   0.13025846]]\n\n ...\n\n [[0.11045159 0.13877444 0.13809311 ... 0.11961746 0.13008252 0.13158746]\n  [0.11055025 0.13878551 0.13808344 ... 0.11960085 0.13005987 0.13164884]\n  [0.11043929 0.13876064 0.13809872 ... 0.11962433 0.130092   0.13157608]\n  ...\n  [0.11051523 0.13885738 0.13805516 ... 0.11957557 0.13002443 0.13164896]\n  [0.11025853 0.13864714 0.13816004 ... 0.1196847  0.13019852 0.13142756]\n  [0.11035733 0.13868138 0.13814032 ... 0.11966435 0.13015564 0.13150036]]\n\n [[0.11045409 0.13877566 0.13809294 ... 0.11961675 0.13008171 0.13158922]\n  [0.11054509 0.13878296 0.13808548 ... 0.11960268 0.1300627  0.13164487]\n  [0.1104415  0.13876075 0.13809879 ... 0.11962404 0.13009167 0.13157739]\n  ...\n  [0.11052387 0.13886212 0.13805324 ... 0.11957248 0.13002062 0.13165516]\n  [0.11026067 0.1386493  0.1381595  ... 0.11968384 0.1301971  0.13142955]\n  [0.11035493 0.13868082 0.13814135 ... 0.11966489 0.130157   0.13149855]]\n\n [[0.11045635 0.13877708 0.1380927  ... 0.11961598 0.13008088 0.13159089]\n  [0.11053989 0.13878076 0.13808729 ... 0.11960436 0.13006526 0.13164102]\n  [0.11044345 0.13876094 0.13809898 ... 0.11962385 0.13009144 0.13157855]\n  ...\n  [0.1105322  0.13886707 0.13805135 ... 0.11956932 0.13001688 0.13166118]\n  [0.1102627  0.13865171 0.1381588  ... 0.11968284 0.13019554 0.13143153]\n  [0.11035246 0.13868058 0.13814212 ... 0.11966527 0.13015811 0.13149679]]]", "accuracy": 0.09090909090909091, "inputs": "[[[-1.0574203 ]\n  [-1.0514047 ]\n  [-1.0463719 ]\n  ...\n  [-0.9943956 ]\n  [-0.9967297 ]\n  [-0.99922913]]\n\n [[-1.2535369 ]\n  [-1.2642459 ]\n  [-1.2733136 ]\n  ...\n  [-1.0389028 ]\n  [-1.034854  ]\n  [-1.0311028 ]]\n\n [[-0.70577186]\n  [-0.69676715]\n  [-0.689986  ]\n  ...\n  [-0.9754479 ]\n  [-0.9764079 ]\n  [-0.9773511 ]]\n\n ...\n\n [[-0.9909409 ]\n  [-1.0027453 ]\n  [-1.0147117 ]\n  ...\n  [-1.1046433 ]\n  [-1.1131419 ]\n  [-1.1218793 ]]\n\n [[-0.8702758 ]\n  [-0.85922086]\n  [-0.84914935]\n  ...\n  [-0.811603  ]\n  [-0.8145301 ]\n  [-0.8177387 ]]\n\n [[-0.7803517 ]\n  [-0.7895152 ]\n  [-0.7991167 ]\n  ...\n  [-0.8716578 ]\n  [-0.8707964 ]\n  [-0.870276  ]]]"}
{"time_total_s": 5.106909275054932, "pid": 7040, "time_this_iter_s": 2.605753183364868, "experiment_id": "cfbde1b0c87e48d5afbf09a3e7e7d1db", "timesteps_total": null, "timesteps_since_restore": 0, "training_iteration": 2, "config": {"workers": 2, "learning_rate": 0.01, "num_rnn_layers": 1, "hidden_dims": 128, "epochs": 99999, "dataset": "Mallat", "dropout": 0.3, "fold": 5, "earliness_factor": 1, "switch_epoch": 9999, "batchsize": 96}, "loss": 1.9801846742630005, "hostname": "e9379f55ba79", "timestamp": 1544558207, "confusion_matrix": "[[0. 1. 0. 0. 0. 0. 0. 0.]\n [0. 1. 0. 0. 0. 0. 0. 0.]\n [0. 0. 0. 0. 0. 0. 0. 0.]\n [0. 4. 0. 0. 0. 0. 0. 0.]\n [0. 0. 0. 0. 0. 0. 0. 0.]\n [0. 1. 0. 0. 0. 0. 0. 0.]\n [0. 3. 0. 0. 0. 0. 0. 0.]\n [0. 1. 0. 0. 0. 0. 0. 0.]]", "date": "2018-12-11_20-56-47", "targets": "[[3 3 3 ... 3 3 3]\n [6 6 6 ... 6 6 6]\n [3 3 3 ... 3 3 3]\n ...\n [3 3 3 ... 3 3 3]\n [6 6 6 ... 6 6 6]\n [1 1 1 ... 1 1 1]]", "episodes_total": null, "done": false, "iterations_since_restore": 2, "weights": "[[4.4926492e-05 4.4690358e-05 4.4625671e-05 ... 4.3866392e-05\n  4.3866592e-05 9.5233697e-01]\n [4.4898952e-05 4.4633030e-05 4.4579610e-05 ... 4.3924203e-05\n  4.3918786e-05 9.5216537e-01]\n [4.4982138e-05 4.4808094e-05 4.4734614e-05 ... 4.3853721e-05\n  4.3853375e-05 9.5231706e-01]\n ...\n [4.4936387e-05 4.4708857e-05 4.4637378e-05 ... 4.3923868e-05\n  4.3928583e-05 9.5230967e-01]\n [4.4955083e-05 4.4750577e-05 4.4679196e-05 ... 4.3693344e-05\n  4.3693883e-05 9.5217401e-01]\n [4.4969660e-05 4.4778881e-05 4.4701144e-05 ... 4.3781743e-05\n  4.3778440e-05 9.5231497e-01]]", "time_since_restore": 5.106909275054932, "node_ip": "172.17.0.2", "probas": "[[[0.10339811 0.15591416 0.13799267 ... 0.1043691  0.13325611 0.13391784]\n  [0.1030296  0.15609498 0.1382301  ... 0.10427259 0.13330796 0.1338003 ]\n  [0.10407978 0.1555686  0.13756719 ... 0.10454383 0.13315949 0.1341304 ]\n  ...\n  [0.10352495 0.15585095 0.13791218 ... 0.10440197 0.13323821 0.13395785]\n  [0.1037576  0.15573363 0.13776614 ... 0.10446183 0.13320525 0.13403066]\n  [0.103933   0.15564418 0.13765737 ... 0.1045066  0.13318035 0.13408512]]\n\n [[0.10321314 0.1567715  0.13730021 ... 0.10371701 0.13195834 0.13432801]\n  [0.10283541 0.15706775 0.13741079 ... 0.10353307 0.131768   0.13429308]\n  [0.10390922 0.15619199 0.13712089 ... 0.10407052 0.13229918 0.13438977]\n  ...\n  [0.10330629 0.15668465 0.13728832 ... 0.10377266 0.1320272  0.13432859]\n  [0.10357953 0.15647088 0.13720286 ... 0.10390117 0.13214    0.13436055]\n  [0.10372262 0.15633866 0.1371804  ... 0.10398409 0.13223165 0.13436556]]\n\n [[0.10335234 0.15761194 0.13715956 ... 0.10334285 0.13078947 0.13455187]\n  [0.1030043  0.15792602 0.13728985 ... 0.10315198 0.13046452 0.13457292]\n  [0.10397283 0.15690005 0.136992   ... 0.10374992 0.1314295  0.13451844]\n  ...\n  [0.10340223 0.15753087 0.13715479 ... 0.10339084 0.13089249 0.13453433]\n  [0.10368286 0.15725547 0.13706042 ... 0.10354936 0.13112055 0.13453314]\n  [0.10377179 0.15710996 0.13705271 ... 0.10363217 0.13127527 0.13451344]]\n\n ...\n\n [[0.09265783 0.15549254 0.14890641 ... 0.10995021 0.14217617 0.13312614]\n  [0.09169623 0.15436164 0.14888038 ... 0.11057682 0.14326084 0.13372608]\n  [0.09280089 0.15564334 0.14888595 ... 0.10988186 0.14203356 0.13305375]\n  ...\n  [0.09196203 0.15470223 0.14899576 ... 0.11026672 0.1428793  0.13348816]\n  [0.09484354 0.15749197 0.1484783  ... 0.10883403 0.14005674 0.13208966]\n  [0.09371031 0.15653443 0.14872691 ... 0.10944846 0.14115298 0.132616  ]]\n\n [[0.09262637 0.15545863 0.14890829 ... 0.10996874 0.1422097  0.1331441 ]\n  [0.09173073 0.15440437 0.14887774 ... 0.11055896 0.14322354 0.13370681]\n  [0.09277719 0.15561818 0.14888726 ... 0.10989682 0.14205922 0.13306746]\n  ...\n  [0.09187666 0.15459907 0.14899798 ... 0.11031581 0.14297348 0.13353916]\n  [0.0948082  0.1574657  0.14848845 ... 0.108851   0.14008883 0.13210408]\n  [0.09372193 0.15654536 0.1487235  ... 0.10944311 0.1411419  0.13261132]]\n\n [[0.09259585 0.15542565 0.14891    ... 0.10998646 0.14224209 0.13316153]\n  [0.09176647 0.15444846 0.14887565 ... 0.11053965 0.14318457 0.13368647]\n  [0.09275518 0.15559475 0.14888825 ... 0.10991073 0.14208308 0.1330803 ]\n  ...\n  [0.09179201 0.15449554 0.14899921 ... 0.11036467 0.14306746 0.13359036]\n  [0.09477272 0.15743919 0.14849855 ... 0.10886768 0.14012082 0.13211854]\n  [0.09373382 0.15655659 0.14872035 ... 0.10943706 0.14113027 0.1326063 ]]]", "accuracy": 0.09090909090909091, "inputs": "[[[-1.0574203 ]\n  [-1.0514047 ]\n  [-1.0463719 ]\n  ...\n  [-0.9943956 ]\n  [-0.9967297 ]\n  [-0.99922913]]\n\n [[-1.2535369 ]\n  [-1.2642459 ]\n  [-1.2733136 ]\n  ...\n  [-1.0389028 ]\n  [-1.034854  ]\n  [-1.0311028 ]]\n\n [[-0.70577186]\n  [-0.69676715]\n  [-0.689986  ]\n  ...\n  [-0.9754479 ]\n  [-0.9764079 ]\n  [-0.9773511 ]]\n\n ...\n\n [[-0.9909409 ]\n  [-1.0027453 ]\n  [-1.0147117 ]\n  ...\n  [-1.1046433 ]\n  [-1.1131419 ]\n  [-1.1218793 ]]\n\n [[-0.8702758 ]\n  [-0.85922086]\n  [-0.84914935]\n  ...\n  [-0.811603  ]\n  [-0.8145301 ]\n  [-0.8177387 ]]\n\n [[-0.7803517 ]\n  [-0.7895152 ]\n  [-0.7991167 ]\n  ...\n  [-0.8716578 ]\n  [-0.8707964 ]\n  [-0.870276  ]]]"}
{"time_total_s": 7.6797990798950195, "pid": 7040, "time_this_iter_s": 2.572889804840088, "experiment_id": "cfbde1b0c87e48d5afbf09a3e7e7d1db", "timesteps_total": null, "timesteps_since_restore": 0, "training_iteration": 3, "config": {"workers": 2, "learning_rate": 0.01, "num_rnn_layers": 1, "hidden_dims": 128, "epochs": 99999, "dataset": "Mallat", "dropout": 0.3, "fold": 5, "earliness_factor": 1, "switch_epoch": 9999, "batchsize": 96}, "loss": 1.9375499486923218, "hostname": "e9379f55ba79", "timestamp": 1544558209, "confusion_matrix": "[[0. 1. 0. 0. 0. 0. 0. 0.]\n [0. 1. 0. 0. 0. 0. 0. 0.]\n [0. 0. 0. 0. 0. 0. 0. 0.]\n [0. 4. 0. 0. 0. 0. 0. 0.]\n [0. 0. 0. 0. 0. 0. 0. 0.]\n [0. 1. 0. 0. 0. 0. 0. 0.]\n [0. 3. 0. 0. 0. 0. 0. 0.]\n [0. 1. 0. 0. 0. 0. 0. 0.]]", "date": "2018-12-11_20-56-49", "targets": "[[3 3 3 ... 3 3 3]\n [6 6 6 ... 6 6 6]\n [3 3 3 ... 3 3 3]\n ...\n [3 3 3 ... 3 3 3]\n [6 6 6 ... 6 6 6]\n [1 1 1 ... 1 1 1]]", "episodes_total": null, "done": false, "iterations_since_restore": 3, "weights": "[[4.3722401e-05 4.3586027e-05 4.3957458e-05 ... 4.5891098e-05\n  4.5905039e-05 9.5319968e-01]\n [4.3696058e-05 4.3556072e-05 4.4041677e-05 ... 4.6424855e-05\n  4.6389403e-05 9.5308793e-01]\n [4.3777600e-05 4.3661494e-05 4.3854539e-05 ... 4.5793571e-05\n  4.5802462e-05 9.5318544e-01]\n ...\n [4.3732038e-05 4.3596214e-05 4.3931439e-05 ... 4.6436777e-05\n  4.6493758e-05 9.5321256e-01]\n [4.3750471e-05 4.3622575e-05 4.3894459e-05 ... 4.4794277e-05\n  4.4804900e-05 9.5316082e-01]\n [4.3765038e-05 4.3640717e-05 4.3867254e-05 ... 4.5233406e-05\n  4.5220779e-05 9.5332628e-01]]", "time_since_restore": 7.6797990798950195, "node_ip": "172.17.0.2", "probas": "[[[0.11006589 0.17199554 0.1310298  ... 0.10330841 0.12769316 0.13636959]\n  [0.10947885 0.17222542 0.13132773 ... 0.10329467 0.12778077 0.1362746 ]\n  [0.11116376 0.17154095 0.13048944 ... 0.10332984 0.12752268 0.13655195]\n  ...\n  [0.11026901 0.1719138  0.13092828 ... 0.1033128  0.12766227 0.13640288]\n  [0.11064298 0.17176038 0.1307432  ... 0.10332038 0.1276046  0.1364647 ]\n  [0.11092611 0.17164192 0.1306047  ... 0.10332568 0.12756032 0.13651198]]\n\n [[0.10949558 0.17305993 0.12999815 ... 0.10356815 0.12633893 0.13749264]\n  [0.10885598 0.17336345 0.13009991 ... 0.10364395 0.12616524 0.13764468]\n  [0.11069362 0.17238061 0.12982808 ... 0.10346195 0.12663668 0.13725722]\n  ...\n  [0.10966024 0.17296503 0.12999353 ... 0.10354504 0.12640348 0.13743772]\n  [0.11012328 0.17271948 0.12990697 ... 0.10350693 0.12649988 0.1373613 ]\n  [0.11037575 0.1725614  0.12989166 ... 0.10348107 0.12658283 0.13729542]]\n\n [[0.10901727 0.17391191 0.13034812 ... 0.10446133 0.12593874 0.13815331]\n  [0.10819314 0.1740464  0.13064125 ... 0.10478941 0.12584893 0.13846558]\n  [0.11042834 0.17327215 0.12993999 ... 0.10397058 0.12620032 0.1376711 ]\n  ...\n  [0.10917526 0.17385998 0.13029985 ... 0.10437226 0.12597409 0.1380693 ]\n  [0.1097783  0.17363095 0.13011198 ... 0.10418472 0.12606095 0.13788587]\n  [0.11001736 0.17349228 0.13005292 ... 0.10407447 0.12612979 0.13777593]]\n\n ...\n\n [[0.10172568 0.1779844  0.13855115 ... 0.10908885 0.14013328 0.13326043]\n  [0.10075425 0.17714569 0.1378407  ... 0.10979989 0.14138435 0.1340081 ]\n  [0.10196573 0.17803806 0.13858132 ... 0.10897239 0.13992918 0.13317153]\n  ...\n  [0.10037258 0.17763034 0.1384147  ... 0.10971325 0.1411647  0.13379177]\n  [0.10449363 0.17821823 0.13862142 ... 0.10772585 0.13744456 0.13254267]\n  [0.10343251 0.1781745  0.13859974 ... 0.10828248 0.1386679  0.13276868]]\n\n [[0.10169186 0.17796707 0.13853619 ... 0.10910922 0.14017205 0.13327898]\n  [0.10082692 0.1771822  0.1378599  ... 0.10976154 0.14131908 0.13397011]\n  [0.10194514 0.17802358 0.13856827 ... 0.10898665 0.13995898 0.13318463]\n  ...\n  [0.10025022 0.17755403 0.13836119 ... 0.10978348 0.14128664 0.13386756]\n  [0.10445682 0.17822373 0.13862614 ... 0.1077422  0.13748105 0.1325467 ]\n  [0.10345779 0.17817588 0.1385973  ... 0.10827003 0.13864182 0.13276406]]\n\n [[0.10165874 0.17795067 0.13852148 ... 0.10912891 0.14020859 0.13329716]\n  [0.10089742 0.17722034 0.13788143 ... 0.10972303 0.14125277 0.13393179]\n  [0.10192739 0.17801017 0.1385554  ... 0.10899945 0.13998532 0.13319689]\n  ...\n  [0.10012923 0.17747565 0.13830529 ... 0.10985355 0.14140591 0.13394505]\n  [0.10441837 0.17822988 0.138631   ... 0.10775901 0.13751723 0.13255121]\n  [0.10348016 0.17817843 0.13859591 ... 0.10825839 0.13861611 0.13275969]]]", "accuracy": 0.09090909090909091, "inputs": "[[[-1.0574203 ]\n  [-1.0514047 ]\n  [-1.0463719 ]\n  ...\n  [-0.9943956 ]\n  [-0.9967297 ]\n  [-0.99922913]]\n\n [[-1.2535369 ]\n  [-1.2642459 ]\n  [-1.2733136 ]\n  ...\n  [-1.0389028 ]\n  [-1.034854  ]\n  [-1.0311028 ]]\n\n [[-0.70577186]\n  [-0.69676715]\n  [-0.689986  ]\n  ...\n  [-0.9754479 ]\n  [-0.9764079 ]\n  [-0.9773511 ]]\n\n ...\n\n [[-0.9909409 ]\n  [-1.0027453 ]\n  [-1.0147117 ]\n  ...\n  [-1.1046433 ]\n  [-1.1131419 ]\n  [-1.1218793 ]]\n\n [[-0.8702758 ]\n  [-0.85922086]\n  [-0.84914935]\n  ...\n  [-0.811603  ]\n  [-0.8145301 ]\n  [-0.8177387 ]]\n\n [[-0.7803517 ]\n  [-0.7895152 ]\n  [-0.7991167 ]\n  ...\n  [-0.8716578 ]\n  [-0.8707964 ]\n  [-0.870276  ]]]"}
{"time_total_s": 10.158477306365967, "pid": 7040, "time_this_iter_s": 2.4786782264709473, "experiment_id": "cfbde1b0c87e48d5afbf09a3e7e7d1db", "timesteps_total": null, "timesteps_since_restore": 0, "training_iteration": 4, "config": {"workers": 2, "learning_rate": 0.01, "num_rnn_layers": 1, "hidden_dims": 128, "epochs": 99999, "dataset": "Mallat", "dropout": 0.3, "fold": 5, "earliness_factor": 1, "switch_epoch": 9999, "batchsize": 96}, "loss": 1.960913896560669, "hostname": "e9379f55ba79", "timestamp": 1544558212, "confusion_matrix": "[[0. 1. 0. 0. 0. 0. 0. 0.]\n [0. 1. 0. 0. 0. 0. 0. 0.]\n [0. 0. 0. 0. 0. 0. 0. 0.]\n [0. 4. 0. 0. 0. 0. 0. 0.]\n [0. 0. 0. 0. 0. 0. 0. 0.]\n [0. 1. 0. 0. 0. 0. 0. 0.]\n [0. 3. 0. 0. 0. 0. 0. 0.]\n [0. 1. 0. 0. 0. 0. 0. 0.]]", "date": "2018-12-11_20-56-52", "targets": "[[3 3 3 ... 3 3 3]\n [6 6 6 ... 6 6 6]\n [3 3 3 ... 3 3 3]\n ...\n [3 3 3 ... 3 3 3]\n [6 6 6 ... 6 6 6]\n [1 1 1 ... 1 1 1]]", "episodes_total": null, "done": false, "iterations_since_restore": 4, "weights": "[[4.2565920e-05 4.2537973e-05 4.3366766e-05 ... 4.2055257e-05\n  4.1697953e-05 9.5514041e-01]\n [4.2539545e-05 4.2538220e-05 4.3596156e-05 ... 4.2068132e-05\n  4.1741358e-05 9.5495826e-01]\n [4.2623440e-05 4.2568285e-05 4.3033648e-05 ... 4.2286407e-05\n  4.1956333e-05 9.5514905e-01]\n ...\n [4.2575786e-05 4.2539028e-05 4.3299409e-05 ... 4.2626460e-05\n  4.2409469e-05 9.5513994e-01]\n [4.2594835e-05 4.2548934e-05 4.3176202e-05 ... 4.2784544e-05\n  4.2698219e-05 9.5498353e-01]\n [4.2610107e-05 4.2556228e-05 4.3096028e-05 ... 4.2666281e-05\n  4.2471398e-05 9.5520288e-01]]", "time_since_restore": 10.158477306365967, "node_ip": "172.17.0.2", "probas": "[[[0.12391424 0.16528636 0.13182482 ... 0.11497274 0.1250135  0.14257318]\n  [0.12305434 0.16539429 0.13217698 ... 0.11502565 0.12519231 0.14260416]\n  [0.1255472  0.1650335  0.13117452 ... 0.11486476 0.12465668 0.14254512]\n  ...\n  [0.12421394 0.16524436 0.13170372 ... 0.11495361 0.12494958 0.14256513]\n  [0.12476865 0.16516125 0.13148172 ... 0.11491738 0.12482934 0.14255379]\n  [0.12519106 0.1650935  0.13131444 ... 0.11488909 0.12473623 0.14254808]]\n\n [[0.1233271  0.16455089 0.12976758 ... 0.11556184 0.12371203 0.14579223]\n  [0.12248844 0.16431734 0.12972695 ... 0.11578391 0.12359747 0.14651582]\n  [0.12496525 0.164745   0.1298411  ... 0.11520065 0.12385532 0.14460216]\n  ...\n  [0.12354432 0.16461383 0.12981306 ... 0.11549667 0.12375864 0.14556749]\n  [0.12417465 0.16468886 0.12980811 ... 0.11536377 0.1237987  0.14514269]\n  [0.12451977 0.16473591 0.12985823 ... 0.11528008 0.12384738 0.14485091]]\n\n [[0.12314802 0.16260163 0.12947324 ... 0.11702723 0.12378518 0.14862876]\n  [0.12209518 0.16151272 0.12962817 ... 0.11768541 0.12390437 0.14994653]\n  [0.12495361 0.16391075 0.12938042 ... 0.11599705 0.12366953 0.14648585]\n  ...\n  [0.12334187 0.16286057 0.12946923 ... 0.11685454 0.1237644  0.14829664]\n  [0.12412024 0.1633952  0.12939255 ... 0.11645321 0.12370573 0.14745918]\n  [0.12441472 0.16367146 0.12941083 ... 0.11623196 0.12369631 0.14700119]]\n\n ...\n\n [[0.12601295 0.16276442 0.13308607 ... 0.11780147 0.13477738 0.13745588]\n  [0.1256019  0.16260345 0.13287815 ... 0.11808038 0.13530011 0.13747184]\n  [0.12564749 0.16284329 0.13320836 ... 0.11811701 0.13458636 0.1380326 ]\n  ...\n  [0.12411524 0.16254489 0.13312115 ... 0.11902868 0.13543321 0.1388381 ]\n  [0.12517491 0.1631748  0.13333644 ... 0.11841078 0.13184474 0.1408327 ]\n  [0.12524542 0.16307454 0.13334522 ... 0.11841598 0.13300417 0.1397835 ]]\n\n [[0.12638324 0.16283192 0.13275981 ... 0.11727484 0.13425706 0.13722673]\n  [0.12601833 0.16269152 0.13261732 ... 0.11756648 0.1348021  0.13721472]\n  [0.12620501 0.16284563 0.13300414 ... 0.11760856 0.13444464 0.13745743]\n  ...\n  [0.12464745 0.16249184 0.13307355 ... 0.11871129 0.13587831 0.13798453]\n  [0.1259044  0.16306105 0.13367562 ... 0.11819357 0.13296667 0.13936684]\n  [0.12601067 0.16297765 0.13347849 ... 0.11805721 0.13370945 0.13856404]]\n\n [[0.12641187 0.16297626 0.13233133 ... 0.11684942 0.13339901 0.13749008]\n  [0.1261365  0.16284744 0.13225983 ... 0.11713082 0.13397615 0.13740313]\n  [0.12650545 0.16291574 0.1326631  ... 0.11710757 0.13385549 0.1373371 ]\n  ...\n  [0.1251195  0.1625281  0.13287416 ... 0.11827885 0.13585208 0.13741201]\n  [0.12680231 0.16296326 0.13366607 ... 0.11765733 0.13347805 0.13810953]\n  [0.12679388 0.16291273 0.13334766 ... 0.11748329 0.13381778 0.13765171]]]", "accuracy": 0.09090909090909091, "inputs": "[[[-1.0574203 ]\n  [-1.0514047 ]\n  [-1.0463719 ]\n  ...\n  [-0.9943956 ]\n  [-0.9967297 ]\n  [-0.99922913]]\n\n [[-1.2535369 ]\n  [-1.2642459 ]\n  [-1.2733136 ]\n  ...\n  [-1.0389028 ]\n  [-1.034854  ]\n  [-1.0311028 ]]\n\n [[-0.70577186]\n  [-0.69676715]\n  [-0.689986  ]\n  ...\n  [-0.9754479 ]\n  [-0.9764079 ]\n  [-0.9773511 ]]\n\n ...\n\n [[-0.9909409 ]\n  [-1.0027453 ]\n  [-1.0147117 ]\n  ...\n  [-1.1046433 ]\n  [-1.1131419 ]\n  [-1.1218793 ]]\n\n [[-0.8702758 ]\n  [-0.85922086]\n  [-0.84914935]\n  ...\n  [-0.811603  ]\n  [-0.8145301 ]\n  [-0.8177387 ]]\n\n [[-0.7803517 ]\n  [-0.7895152 ]\n  [-0.7991167 ]\n  ...\n  [-0.8716578 ]\n  [-0.8707964 ]\n  [-0.870276  ]]]"}
{"time_total_s": 12.54960036277771, "pid": 7040, "time_this_iter_s": 2.391123056411743, "experiment_id": "cfbde1b0c87e48d5afbf09a3e7e7d1db", "timesteps_total": null, "timesteps_since_restore": 0, "training_iteration": 5, "config": {"workers": 2, "learning_rate": 0.01, "num_rnn_layers": 1, "hidden_dims": 128, "epochs": 99999, "dataset": "Mallat", "dropout": 0.3, "fold": 5, "earliness_factor": 1, "switch_epoch": 9999, "batchsize": 96}, "loss": 1.967250108718872, "hostname": "e9379f55ba79", "timestamp": 1544558214, "confusion_matrix": "[[0. 0. 0. 1. 0. 0. 0. 0.]\n [1. 0. 0. 0. 0. 0. 0. 0.]\n [0. 0. 0. 0. 0. 0. 0. 0.]\n [3. 0. 0. 1. 0. 0. 0. 0.]\n [0. 0. 0. 0. 0. 0. 0. 0.]\n [0. 0. 0. 1. 0. 0. 0. 0.]\n [1. 0. 1. 1. 0. 0. 0. 0.]\n [0. 0. 1. 0. 0. 0. 0. 0.]]", "date": "2018-12-11_20-56-54", "targets": "[[3 3 3 ... 3 3 3]\n [6 6 6 ... 6 6 6]\n [3 3 3 ... 3 3 3]\n ...\n [3 3 3 ... 3 3 3]\n [6 6 6 ... 6 6 6]\n [1 1 1 ... 1 1 1]]", "episodes_total": null, "done": false, "iterations_since_restore": 5, "weights": "[[4.1627056e-05 4.1498690e-05 4.2199976e-05 ... 5.4317519e-05\n  5.0811119e-05 9.4918096e-01]\n [4.1592139e-05 4.1470601e-05 4.2382631e-05 ... 5.1654079e-05\n  4.8869009e-05 9.4900268e-01]\n [4.1699212e-05 4.1577074e-05 4.1950312e-05 ... 5.4393666e-05\n  5.1681960e-05 9.4917542e-01]\n ...\n [4.1639723e-05 4.1508072e-05 4.2144555e-05 ... 5.3808406e-05\n  5.3902520e-05 9.4917095e-01]\n [4.1663872e-05 4.1535583e-05 4.2053700e-05 ... 5.2306055e-05\n  4.9635248e-05 9.4919944e-01]\n [4.1682826e-05 4.1554129e-05 4.1991301e-05 ... 5.0149181e-05\n  5.2398205e-05 9.4917560e-01]]", "time_since_restore": 12.54960036277771, "node_ip": "172.17.0.2", "probas": "[[[0.1271671  0.17422688 0.12522712 ... 0.10451648 0.12011208 0.14219013]\n  [0.12633829 0.1744155  0.12564872 ... 0.10454133 0.12038683 0.14192873]\n  [0.12875725 0.17380086 0.12443811 ... 0.10445637 0.11957298 0.14272164]\n  ...\n  [0.12745744 0.174155   0.12508124 ... 0.10450669 0.12001479 0.14228442]\n  [0.1279966  0.17401417 0.12481248 ... 0.10448704 0.1198326  0.1424629 ]\n  [0.12840874 0.17390062 0.12460899 ... 0.10447084 0.11969231 0.14260212]]\n\n [[0.12830262 0.17465055 0.12378231 ... 0.10397565 0.11900941 0.14267196]\n  [0.12779842 0.17458874 0.12389977 ... 0.10398657 0.11904154 0.14267933]\n  [0.12933928 0.17440934 0.12354334 ... 0.10401057 0.11889914 0.14285168]\n  ...\n  [0.12841056 0.17464833 0.1237768  ... 0.10398022 0.11901682 0.14267115]\n  [0.12883033 0.17457658 0.12366131 ... 0.10398553 0.11896008 0.14273725]\n  [0.12902488 0.1745127  0.12363602 ... 0.10400102 0.11895396 0.14277251]]\n\n [[0.13023387 0.17304358 0.125278   ... 0.10429999 0.11914568 0.14202407]\n  [0.12972677 0.17195018 0.1259112  ... 0.10464881 0.11954556 0.1420265 ]\n  [0.13092227 0.17405598 0.12429819 ... 0.1039117  0.1186543  0.14231908]\n  ...\n  [0.13025929 0.17328554 0.12512796 ... 0.10421801 0.11907526 0.14204937]\n  [0.13063365 0.1737264  0.12473016 ... 0.10405261 0.11884744 0.14213851]\n  [0.13066521 0.17393138 0.12454075 ... 0.10397811 0.11877821 0.14220892]]\n\n ...\n\n [[0.11986603 0.11506793 0.1591405  ... 0.12445859 0.1314562  0.14335135]\n  [0.09549732 0.137842   0.15568934 ... 0.14376847 0.14971745 0.12671563]\n  [0.11640116 0.1154764  0.15976235 ... 0.1252201  0.13292666 0.14298192]\n  ...\n  [0.11140695 0.11310565 0.16053    ... 0.12632455 0.13611276 0.14457762]\n  [0.13279468 0.11612286 0.15629552 ... 0.12178662 0.12722303 0.14427911]\n  [0.17634583 0.10610119 0.14465792 ... 0.11554272 0.12058711 0.15955171]]\n\n [[0.14739187 0.11011984 0.15332781 ... 0.11957377 0.12477954 0.15016931]\n  [0.08147176 0.14118128 0.1610544  ... 0.14286797 0.1613378  0.12660563]\n  [0.13946642 0.11197439 0.15498689 ... 0.1207823  0.12620409 0.14770661]\n  ...\n  [0.12498545 0.11288876 0.15810868 ... 0.12340917 0.13003086 0.14511544]\n  [0.16445443 0.10861799 0.14931922 ... 0.11706009 0.12157974 0.1546722 ]\n  [0.17970777 0.11285868 0.13404757 ... 0.11441449 0.12205766 0.15625894]]\n\n [[0.17692511 0.10530054 0.14422739 ... 0.11553583 0.12101163 0.16011022]\n  [0.08427426 0.15253583 0.1551686  ... 0.13810155 0.15445128 0.12745729]\n  [0.17135558 0.10592964 0.14673938 ... 0.11623361 0.1213959  0.15828995]\n  ...\n  [0.15639383 0.10731928 0.15121794 ... 0.11832194 0.1238041  0.15370911]\n  [0.18223928 0.10798537 0.13924116 ... 0.11457039 0.12088434 0.1596818 ]\n  [0.16282107 0.1301104  0.12426676 ... 0.11840761 0.1180812  0.14457253]]]", "accuracy": 0.09090909090909091, "inputs": "[[[-1.0574203 ]\n  [-1.0514047 ]\n  [-1.0463719 ]\n  ...\n  [-0.9943956 ]\n  [-0.9967297 ]\n  [-0.99922913]]\n\n [[-1.2535369 ]\n  [-1.2642459 ]\n  [-1.2733136 ]\n  ...\n  [-1.0389028 ]\n  [-1.034854  ]\n  [-1.0311028 ]]\n\n [[-0.70577186]\n  [-0.69676715]\n  [-0.689986  ]\n  ...\n  [-0.9754479 ]\n  [-0.9764079 ]\n  [-0.9773511 ]]\n\n ...\n\n [[-0.9909409 ]\n  [-1.0027453 ]\n  [-1.0147117 ]\n  ...\n  [-1.1046433 ]\n  [-1.1131419 ]\n  [-1.1218793 ]]\n\n [[-0.8702758 ]\n  [-0.85922086]\n  [-0.84914935]\n  ...\n  [-0.811603  ]\n  [-0.8145301 ]\n  [-0.8177387 ]]\n\n [[-0.7803517 ]\n  [-0.7895152 ]\n  [-0.7991167 ]\n  ...\n  [-0.8716578 ]\n  [-0.8707964 ]\n  [-0.870276  ]]]"}
{"time_total_s": 14.966098546981812, "pid": 7040, "time_this_iter_s": 2.4164981842041016, "experiment_id": "cfbde1b0c87e48d5afbf09a3e7e7d1db", "timesteps_total": null, "timesteps_since_restore": 0, "training_iteration": 6, "config": {"workers": 2, "learning_rate": 0.01, "num_rnn_layers": 1, "hidden_dims": 128, "epochs": 99999, "dataset": "Mallat", "dropout": 0.3, "fold": 5, "earliness_factor": 1, "switch_epoch": 9999, "batchsize": 96}, "loss": 1.9633991718292236, "hostname": "e9379f55ba79", "timestamp": 1544558217, "confusion_matrix": "[[0. 0. 0. 1. 0. 0. 0. 0.]\n [0. 0. 0. 1. 0. 0. 0. 0.]\n [0. 0. 0. 0. 0. 0. 0. 0.]\n [0. 0. 0. 4. 0. 0. 0. 0.]\n [0. 0. 0. 0. 0. 0. 0. 0.]\n [0. 0. 0. 1. 0. 0. 0. 0.]\n [0. 0. 0. 1. 0. 0. 2. 0.]\n [0. 0. 0. 0. 0. 0. 1. 0.]]", "date": "2018-12-11_20-56-57", "targets": "[[3 3 3 ... 3 3 3]\n [6 6 6 ... 6 6 6]\n [3 3 3 ... 3 3 3]\n ...\n [3 3 3 ... 3 3 3]\n [6 6 6 ... 6 6 6]\n [1 1 1 ... 1 1 1]]", "episodes_total": null, "done": false, "iterations_since_restore": 6, "weights": "[[3.9167091e-05 3.8970298e-05 3.9355611e-05 ... 4.8588932e-05\n  4.8659334e-05 9.4887275e-01]\n [3.9128787e-05 3.8918712e-05 3.9432929e-05 ... 4.4848250e-05\n  4.7341455e-05 9.4886076e-01]\n [3.9243470e-05 3.9083174e-05 3.9270239e-05 ... 4.9520546e-05\n  4.6911679e-05 9.4889373e-01]\n ...\n [3.9180763e-05 3.8986243e-05 3.9329196e-05 ... 4.9001817e-05\n  4.8618458e-05 9.4887334e-01]\n [3.9206439e-05 3.9026749e-05 3.9300769e-05 ... 4.5045184e-05\n  4.8054855e-05 9.4887656e-01]\n [3.9226408e-05 3.9053182e-05 3.9275368e-05 ... 4.5791548e-05\n  4.9128928e-05 9.4887722e-01]]", "time_since_restore": 14.966098546981812, "node_ip": "172.17.0.2", "probas": "[[[0.11612433 0.18056287 0.12309712 ... 0.09726233 0.1247142  0.13756108]\n  [0.11574247 0.18040696 0.12340087 ... 0.09724061 0.12498474 0.13740349]\n  [0.11687243 0.18079172 0.1225293  ... 0.09728794 0.12419247 0.13789181]\n  ...\n  [0.11625949 0.18061115 0.12299207 ... 0.09726854 0.1246192  0.13761885]\n  [0.11651225 0.18069282 0.12279863 ... 0.09727818 0.12444241 0.13772932]\n  [0.11670689 0.18074866 0.1226522  ... 0.097284   0.12430706 0.13781644]]\n\n [[0.11876704 0.17958225 0.12106239 ... 0.09663876 0.12501758 0.13744561]\n  [0.11889543 0.17907278 0.12099976 ... 0.09656746 0.12532622 0.13737647]\n  [0.11858386 0.18028522 0.1211848  ... 0.09680565 0.12443631 0.13769798]\n  ...\n  [0.11869389 0.17971633 0.12111141 ... 0.09666437 0.12493528 0.13747148]\n  [0.11866058 0.17998748 0.12112718 ... 0.09672126 0.12471375 0.13755982]\n  [0.11858032 0.18014236 0.12118595 ... 0.09676451 0.1245892  0.13761817]]\n\n [[0.11984763 0.17952213 0.12190076 ... 0.09694387 0.12781616 0.13405862]\n  [0.11982971 0.17857085 0.12224795 ... 0.09714726 0.1289208  0.13335142]\n  [0.11963345 0.18061462 0.12146854 ... 0.09676273 0.12606013 0.13546416]\n  ...\n  [0.1198024  0.17969903 0.12182455 ... 0.09688859 0.12754044 0.13429347]\n  [0.11977244 0.18019329 0.12163851 ... 0.09681625 0.1268474  0.13478902]\n  [0.11967385 0.18037635 0.12156282 ... 0.0967753  0.12648316 0.13512695]]\n\n ...\n\n [[0.10058139 0.10137962 0.16403957 ... 0.12652735 0.16718061 0.13297369]\n  [0.11705668 0.09956054 0.15295404 ... 0.12854059 0.15196022 0.15037216]\n  [0.09625553 0.10873904 0.16423704 ... 0.12775187 0.16695103 0.1272997 ]\n  ...\n  [0.09936513 0.10168713 0.16484301 ... 0.12666601 0.1673601  0.1327551 ]\n  [0.11530949 0.09892898 0.15474927 ... 0.12710026 0.15632957 0.14575662]\n  [0.110965   0.09692716 0.15814586 ... 0.12649652 0.16077137 0.14234443]]\n\n [[0.09049144 0.12478236 0.15940832 ... 0.12965167 0.16190214 0.11869866]\n  [0.10481496 0.09691863 0.16241424 ... 0.12623423 0.16517317 0.13819458]\n  [0.08876844 0.13431978 0.15401274 ... 0.12964301 0.15632229 0.11520721]\n  ...\n  [0.08973261 0.12556992 0.15920174 ... 0.12962656 0.16143207 0.1187164 ]\n  [0.10215606 0.10198265 0.16268423 ... 0.12630992 0.16692606 0.13251951]\n  [0.09781074 0.10727359 0.16375712 ... 0.12739024 0.16719003 0.12809609]]\n\n [[0.09120077 0.1473796  0.14514719 ... 0.12710702 0.13996992 0.11467852]\n  [0.09308477 0.1153539  0.16318102 ... 0.12886244 0.16525874 0.12351414]\n  [0.09570242 0.15459025 0.14172465 ... 0.12517929 0.12742405 0.11664405]\n  ...\n  [0.09119331 0.14756285 0.14485276 ... 0.12690866 0.13891925 0.11518667]\n  [0.09154487 0.12496588 0.15900327 ... 0.12962157 0.1621041  0.11801271]\n  [0.08946007 0.13281062 0.1550046  ... 0.12978177 0.15765302 0.1152507 ]]]", "accuracy": 0.5454545454545454, "inputs": "[[[-1.0574203 ]\n  [-1.0514047 ]\n  [-1.0463719 ]\n  ...\n  [-0.9943956 ]\n  [-0.9967297 ]\n  [-0.99922913]]\n\n [[-1.2535369 ]\n  [-1.2642459 ]\n  [-1.2733136 ]\n  ...\n  [-1.0389028 ]\n  [-1.034854  ]\n  [-1.0311028 ]]\n\n [[-0.70577186]\n  [-0.69676715]\n  [-0.689986  ]\n  ...\n  [-0.9754479 ]\n  [-0.9764079 ]\n  [-0.9773511 ]]\n\n ...\n\n [[-0.9909409 ]\n  [-1.0027453 ]\n  [-1.0147117 ]\n  ...\n  [-1.1046433 ]\n  [-1.1131419 ]\n  [-1.1218793 ]]\n\n [[-0.8702758 ]\n  [-0.85922086]\n  [-0.84914935]\n  ...\n  [-0.811603  ]\n  [-0.8145301 ]\n  [-0.8177387 ]]\n\n [[-0.7803517 ]\n  [-0.7895152 ]\n  [-0.7991167 ]\n  ...\n  [-0.8716578 ]\n  [-0.8707964 ]\n  [-0.870276  ]]]"}
{"time_total_s": 17.76072120666504, "pid": 7040, "time_this_iter_s": 2.7946226596832275, "experiment_id": "cfbde1b0c87e48d5afbf09a3e7e7d1db", "timesteps_total": null, "timesteps_since_restore": 0, "training_iteration": 7, "config": {"workers": 2, "learning_rate": 0.01, "num_rnn_layers": 1, "hidden_dims": 128, "epochs": 99999, "dataset": "Mallat", "dropout": 0.3, "fold": 5, "earliness_factor": 1, "switch_epoch": 9999, "batchsize": 96}, "loss": 1.9699982404708862, "hostname": "e9379f55ba79", "timestamp": 1544558219, "confusion_matrix": "[[0. 1. 0. 0. 0. 0. 0. 0.]\n [0. 1. 0. 0. 0. 0. 0. 0.]\n [0. 0. 0. 0. 0. 0. 0. 0.]\n [0. 4. 0. 0. 0. 0. 0. 0.]\n [0. 0. 0. 0. 0. 0. 0. 0.]\n [0. 1. 0. 0. 0. 0. 0. 0.]\n [0. 3. 0. 0. 0. 0. 0. 0.]\n [0. 1. 0. 0. 0. 0. 0. 0.]]", "date": "2018-12-11_20-56-59", "targets": "[[3 3 3 ... 3 3 3]\n [6 6 6 ... 6 6 6]\n [3 3 3 ... 3 3 3]\n ...\n [3 3 3 ... 3 3 3]\n [6 6 6 ... 6 6 6]\n [1 1 1 ... 1 1 1]]", "episodes_total": null, "done": false, "iterations_since_restore": 7, "weights": "[[3.7319220e-05 3.7116904e-05 3.7377806e-05 ... 4.5861401e-05\n  4.6108176e-05 9.5156556e-01]\n [3.7278314e-05 3.7059610e-05 3.7418111e-05 ... 4.5141664e-05\n  4.7113332e-05 9.5157498e-01]\n [3.7399812e-05 3.7238264e-05 3.7353071e-05 ... 4.5200344e-05\n  4.9477039e-05 9.5157456e-01]\n ...\n [3.7333743e-05 3.7134323e-05 3.7362090e-05 ... 4.5847381e-05\n  4.6032150e-05 9.5156693e-01]\n [3.7360918e-05 3.7178190e-05 3.7356385e-05 ... 4.5196877e-05\n  4.9168651e-05 9.5156634e-01]\n [3.7381909e-05 3.7206424e-05 3.7344846e-05 ... 4.5534580e-05\n  5.1062816e-05 9.5155680e-01]]", "time_since_restore": 17.76072120666504, "node_ip": "172.17.0.2", "probas": "[[[0.11030353 0.18272552 0.12296835 ... 0.09736832 0.1366141  0.12898834]\n  [0.1099517  0.1828619  0.1230436  ... 0.09714938 0.13673647 0.1287793 ]\n  [0.11099374 0.18244146 0.12281832 ... 0.09775773 0.13635977 0.1293984 ]\n  ...\n  [0.11042816 0.18267572 0.12294149 ... 0.09744228 0.13656949 0.12906238]\n  [0.11066133 0.18258066 0.12289093 ... 0.09757617 0.1364844  0.12920092]\n  [0.11084093 0.18250589 0.12285174 ... 0.09767552 0.1364175  0.12930761]]\n\n [[0.1127932  0.18435523 0.11984566 ... 0.09496351 0.13550583 0.12826686]\n  [0.11294432 0.18469977 0.11935286 ... 0.09437196 0.13533434 0.12801537]\n  [0.11258497 0.18361723 0.12073512 ... 0.0960694  0.13572638 0.12881206]\n  ...\n  [0.11271644 0.18424264 0.12001754 ... 0.09514587 0.1355628  0.12834355]\n  [0.1126711  0.18398042 0.12031877 ... 0.09554432 0.13563791 0.12854166]\n  [0.11258801 0.18380272 0.12055156 ... 0.09580838 0.13569848 0.12866713]]\n\n [[0.11537096 0.1872336  0.11940943 ... 0.09344628 0.13565265 0.12485292]\n  [0.11581781 0.18790424 0.11896785 ... 0.09279078 0.13559015 0.12398085]\n  [0.11446267 0.1857423  0.12027431 ... 0.0947905  0.13576469 0.12651457]\n  ...\n  [0.1151926  0.18702762 0.11951891 ... 0.09360891 0.13567422 0.12511234]\n  [0.11490363 0.18648188 0.11985631 ... 0.09413268 0.13571402 0.12572357]\n  [0.11464458 0.18614358 0.12003754 ... 0.09440992 0.1357449  0.12610234]]\n\n ...\n\n [[0.11563529 0.1758822  0.12740862 ... 0.11058561 0.10512356 0.15923919]\n  [0.11035606 0.17855665 0.12922227 ... 0.10938808 0.10665128 0.15889424]\n  [0.10442487 0.17984557 0.13151558 ... 0.10923566 0.10763282 0.15777707]\n  ...\n  [0.11599998 0.17568298 0.12737256 ... 0.11050034 0.10522289 0.15915082]\n  [0.10500669 0.17989227 0.13105963 ... 0.10954918 0.10713705 0.15802705]\n  [0.10234285 0.17922603 0.13259938 ... 0.10984378 0.10713279 0.15781094]]\n\n [[0.10072113 0.17734316 0.13486649 ... 0.11126377 0.10682404 0.15799017]\n  [0.09891799 0.17574681 0.13705723 ... 0.11334199 0.10668581 0.1581375 ]\n  [0.09601268 0.17375068 0.13931547 ... 0.11608779 0.10703296 0.15923493]\n  ...\n  [0.10080065 0.17733876 0.1350163  ... 0.11107447 0.10718631 0.15771821]\n  [0.0965072  0.17417298 0.13854562 ... 0.11564045 0.10669483 0.15957946]\n  [0.09478237 0.17281178 0.14052992 ... 0.11696601 0.10763487 0.16042277]]\n\n [[0.09326953 0.17138988 0.14381091 ... 0.1180991  0.10927695 0.16003402]\n  [0.09244335 0.17006391 0.14644684 ... 0.11877338 0.11079575 0.1596617 ]\n  [0.09294043 0.16825674 0.14838816 ... 0.11883042 0.11259192 0.15963413]\n  ...\n  [0.09310232 0.17118518 0.14408346 ... 0.11836195 0.10931812 0.15955338]\n  [0.09340512 0.1690885  0.14745414 ... 0.11837075 0.11203098 0.16025084]\n  [0.09464444 0.16777314 0.14849925 ... 0.11828084 0.11321862 0.15960453]]]", "accuracy": 0.09090909090909091, "inputs": "[[[-1.0574203 ]\n  [-1.0514047 ]\n  [-1.0463719 ]\n  ...\n  [-0.9943956 ]\n  [-0.9967297 ]\n  [-0.99922913]]\n\n [[-1.2535369 ]\n  [-1.2642459 ]\n  [-1.2733136 ]\n  ...\n  [-1.0389028 ]\n  [-1.034854  ]\n  [-1.0311028 ]]\n\n [[-0.70577186]\n  [-0.69676715]\n  [-0.689986  ]\n  ...\n  [-0.9754479 ]\n  [-0.9764079 ]\n  [-0.9773511 ]]\n\n ...\n\n [[-0.9909409 ]\n  [-1.0027453 ]\n  [-1.0147117 ]\n  ...\n  [-1.1046433 ]\n  [-1.1131419 ]\n  [-1.1218793 ]]\n\n [[-0.8702758 ]\n  [-0.85922086]\n  [-0.84914935]\n  ...\n  [-0.811603  ]\n  [-0.8145301 ]\n  [-0.8177387 ]]\n\n [[-0.7803517 ]\n  [-0.7895152 ]\n  [-0.7991167 ]\n  ...\n  [-0.8716578 ]\n  [-0.8707964 ]\n  [-0.870276  ]]]"}
{"time_total_s": 20.271618604660034, "pid": 7040, "time_this_iter_s": 2.510897397994995, "experiment_id": "cfbde1b0c87e48d5afbf09a3e7e7d1db", "timesteps_total": null, "timesteps_since_restore": 0, "training_iteration": 8, "config": {"workers": 2, "learning_rate": 0.01, "num_rnn_layers": 1, "hidden_dims": 128, "epochs": 99999, "dataset": "Mallat", "dropout": 0.3, "fold": 5, "earliness_factor": 1, "switch_epoch": 9999, "batchsize": 96}, "loss": 1.974349856376648, "hostname": "e9379f55ba79", "timestamp": 1544558222, "confusion_matrix": "[[0. 0. 0. 1. 0. 0. 0. 0.]\n [0. 0. 0. 1. 0. 0. 0. 0.]\n [0. 0. 0. 0. 0. 0. 0. 0.]\n [0. 0. 0. 4. 0. 0. 0. 0.]\n [0. 0. 0. 0. 0. 0. 0. 0.]\n [0. 0. 0. 1. 0. 0. 0. 0.]\n [0. 0. 0. 3. 0. 0. 0. 0.]\n [0. 0. 0. 1. 0. 0. 0. 0.]]", "date": "2018-12-11_20-57-02", "targets": "[[3 3 3 ... 3 3 3]\n [6 6 6 ... 6 6 6]\n [3 3 3 ... 3 3 3]\n ...\n [3 3 3 ... 3 3 3]\n [6 6 6 ... 6 6 6]\n [1 1 1 ... 1 1 1]]", "episodes_total": null, "done": false, "iterations_since_restore": 8, "weights": "[[3.6974503e-05 3.6772319e-05 3.7027912e-05 ... 4.1041079e-05\n  4.2662461e-05 9.5380712e-01]\n [3.6932004e-05 3.6712612e-05 3.7062255e-05 ... 4.1721087e-05\n  4.2712225e-05 9.5380294e-01]\n [3.7057671e-05 3.6897407e-05 3.7013466e-05 ... 4.1836116e-05\n  4.2671440e-05 9.5381951e-01]\n ...\n [3.6989491e-05 3.6790381e-05 3.7013931e-05 ... 4.1293828e-05\n  4.2748350e-05 9.5380783e-01]\n [3.7017580e-05 3.6835703e-05 3.7012305e-05 ... 4.1662141e-05\n  4.2608666e-05 9.5381343e-01]\n [3.7039226e-05 3.6864731e-05 3.7002887e-05 ... 4.2071752e-05\n  4.2598793e-05 9.5381528e-01]]", "time_since_restore": 20.271618604660034, "node_ip": "172.17.0.2", "probas": "[[[0.1143509  0.17097507 0.12673377 ... 0.10525935 0.14758018 0.1278721 ]\n  [0.11415555 0.17106837 0.12684114 ... 0.10513221 0.14765316 0.12775035]\n  [0.11474974 0.17078795 0.12652624 ... 0.10548092 0.1474203  0.12810373]\n  ...\n  [0.11442148 0.17094165 0.126696   ... 0.10530189 0.14755283 0.12791458]\n  [0.11455531 0.17087862 0.1266257  ... 0.10537834 0.14749976 0.12799318]\n  [0.11465991 0.17082976 0.12657185 ... 0.10543469 0.14745739 0.12805316]]\n\n [[0.11680819 0.17253691 0.12440335 ... 0.10336602 0.14689961 0.12781209]\n  [0.11711518 0.17290325 0.1240751  ... 0.10295028 0.14673768 0.1276957 ]\n  [0.11632334 0.17184167 0.12498739 ... 0.10415114 0.14708969 0.12803634]\n  ...\n  [0.11669473 0.17242295 0.12452258 ... 0.10349768 0.14694709 0.12784073]\n  [0.11653887 0.17217223 0.12471562 ... 0.10377733 0.1470175  0.12792829]\n  [0.11640078 0.17200652 0.12487355 ... 0.10396807 0.14706448 0.12797436]]\n\n [[0.11742961 0.17624468 0.1243954  ... 0.10183769 0.14820722 0.12507625]\n  [0.11769411 0.17724814 0.12408894 ... 0.10136079 0.14824511 0.12442584]\n  [0.11688884 0.17436948 0.12493624 ... 0.10287678 0.1480269  0.12623346]\n  ...\n  [0.11734737 0.1759564  0.12446868 ... 0.1019687  0.14817587 0.12526217]\n  [0.11715208 0.17525683 0.12468375 ... 0.10236013 0.14813115 0.12569402]\n  [0.11701912 0.17483339 0.12479506 ... 0.10258671 0.1480741  0.1259569 ]]\n\n ...\n\n [[0.11928541 0.15012673 0.13788722 ... 0.11924088 0.11585736 0.15102509]\n  [0.11847777 0.15025918 0.13955136 ... 0.11923733 0.11562369 0.15147543]\n  [0.11851163 0.15038633 0.13973336 ... 0.11912924 0.11572044 0.15162359]\n  ...\n  [0.11875469 0.15011072 0.13856943 ... 0.11945762 0.11558447 0.15112102]\n  [0.11907508 0.1503972  0.1393316  ... 0.11875429 0.11619856 0.15157214]\n  [0.11852003 0.15060711 0.14000155 ... 0.11910027 0.11583415 0.15185076]]\n\n [[0.11774617 0.15108551 0.13987496 ... 0.12076333 0.11483891 0.15270875]\n  [0.1177993  0.15084518 0.13884991 ... 0.12199628 0.11449804 0.15308325]\n  [0.11806985 0.15064682 0.13844942 ... 0.12219914 0.11474868 0.15299058]\n  ...\n  [0.11743271 0.15113513 0.13975832 ... 0.12128366 0.11435337 0.15298852]\n  [0.11844362 0.15060323 0.13850483 ... 0.12174476 0.11546905 0.15254469]\n  [0.11870614 0.14998826 0.13760212 ... 0.122621   0.11523053 0.15278709]]\n\n [[0.12094529 0.14705284 0.13506155 ... 0.12411675 0.11487654 0.15358633]\n  [0.12317324 0.14518343 0.13391832 ... 0.12397151 0.11480593 0.15414102]\n  [0.12408009 0.14475156 0.1336805  ... 0.12353811 0.11511894 0.15400624]\n  ...\n  [0.1212304  0.14663924 0.13464926 ... 0.12443767 0.11436267 0.15411143]\n  [0.12420758 0.14484176 0.13388945 ... 0.12314687 0.11588341 0.15328933]\n  [0.12611793 0.1441558  0.13308328 ... 0.12235366 0.11563033 0.15381153]]]", "accuracy": 0.36363636363636365, "inputs": "[[[-1.0574203 ]\n  [-1.0514047 ]\n  [-1.0463719 ]\n  ...\n  [-0.9943956 ]\n  [-0.9967297 ]\n  [-0.99922913]]\n\n [[-1.2535369 ]\n  [-1.2642459 ]\n  [-1.2733136 ]\n  ...\n  [-1.0389028 ]\n  [-1.034854  ]\n  [-1.0311028 ]]\n\n [[-0.70577186]\n  [-0.69676715]\n  [-0.689986  ]\n  ...\n  [-0.9754479 ]\n  [-0.9764079 ]\n  [-0.9773511 ]]\n\n ...\n\n [[-0.9909409 ]\n  [-1.0027453 ]\n  [-1.0147117 ]\n  ...\n  [-1.1046433 ]\n  [-1.1131419 ]\n  [-1.1218793 ]]\n\n [[-0.8702758 ]\n  [-0.85922086]\n  [-0.84914935]\n  ...\n  [-0.811603  ]\n  [-0.8145301 ]\n  [-0.8177387 ]]\n\n [[-0.7803517 ]\n  [-0.7895152 ]\n  [-0.7991167 ]\n  ...\n  [-0.8716578 ]\n  [-0.8707964 ]\n  [-0.870276  ]]]"}
{"time_total_s": 22.450153350830078, "pid": 7040, "time_this_iter_s": 2.178534746170044, "experiment_id": "cfbde1b0c87e48d5afbf09a3e7e7d1db", "timesteps_total": null, "timesteps_since_restore": 0, "training_iteration": 9, "config": {"workers": 2, "learning_rate": 0.01, "num_rnn_layers": 1, "hidden_dims": 128, "epochs": 99999, "dataset": "Mallat", "dropout": 0.3, "fold": 5, "earliness_factor": 1, "switch_epoch": 9999, "batchsize": 96}, "loss": 1.9635883569717407, "hostname": "e9379f55ba79", "timestamp": 1544558224, "confusion_matrix": "[[0. 1. 0. 0. 0. 0. 0. 0.]\n [0. 1. 0. 0. 0. 0. 0. 0.]\n [0. 0. 0. 0. 0. 0. 0. 0.]\n [0. 1. 0. 3. 0. 0. 0. 0.]\n [0. 0. 0. 0. 0. 0. 0. 0.]\n [0. 0. 0. 1. 0. 0. 0. 0.]\n [0. 2. 0. 1. 0. 0. 0. 0.]\n [0. 0. 0. 1. 0. 0. 0. 0.]]", "date": "2018-12-11_20-57-04", "targets": "[[3 3 3 ... 3 3 3]\n [6 6 6 ... 6 6 6]\n [3 3 3 ... 3 3 3]\n ...\n [3 3 3 ... 3 3 3]\n [6 6 6 ... 6 6 6]\n [1 1 1 ... 1 1 1]]", "episodes_total": null, "done": false, "iterations_since_restore": 9, "weights": "[[3.6907535e-05 3.6721758e-05 3.7050559e-05 ... 5.4805554e-05\n  4.9440387e-05 9.5350957e-01]\n [3.6864054e-05 3.6665944e-05 3.7111033e-05 ... 5.5255594e-05\n  5.0860366e-05 9.5351017e-01]\n [3.6992598e-05 3.6841502e-05 3.6999390e-05 ... 5.0854662e-05\n  4.3922391e-05 9.5350665e-01]\n ...\n [3.6922920e-05 3.6738638e-05 3.7029720e-05 ... 5.5003147e-05\n  4.9800325e-05 9.5351231e-01]\n [3.6951627e-05 3.6782032e-05 3.7013971e-05 ... 5.1089239e-05\n  4.4255448e-05 9.5350420e-01]\n [3.6973765e-05 3.6809757e-05 3.6996364e-05 ... 5.2472020e-05\n  4.5738932e-05 9.5350498e-01]]", "time_since_restore": 22.450153350830078, "node_ip": "172.17.0.2", "probas": "[[[0.10836646 0.16940944 0.13134488 ... 0.10673451 0.15801367 0.12159896]\n  [0.10822394 0.16959238 0.13138977 ... 0.10650897 0.15810327 0.1213599 ]\n  [0.10866518 0.16906415 0.13125098 ... 0.10713863 0.15782839 0.12203715]\n  ...\n  [0.10841867 0.16934581 0.13132845 ... 0.10681097 0.1579811  0.12168086]\n  [0.10851848 0.16922837 0.13129704 ... 0.10694969 0.15791906 0.12183062]\n  [0.10859717 0.16913918 0.13127232 ... 0.10705302 0.15787037 0.12194317]]\n\n [[0.11105112 0.17140155 0.12887006 ... 0.10447866 0.15715677 0.1204715 ]\n  [0.11144876 0.1719594  0.12844941 ... 0.10390189 0.15698157 0.12001115]\n  [0.11039828 0.17038956 0.12961504 ... 0.10555705 0.15737869 0.12127845]\n  ...\n  [0.11091119 0.17123514 0.12901409 ... 0.10465568 0.15721162 0.12059967]\n  [0.11069341 0.17086455 0.12926856 ... 0.10504515 0.15729052 0.12090273]\n  [0.11051697 0.17062835 0.12946151 ... 0.10530159 0.1573477  0.12108346]]\n\n [[0.11251811 0.17476287 0.12882411 ... 0.10342782 0.15716769 0.11671413]\n  [0.11300059 0.17598292 0.12841971 ... 0.10286219 0.15691799 0.11545414]\n  [0.1115559  0.17261374 0.12953265 ... 0.10460865 0.15749264 0.11885538]\n  ...\n  [0.11236987 0.17444548 0.12891567 ... 0.10356242 0.15723182 0.11704361]\n  [0.1120207  0.17361239 0.1292029  ... 0.10402837 0.15736309 0.11787229]\n  [0.11179031 0.17315446 0.12934273 ... 0.10426531 0.15743276 0.11833252]]\n\n ...\n\n [[0.09728332 0.16438    0.14053869 ... 0.11352874 0.12926814 0.14524177]\n  [0.09671392 0.16351613 0.14107126 ... 0.11376461 0.12877439 0.14612553]\n  [0.09903064 0.16785915 0.13865265 ... 0.1119517  0.12956817 0.14268856]\n  ...\n  [0.09679788 0.16373567 0.14096887 ... 0.11383072 0.12931822 0.14540137]\n  [0.0995824  0.16841319 0.13833807 ... 0.11187104 0.12933847 0.14262299]\n  [0.09912704 0.16728923 0.13900144 ... 0.11276478 0.12939091 0.14299344]]\n\n [[0.09898569 0.16820288 0.13845861 ... 0.11087355 0.12956458 0.14299773]\n  [0.09881145 0.16759686 0.13880047 ... 0.11203773 0.12965293 0.14271939]\n  [0.10056271 0.17021562 0.13667388 ... 0.10677721 0.12771912 0.14530891]\n  ...\n  [0.09861014 0.16765173 0.13876699 ... 0.11133815 0.12973337 0.14294861]\n  [0.10061509 0.1705212  0.13679111 ... 0.10661743 0.12778372 0.14525643]\n  [0.09969388 0.16962314 0.13770655 ... 0.1077304  0.12858824 0.14463378]]\n\n [[0.10201266 0.1709003  0.13537224 ... 0.10637067 0.12682565 0.14533596]\n  [0.10048059 0.17005539 0.136693   ... 0.10687491 0.12774658 0.14530687]\n  [0.10966154 0.1716366  0.13066936 ... 0.1070567  0.12379925 0.14326546]\n  ...\n  [0.10146958 0.17043476 0.1357418  ... 0.10672385 0.12709834 0.14528191]\n  [0.109339   0.17225362 0.13071194 ... 0.10649803 0.12383332 0.14352822]\n  [0.10714714 0.17228766 0.13183704 ... 0.10625088 0.12449661 0.14410934]]]", "accuracy": 0.36363636363636365, "inputs": "[[[-1.0574203 ]\n  [-1.0514047 ]\n  [-1.0463719 ]\n  ...\n  [-0.9943956 ]\n  [-0.9967297 ]\n  [-0.99922913]]\n\n [[-1.2535369 ]\n  [-1.2642459 ]\n  [-1.2733136 ]\n  ...\n  [-1.0389028 ]\n  [-1.034854  ]\n  [-1.0311028 ]]\n\n [[-0.70577186]\n  [-0.69676715]\n  [-0.689986  ]\n  ...\n  [-0.9754479 ]\n  [-0.9764079 ]\n  [-0.9773511 ]]\n\n ...\n\n [[-0.9909409 ]\n  [-1.0027453 ]\n  [-1.0147117 ]\n  ...\n  [-1.1046433 ]\n  [-1.1131419 ]\n  [-1.1218793 ]]\n\n [[-0.8702758 ]\n  [-0.85922086]\n  [-0.84914935]\n  ...\n  [-0.811603  ]\n  [-0.8145301 ]\n  [-0.8177387 ]]\n\n [[-0.7803517 ]\n  [-0.7895152 ]\n  [-0.7991167 ]\n  ...\n  [-0.8716578 ]\n  [-0.8707964 ]\n  [-0.870276  ]]]"}
{"time_total_s": 24.858838319778442, "pid": 7040, "time_this_iter_s": 2.4086849689483643, "experiment_id": "cfbde1b0c87e48d5afbf09a3e7e7d1db", "timesteps_total": null, "timesteps_since_restore": 0, "training_iteration": 10, "config": {"workers": 2, "learning_rate": 0.01, "num_rnn_layers": 1, "hidden_dims": 128, "epochs": 99999, "dataset": "Mallat", "dropout": 0.3, "fold": 5, "earliness_factor": 1, "switch_epoch": 9999, "batchsize": 96}, "loss": 1.9546329975128174, "hostname": "e9379f55ba79", "timestamp": 1544558227, "confusion_matrix": "[[0. 1. 0. 0. 0. 0. 0. 0.]\n [0. 1. 0. 0. 0. 0. 0. 0.]\n [0. 0. 0. 0. 0. 0. 0. 0.]\n [0. 4. 0. 0. 0. 0. 0. 0.]\n [0. 0. 0. 0. 0. 0. 0. 0.]\n [0. 1. 0. 0. 0. 0. 0. 0.]\n [0. 3. 0. 0. 0. 0. 0. 0.]\n [0. 1. 0. 0. 0. 0. 0. 0.]]", "date": "2018-12-11_20-57-07", "targets": "[[3 3 3 ... 3 3 3]\n [6 6 6 ... 6 6 6]\n [3 3 3 ... 3 3 3]\n ...\n [3 3 3 ... 3 3 3]\n [6 6 6 ... 6 6 6]\n [1 1 1 ... 1 1 1]]", "episodes_total": null, "done": true, "iterations_since_restore": 10, "weights": "[[3.6922742e-05 3.6746977e-05 3.7089550e-05 ... 4.1148956e-05\n  4.1243544e-05 9.5460808e-01]\n [3.6878828e-05 3.6692385e-05 3.7151396e-05 ... 4.1121679e-05\n  4.1198331e-05 9.5460522e-01]\n [3.7008547e-05 3.6864556e-05 3.7035079e-05 ... 4.1187996e-05\n  4.1524316e-05 9.5461541e-01]\n ...\n [3.6938240e-05 3.6763486e-05 3.7068476e-05 ... 4.1210005e-05\n  4.1246443e-05 9.5460767e-01]\n [3.6967242e-05 3.6806137e-05 3.7051435e-05 ... 4.1153064e-05\n  4.1669995e-05 9.5461380e-01]\n [3.6989561e-05 3.6833280e-05 3.7033100e-05 ... 4.1150128e-05\n  4.1360167e-05 9.5461071e-01]]", "time_since_restore": 24.858838319778442, "node_ip": "172.17.0.2", "probas": "[[[0.10633514 0.16514936 0.13446121 ... 0.11215279 0.16053069 0.12100857]\n  [0.10619359 0.16525806 0.13453615 ... 0.1119796  0.16058004 0.12085988]\n  [0.10662854 0.164944   0.13431267 ... 0.11245905 0.16042756 0.12127654]\n  ...\n  [0.10638672 0.16511156 0.13443454 ... 0.11221118 0.16051267 0.1210591 ]\n  [0.10648495 0.16504176 0.13438445 ... 0.11231657 0.16047823 0.12115097]\n  [0.10656206 0.16498865 0.1343457  ... 0.11239464 0.16045105 0.12121956]]\n\n [[0.10821731 0.16698457 0.13246632 ... 0.10992919 0.15982282 0.12073002]\n  [0.10844606 0.16746308 0.13216057 ... 0.10939898 0.15966223 0.12050454]\n  [0.10784764 0.16613714 0.13300262 ... 0.11091471 0.16004775 0.12110087]\n  ...\n  [0.10813151 0.16684017 0.13257469 ... 0.11009468 0.15987293 0.12078571]\n  [0.10801341 0.16653153 0.13275425 ... 0.11044798 0.15995353 0.12093159]\n  [0.1079075  0.16633137 0.13289697 ... 0.11068518 0.1600098  0.12100866]]\n\n [[0.10837672 0.17092364 0.13290511 ... 0.10794627 0.16058488 0.1179388 ]\n  [0.10846678 0.17217788 0.13273434 ... 0.10726733 0.1604563  0.11708755]\n  [0.10810909 0.16873431 0.13322113 ... 0.10934075 0.16069478 0.11933422]\n  ...\n  [0.10833975 0.17058234 0.1329379  ... 0.10813096 0.16060722 0.1181592 ]\n  [0.10825003 0.16974863 0.13307098 ... 0.10865941 0.16066597 0.11870155]\n  [0.10817838 0.1692658  0.13312887 ... 0.10896203 0.1606775  0.11900225]]\n\n ...\n\n [[0.10525674 0.1694154  0.13156368 ... 0.11694203 0.12640415 0.14834054]\n  [0.10558967 0.16881755 0.13228232 ... 0.11680908 0.1263962  0.14805284]\n  [0.10382871 0.17124552 0.12877369 ... 0.11786425 0.12637947 0.14895529]\n  ...\n  [0.10492887 0.16980627 0.13128671 ... 0.11718161 0.12609392 0.14842339]\n  [0.10362688 0.17120379 0.1281383  ... 0.1178826  0.1270274  0.14887542]\n  [0.10479251 0.17015672 0.13038038 ... 0.11713681 0.12663205 0.1486944 ]]\n\n [[0.10266674 0.17005989 0.12621988 ... 0.11885105 0.1277657  0.14811173]\n  [0.10263125 0.17064822 0.12614883 ... 0.11894362 0.12732933 0.14838405]\n  [0.10336663 0.16760342 0.12702318 ... 0.11808015 0.12878741 0.14732634]\n  ...\n  [0.10261389 0.170089   0.1260598  ... 0.11904605 0.12748632 0.1481257 ]\n  [0.10395228 0.16662565 0.12768647 ... 0.11720379 0.12949297 0.14695689]\n  [0.1028977  0.16880481 0.12661743 ... 0.11845746 0.12864943 0.14763483]]\n\n [[0.10735319 0.16617878 0.12975916 ... 0.11301867 0.12855193 0.146289  ]\n  [0.10672992 0.16601287 0.1292423  ... 0.11393657 0.12859435 0.14655928]\n  [0.10933689 0.16794905 0.13207357 ... 0.10991679 0.12778783 0.14506917]\n  ...\n  [0.1074837  0.16646028 0.12989207 ... 0.11285977 0.12823048 0.14626902]\n  [0.10985585 0.16864619 0.13286828 ... 0.10902996 0.12774764 0.14451025]\n  [0.10837153 0.16657473 0.13071176 ... 0.11149464 0.12851451 0.14575392]]]", "accuracy": 0.09090909090909091, "inputs": "[[[-1.0574203 ]\n  [-1.0514047 ]\n  [-1.0463719 ]\n  ...\n  [-0.9943956 ]\n  [-0.9967297 ]\n  [-0.99922913]]\n\n [[-1.2535369 ]\n  [-1.2642459 ]\n  [-1.2733136 ]\n  ...\n  [-1.0389028 ]\n  [-1.034854  ]\n  [-1.0311028 ]]\n\n [[-0.70577186]\n  [-0.69676715]\n  [-0.689986  ]\n  ...\n  [-0.9754479 ]\n  [-0.9764079 ]\n  [-0.9773511 ]]\n\n ...\n\n [[-0.9909409 ]\n  [-1.0027453 ]\n  [-1.0147117 ]\n  ...\n  [-1.1046433 ]\n  [-1.1131419 ]\n  [-1.1218793 ]]\n\n [[-0.8702758 ]\n  [-0.85922086]\n  [-0.84914935]\n  ...\n  [-0.811603  ]\n  [-0.8145301 ]\n  [-0.8177387 ]]\n\n [[-0.7803517 ]\n  [-0.7895152 ]\n  [-0.7991167 ]\n  ...\n  [-0.8716578 ]\n  [-0.8707964 ]\n  [-0.870276  ]]]"}

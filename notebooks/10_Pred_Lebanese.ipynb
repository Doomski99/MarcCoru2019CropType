{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import sys\n",
    "sys.path.append(\"../src\")\n",
    "sys.path.append(\"../src/models\")\n",
    "\n",
    "from models.duplo import DuPLO\n",
    "import torch\n",
    "from train import prepare_dataset\n",
    "from argparse import Namespace\n",
    "from tqdm.notebook import tqdm\n",
    "import numpy as np\n",
    "import sklearn.metrics\n",
    "import pandas as pd\n",
    "import os\n",
    "from datasets.BavarianCrops_Dataset import BavarianCropsDataset\n",
    "from train_duplo import metrics\n",
    "\n",
    "model_root = \"../models/duplo\"\n",
    "\n",
    "def merge(namespaces):\n",
    "    merged = dict()\n",
    "\n",
    "    for n in namespaces:\n",
    "        d = n.__dict__\n",
    "        for k,v in d.items():\n",
    "            merged[k]=v\n",
    "\n",
    "    return Namespace(**merged)\n",
    "\n",
    "TUM_dataset = Namespace(\n",
    "    dataset = \"BavarianCrops\",\n",
    "    trainregions = [\"holl\",\"nowa\",\"krum\"],\n",
    "    testregions = [\"holl\",\"nowa\",\"krum\"],\n",
    "    scheme=\"blocks\",\n",
    "    test_on = \"test\",\n",
    "    train_on = \"trainvalid\",\n",
    "    samplet = 70\n",
    ")\n",
    "\n",
    "GAF_dataset = Namespace(\n",
    "    dataset = \"GAFv2\",\n",
    "    trainregions = [\"holl\",\"nowa\",\"krum\"],\n",
    "    testregions = [\"holl\",\"nowa\",\"krum\"],\n",
    "    features = \"optical\",\n",
    "    scheme=\"blocks\",\n",
    "    test_on=\"test\",\n",
    "    train_on=\"train\",\n",
    "    samplet = 23\n",
    ")\n",
    "\n",
    "def setup(dataset, mode, dataroot=\"../data\", store = '/tmp/'):\n",
    "    \n",
    "    if mode == \"12classes\":\n",
    "        classmapping = os.path.join(dataroot,\"BavarianCrops\",'classmapping12.csv')\n",
    "    elif mode == \"23classes\":\n",
    "        classmapping = os.path.join(dataroot,\"BavarianCrops\",'classmapping23.csv')\n",
    "    \n",
    "    args = Namespace(batchsize=256,\n",
    "                 classmapping=classmapping,\n",
    "                 dataroot=dataroot, dataset=dataset,\n",
    "                 model='duplo',mode=None,\n",
    "                 seed=0, store=store, workers=0)\n",
    "\n",
    "    if dataset == \"BavarianCrops\":\n",
    "        args = merge([args,TUM_dataset])\n",
    "        exp = \"isprs_tum_duplo\"\n",
    "    elif dataset == \"GAFv2\":\n",
    "        args = merge([args,GAF_dataset])\n",
    "        exp = \"isprs_gaf_duplo\"\n",
    "        \n",
    "    traindataloader, testdataloader = prepare_dataset(args)\n",
    "        \n",
    "    input_dim = traindataloader.dataset.datasets[0].ndims\n",
    "    nclasses = len(traindataloader.dataset.datasets[0].classes)\n",
    "\n",
    "    device = torch.device(\"cuda\")\n",
    "    model = DuPLO(input_dim=input_dim, nclasses=nclasses, sequencelength=args.samplet, dropout=0.4)\n",
    "    model.load(f\"{model_root}/{mode}/{exp}/model.pth\")\n",
    "\n",
    "    model.to(device)\n",
    "\n",
    "    \n",
    "    return testdataloader, model\n",
    "\n",
    "def evaluate(model, dataloader):\n",
    "    stats = list()\n",
    "    model.cuda()\n",
    "    model.eval()\n",
    "    y_preds = list()\n",
    "    ys = list()\n",
    "    ids = list()\n",
    "    with torch.no_grad():\n",
    "        for idx, batch in tqdm(enumerate(dataloader),total=len(dataloader)):\n",
    "            X,y,id = batch\n",
    "            logsoftmax , *_ = model.forward(X.transpose(1,2).cuda())\n",
    "            y_pred = logsoftmax.argmax(dim=1)\n",
    "            ys.append(y.cpu().detach().numpy())\n",
    "            y_preds.append(y_pred.cpu().detach().numpy())\n",
    "            ids.append(id)\n",
    "    model.cpu()\n",
    "    return np.hstack(y_preds), np.vstack(ys)[:,0], np.hstack(ids)\n",
    "    "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "testdataloader, model = setup(\"BavarianCrops\",\"23classes\")\n",
    "y_pred, y, ids = evaluate(model, testdataloader)\n",
    "print(sklearn.metrics.classification_report(y,y_pred))\n",
    "metrics(y,y_pred)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Initializing BavarianCropsDataset test partition in holl\n",
      "read 23 classes\n",
      "precached dataset files found at ../data/BavarianCrops/npy/classmapping23.csv/blocks/holl/test\n",
      "loaded 9792 samples\n",
      "Dataset ../data/BavarianCrops. region holl. partition test. X:9792x(144, 13), y:(9792,) with 23 classes\n",
      "Initializing BavarianCropsDataset test partition in nowa\n",
      "read 23 classes\n",
      "precached dataset files found at ../data/BavarianCrops/npy/classmapping23.csv/blocks/nowa/test\n",
      "loaded 3572 samples\n",
      "Dataset ../data/BavarianCrops. region nowa. partition test. X:3572x(287, 13), y:(3572,) with 23 classes\n",
      "Initializing BavarianCropsDataset test partition in krum\n",
      "read 23 classes\n",
      "precached dataset files found at ../data/BavarianCrops/npy/classmapping23.csv/blocks/krum/test\n",
      "loaded 4306 samples\n",
      "Dataset ../data/BavarianCrops. region krum. partition test. X:4306x(143, 13), y:(4306,) with 23 classes\n",
      "Initializing BavarianCropsDataset trainvalid partition in holl\n",
      "read 23 classes\n",
      "precached dataset files found at ../data/BavarianCrops/npy/classmapping23.csv/blocks/holl/trainvalid\n",
      "loaded 25308 samples\n",
      "Dataset ../data/BavarianCrops. region holl. partition trainvalid. X:25308x(71, 13), y:(25308,) with 23 classes\n",
      "Initializing BavarianCropsDataset trainvalid partition in nowa\n",
      "read 23 classes\n",
      "precached dataset files found at ../data/BavarianCrops/npy/classmapping23.csv/blocks/nowa/trainvalid\n",
      "loaded 8488 samples\n",
      "Dataset ../data/BavarianCrops. region nowa. partition trainvalid. X:8488x(289, 13), y:(8488,) with 23 classes\n",
      "Initializing BavarianCropsDataset trainvalid partition in krum\n",
      "read 23 classes\n",
      "precached dataset files found at ../data/BavarianCrops/npy/classmapping23.csv/blocks/krum/trainvalid\n",
      "loaded 25368 samples\n",
      "Dataset ../data/BavarianCrops. region krum. partition trainvalid. X:25368x(71, 13), y:(25368,) with 23 classes\n",
      "setting random seed to 0\n",
      "loading model from ../models/duplo/23classes/isprs_tum_duplo/model.pth\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/home/tanjara/.conda/envs/crop-type-mapping/lib/python3.7/site-packages/torch/nn/modules/rnn.py:51: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.4 and num_layers=1\n",
      "  \"num_layers={}\".format(dropout, num_layers))\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "  0%|          | 0/70 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "93273e4076d440a69201e628c9c040ee"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.19      0.07      0.10       356\n",
      "           1       0.46      0.68      0.55       225\n",
      "           2       0.65      0.29      0.40       882\n",
      "           3       0.00      0.00      0.00       469\n",
      "           4       0.00      0.00      0.00        23\n",
      "           5       0.65      0.78      0.71       995\n",
      "           6       0.92      0.96      0.94      1917\n",
      "           7       0.00      0.00      0.00        56\n",
      "           8       0.50      0.06      0.11        16\n",
      "           9       0.38      0.08      0.14       121\n",
      "          10       0.84      0.97      0.90      9301\n",
      "          11       0.25      0.00      0.01       226\n",
      "          12       0.00      0.00      0.00        52\n",
      "          13       0.27      0.12      0.17       104\n",
      "          14       0.60      0.84      0.70       777\n",
      "          15       0.74      0.82      0.78      1017\n",
      "          16       0.53      0.38      0.44       248\n",
      "          17       0.46      0.09      0.15       466\n",
      "          18       0.84      0.36      0.50        90\n",
      "          19       0.17      0.42      0.24        12\n",
      "          20       0.93      0.86      0.89       257\n",
      "          21       0.00      0.00      0.00        27\n",
      "          22       0.60      0.09      0.16        33\n",
      "\n",
      "    accuracy                           0.79     17670\n",
      "   macro avg       0.43      0.34      0.34     17670\n",
      "weighted avg       0.74      0.79      0.75     17670\n",
      "\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/home/tanjara/.conda/envs/crop-type-mapping/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/tanjara/.conda/envs/crop-type-mapping/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/tanjara/.conda/envs/crop-type-mapping/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/tanjara/.conda/envs/crop-type-mapping/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/tanjara/.conda/envs/crop-type-mapping/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'accuracy': 0.7900396151669496,\n",
       " 'kappa': 0.6795626476440702,\n",
       " 'f1_micro': 0.7900396151669495,\n",
       " 'f1_macro': 0.342844877582905,\n",
       " 'f1_weighted': 0.747589372509714,\n",
       " 'recall_micro': 0.7900396151669496,\n",
       " 'recall_macro': 0.3417897309311548,\n",
       " 'recall_weighted': 0.7900396151669496,\n",
       " 'precision_micro': 0.7900396151669496,\n",
       " 'precision_macro': 0.4343676608558107,\n",
       " 'precision_weighted': 0.73517078259069}"
      ]
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "source": [
    "#test = torch.ones([ 256, 70, 13], dtype=torch.FloatTensor, device='cuda:0')\n",
    "test = torch.ones(1, 70, 13)\n",
    "logsoftmax , *_ = model.forward(test.transpose(1,2))\n",
    "y_pred = logsoftmax.argmax(dim=1)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "source": [
    "print(y_pred)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor([9])\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "crop_csv = pd.read_csv('../data/Test/aadloun_crop.csv')\n",
    "droped_csv = crop_csv.drop({'lat', 'lon'},axis = 1)\n",
    "droped_csv = droped_csv.iloc[0:70, :]\n",
    "print(droped_csv.head)\n",
    "tensor_crop = torch.tensor(droped_csv.values).unsqueeze(0)\n",
    "print(tensor_crop.shape)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<bound method NDFrame.head of      Band1  Band2   Band3   Band4   Band5   Band6   Band7   Band8   Band9  \\\n",
      "0   1361.0   17.0  2730.5  1547.5  1103.5  1178.0  1387.5  1630.5  2793.5   \n",
      "1   1361.0   17.0  2730.5  1547.5  1064.0  1141.5  1184.0  1630.5  2793.5   \n",
      "2   1361.0   17.0  2647.0  1470.5  1059.5  1125.0  1119.5  1577.0  2863.0   \n",
      "3   1361.0   17.0  2600.0  1428.5  1064.0  1127.5  1086.5  1557.0  2942.5   \n",
      "4   1361.0   17.0  2600.0  1428.5  1066.0  1129.0  1087.0  1557.0  2942.5   \n",
      "..     ...    ...     ...     ...     ...     ...     ...     ...     ...   \n",
      "65  1257.5   16.5  2521.5  1449.0  1045.5  1135.0  1081.5  1537.0  2887.0   \n",
      "66  1257.5   16.5  2521.5  1449.0  1043.0  1136.5  1074.0  1537.0  2887.0   \n",
      "67  1282.5   17.5  2505.5  1434.0  1043.5  1136.5  1067.5  1535.0  2911.5   \n",
      "68  1282.5   17.5  2488.0  1409.0  1047.5  1142.0  1073.5  1525.0  2946.0   \n",
      "69  1282.5   17.5  2508.5  1373.5  1047.5  1148.0  1050.0  1502.5  3020.5   \n",
      "\n",
      "    Band10  Band11  Band12  Band13  \n",
      "0   3268.5  3175.5  3560.0  1165.0  \n",
      "1   3268.5  3386.0  3560.0  1165.0  \n",
      "2   3375.0  3454.5  3672.0  1165.0  \n",
      "3   3463.0  3437.5  3753.0  1165.0  \n",
      "4   3463.0  3396.5  3753.0  1165.0  \n",
      "..     ...     ...     ...     ...  \n",
      "65  3375.0  3314.0  3672.5  1145.5  \n",
      "66  3375.0  3368.0  3672.5  1145.5  \n",
      "67  3377.5  3404.5  3692.5  1190.5  \n",
      "68  3407.5  3382.0  3738.0  1190.5  \n",
      "69  3538.0  3451.0  3872.0  1190.5  \n",
      "\n",
      "[70 rows x 13 columns]>\n",
      "torch.Size([1, 70, 13])\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "logsoftmax , *_ = model.forward(tensor_crop.float().transpose(1,2))\n",
    "y_pred = logsoftmax.argmax(dim=1)\n",
    "print(y_pred)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor([18])\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.7.3",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.3 64-bit ('crop-type-mapping': conda)"
  },
  "interpreter": {
   "hash": "2ea37158e581c84da49f57675e0e248ae8eec3c7a5c1d14d345d6b290b33a157"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import sys\n",
    "sys.path.append(\"../src\")\n",
    "sys.path.append(\"../src/models\")\n",
    "from train import getModel, prepare_dataset\n",
    "from experiments import experiments\n",
    "import argparse\n",
    "import tqdm\n",
    "import numpy as np\n",
    "from datasets.ConcatDataset import ConcatDataset\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import sklearn.metrics\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patheffects as path_effects\n",
    "\n",
    "figdir=\"/home/marc/projects/ISPRS_CropTypeMapping/images/regions\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate pretrained model with one dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, dataloader):\n",
    "\n",
    "    probaslist = list()\n",
    "    targetslist = list()\n",
    "    idslist = list()\n",
    "    for iteration, data in tqdm.tqdm(enumerate(dataloader)):\n",
    "        inputs, targets, ids = data\n",
    "        if torch.cuda.is_available():\n",
    "            inputs = inputs.cuda()\n",
    "            targets = targets.cuda()\n",
    "            model.cuda()\n",
    "        else:\n",
    "            model.cpu()\n",
    "\n",
    "        logprobabilities, deltas, pts, budget = model.forward(inputs.transpose(1, 2))\n",
    "        probaslist.append(logprobabilities.exp().cpu().detach().numpy())\n",
    "        targetslist.append(targets.cpu().detach().numpy())\n",
    "        idslist.append(ids.numpy())\n",
    "\n",
    "    ids = np.hstack(idslist)\n",
    "    probas = np.vstack(probaslist)\n",
    "    targets = np.vstack(targetslist)[:,0]\n",
    "\n",
    "    return ids, targets, probas\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get pretrained model and run it on all three regions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def evaluate_regions(experiment, seed=0, metric=sklearn.metrics.cohen_kappa_score, name=\"regions\"):\n",
    "\n",
    "    args = argparse.Namespace(experiment=experiment, seed=seed, batchsize=256, workers=0, hparamset=None)\n",
    "    args = experiments(args)\n",
    "    \n",
    "    args.testregions = args.trainregions = [\"holl\"]\n",
    "    holltraindataloader, holltestdataloader = prepare_dataset(args)\n",
    "\n",
    "    args.testregions = args.trainregions = [\"nowa\"]\n",
    "    nowatraindataloader, nowatestdataloader = prepare_dataset(args)\n",
    "\n",
    "    args.testregions = args.trainregions = [\"krum\"]\n",
    "    krumtraindataloader, krumtestdataloader = prepare_dataset(args)\n",
    "\n",
    "    args.nclasses = holltraindataloader.dataset.nclasses\n",
    "    classname = holltraindataloader.dataset.classname\n",
    "    klassenname = holltraindataloader.dataset.klassenname\n",
    "    args.seqlength = holltraindataloader.dataset.sequencelength\n",
    "    args.input_dims = holltraindataloader.dataset.ndims\n",
    "    \n",
    "    model = getModel(args)\n",
    "    model.load(f\"/data/isprs/{name}/{seed}/{experiment}/model.pth\")\n",
    "\n",
    "    ids_holl, targets_holl, probas_holl = evaluate(model, holltestdataloader)\n",
    "    ids_nowa, targets_nowa, probas_nowa = evaluate(model, nowatestdataloader)\n",
    "    ids_krum, targets_krum, probas_krum = evaluate(model, krumtestdataloader)\n",
    "\n",
    "    holl = metric(targets_holl, probas_holl.argmax(1))\n",
    "    nowa = metric(targets_nowa, probas_nowa.argmax(1))\n",
    "    krum = metric(targets_krum, probas_krum.argmax(1))\n",
    "    \n",
    "    return holl, nowa, krum\n",
    "\n",
    "def plot(matrix, std_matrix=None):\n",
    "    fig,ax = plt.subplots()\n",
    "    ax.imshow(matrix)\n",
    "    ax.set_xticks([0,1,2])\n",
    "    ax.set_xticklabels([\"Hollfeld\", \"Bavarian Forest\", \"Krumbach\"])\n",
    "    ax.set_yticks([0,1,2])\n",
    "    ax.set_yticklabels([\"Hollfeld\", \"Bavarian Forest\", \"Krumbach\"])\n",
    "    ax.set_ylabel(\"trained\")\n",
    "    ax.set_xlabel(\"evaluated\")\n",
    "\n",
    "    for i in np.arange(matrix.shape[0]):\n",
    "        for j in np.arange(matrix.shape[0]):\n",
    "            entry=f\"{matrix[j,i]:.2f}\"\n",
    "            if std_matrix is not None:\n",
    "                entry+=\"$^{\" + f\"\\pm{std_matrix[j,i]:.2f}\" + \"}$\"\n",
    "            \n",
    "            txt = ax.text(i,j,entry, ha=\"center\", va=\"center\", color=\"black\",fontsize=14)\n",
    "            txt.set_path_effects([path_effects.Stroke(linewidth=2, foreground='white'),\n",
    "                           path_effects.Normal()])\n",
    "            \n",
    "    return fig\n",
    "\n",
    "\n",
    "def save_plot(fig,fname):\n",
    "    print(f\"writing {fname}\")\n",
    "    fig.savefig(fname,bbox_inches='tight',transparent=True, density=300)\n",
    "    \n",
    "def get_matrix(seed, run_experiments, metric):\n",
    "\n",
    "    hh, hn, hk = evaluate_regions(run_experiments[0], seed=seed, metric=metric)\n",
    "    nh, nn, nk = evaluate_regions(run_experiments[1], seed=seed, metric=metric)\n",
    "    kh, kn, kk = evaluate_regions(run_experiments[2], seed=seed, metric=metric)\n",
    "\n",
    "    return np.array([[hh, hn, hk],[nh, nn, nk],[kh, kn, kk]])\n",
    "    \n",
    "def print_tex(m_mean, m_std, prefix=[\"\",\"\",\"\"]):\n",
    "    table=\"\"\n",
    "    for row_mean, row_std, pre in zip(m_mean,m_std, prefix):\n",
    "        row = list()\n",
    "        for mean, std in zip(row_mean,row_std):\n",
    "            row.append(f\"{mean:.2f}\" + \"$^{\\pm\"+f\"{std:.2f}\"+\"}$\")\n",
    "\n",
    "        print(pre + \" & \".join(row) + r\" \\\\\")\n",
    "        \n",
    "def get_matrix_all_seeds(run_experiments, metric):\n",
    "\n",
    "    M = list()\n",
    "    for seed in [0,1,2]:\n",
    "        M.append(get_matrix(seed,run_experiments,metric))\n",
    "\n",
    "    M = np.stack(M)\n",
    "    \n",
    "    return M\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accuracy on preprocessed datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "run_experiments = [\"isprs_gafholl_transformer\",\"isprs_gafnowa_transformer\",\"isprs_gafkrum_transformer\"]\n",
    "metric = sklearn.metrics.accuracy_score\n",
    "\n",
    "original = sys.stdout\n",
    "with open(os.devnull, 'w') as f:\n",
    "    sys.stdout = f\n",
    "    M = get_matrix_all_seeds(run_experiments, metric)\n",
    "sys.stdout = original\n",
    "\n",
    "m_mean = M.mean(0)\n",
    "m_std = M.std(0)\n",
    "\n",
    "print_tex(m_mean, m_std, prefix=[\"& Hollfeld & \", \"trained & Bavarian Forest & \", \"& Krumbach & \"])\n",
    "save_plot(plot(m_mean, m_std), os.path.join(figdir,\"gaf_accuracy.png\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kappa on preprocessed datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "run_experiments = [\"isprs_gafholl_transformer\",\"isprs_gafnowa_transformer\",\"isprs_gafkrum_transformer\"]\n",
    "metric = sklearn.metrics.cohen_kappa_score\n",
    "\n",
    "original = sys.stdout\n",
    "with open(os.devnull, 'w') as f:\n",
    "    sys.stdout = original\n",
    "    M = get_matrix_all_seeds(run_experiments, metric)\n",
    "sys.stdout = original\n",
    "\n",
    "cm_mean = M.mean(0)\n",
    "m_std = M.std(0)\n",
    "\n",
    "print_tex(m_mean, m_std, prefix=[\"& Hollfeld & \", \"trained & Bavarian Forest & \", \"& Krumbach & \"])\n",
    "save_plot(plot(m_mean, m_std), os.path.join(figdir,\"gaf_kappa.png\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kappa on raw datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "run_experiments = [\"isprs_tumholl_transformer\",\"isprs_tumnowa_transformer\",\"isprs_tumkrum_transformer\"]\n",
    "metric = sklearn.metrics.cohen_kappa_score\n",
    "\n",
    "original = sys.stdout\n",
    "with open(os.devnull, 'w') as f:\n",
    "    sys.stdout = f\n",
    "    M = get_matrix_all_seeds(run_experiments, metric)\n",
    "sys.stdout = original\n",
    "\n",
    "m_mean = M.mean(0)\n",
    "m_std = M.std(0)\n",
    "\n",
    "print_tex(m_mean, m_std, prefix=[\"& Hollfeld & \", \"trained & Bavarian Forest & \", \"& Krumbach & \"])\n",
    "save_plot(plot(m_mean, m_std), os.path.join(figdir,\"tum_kappa.png\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accuracy on raw datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "run_experiments = [\"isprs_tumholl_transformer\",\"isprs_tumnowa_transformer\",\"isprs_tumkrum_transformer\"]\n",
    "metric = sklearn.metrics.accuracy_score\n",
    "\n",
    "original = sys.stdout\n",
    "with open(os.devnull, 'w') as f:\n",
    "    sys.stdout = f\n",
    "    M = get_matrix_all_seeds(run_experiments, metric)\n",
    "sys.stdout = original\n",
    "\n",
    "m_mean = M.mean(0)\n",
    "m_std = M.std(0)\n",
    "\n",
    "print_tex(m_mean, m_std, prefix=[\"& Hollfeld & \", \"trained & Bavarian Forest & \", \"& Krumbach & \"])\n",
    "save_plot(plot(m_mean, m_std), os.path.join(figdir,\"tum_accuracy.png\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accuracy on preprocessed datasets random split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "run_experiments = [\"isprs_gafholl_transformer_randomsplit\",\"isprs_gafnowa_transformer_randomsplit\",\n",
    "                   \"isprs_gafkrum_transformer_randomsplit\"]\n",
    "metric = sklearn.metrics.accuracy_score\n",
    "\n",
    "original = sys.stdout\n",
    "with open(os.devnull, 'w') as f:\n",
    "    sys.stdout = f\n",
    "    M = get_matrix_all_seeds(run_experiments, metric)\n",
    "sys.stdout = original\n",
    "\n",
    "m_mean = M.mean(0)\n",
    "m_std = M.std(0)\n",
    "\n",
    "print_tex(m_mean, m_std, prefix=[\"& Hollfeld & \", \"trained & Bavarian Forest & \", \"& Krumbach & \"])\n",
    "save_plot(plot(m_mean, m_std), os.path.join(figdir,\"gaf_accuracy_random.png\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kappa on preprocessed datasets random split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "run_experiments = [\"isprs_gafholl_transformer_randomsplit\",\"isprs_gafnowa_transformer_randomsplit\",\n",
    "                   \"isprs_gafkrum_transformer_randomsplit\"]\n",
    "metric = sklearn.metrics.cohen_kappa_score\n",
    "\n",
    "original = sys.stdout\n",
    "with open(os.devnull, 'w') as f:\n",
    "    sys.stdout = f\n",
    "    M = get_matrix_all_seeds(run_experiments, metric)\n",
    "sys.stdout = original\n",
    "\n",
    "m_mean = M.mean(0)\n",
    "m_std = M.std(0)\n",
    "\n",
    "print_tex(m_mean, m_std, prefix=[\"& Hollfeld & \", \"trained & Bavarian Forest & \", \"& Krumbach & \"])\n",
    "save_plot(plot(m_mean, m_std), os.path.join(figdir,\"gaf_kappa_random.png\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accuracy on raw datasets random split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "run_experiments = [\"isprs_tumholl_transformer_randomsplit\",\"isprs_tumnowa_transformer_randomsplit\",\n",
    "                   \"isprs_tumkrum_transformer_randomsplit\"]\n",
    "metric = sklearn.metrics.accuracy_score\n",
    "\n",
    "original = sys.stdout\n",
    "with open(os.devnull, 'w') as f:\n",
    "    sys.stdout = f\n",
    "    M = get_matrix_all_seeds(run_experiments, metric)\n",
    "sys.stdout = original\n",
    "\n",
    "m_mean = M.mean(0)\n",
    "m_std = M.std(0)\n",
    "\n",
    "print_tex(m_mean, m_std, prefix=[\"& Hollfeld & \", \"trained & Bavarian Forest & \", \"& Krumbach & \"])\n",
    "save_plot(plot(m_mean, m_std), os.path.join(figdir,\"tum_accuracy_random.png\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kappa on raw datasets random split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread IPythonHistorySavingThread:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/marc/miniconda3/envs/pytorch/lib/python3.7/site-packages/IPython/core/history.py\", line 780, in writeout_cache\n",
      "    self._writeout_input_cache(conn)\n",
      "  File \"/home/marc/miniconda3/envs/pytorch/lib/python3.7/site-packages/IPython/core/history.py\", line 764, in _writeout_input_cache\n",
      "    (self.session_number,)+line)\n",
      "sqlite3.IntegrityError: UNIQUE constraint failed: history.session, history.line\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/marc/miniconda3/envs/pytorch/lib/python3.7/site-packages/IPython/core/history.py\", line 834, in run\n",
      "    self.history_manager.writeout_cache(self.db)\n",
      "  File \"</home/marc/miniconda3/envs/pytorch/lib/python3.7/site-packages/decorator.py:decorator-gen-23>\", line 2, in writeout_cache\n",
      "  File \"/home/marc/miniconda3/envs/pytorch/lib/python3.7/site-packages/IPython/core/history.py\", line 58, in needs_sqlite\n",
      "    return f(self, *a, **kw)\n",
      "  File \"/home/marc/miniconda3/envs/pytorch/lib/python3.7/site-packages/IPython/core/history.py\", line 785, in writeout_cache\n",
      "    self.session_number)\n",
      "ValueError: I/O operation on closed file.\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/marc/miniconda3/envs/pytorch/lib/python3.7/threading.py\", line 917, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"</home/marc/miniconda3/envs/pytorch/lib/python3.7/site-packages/decorator.py:decorator-gen-24>\", line 2, in run\n",
      "  File \"/home/marc/miniconda3/envs/pytorch/lib/python3.7/site-packages/IPython/core/history.py\", line 58, in needs_sqlite\n",
      "    return f(self, *a, **kw)\n",
      "  File \"/home/marc/miniconda3/envs/pytorch/lib/python3.7/site-packages/IPython/core/history.py\", line 837, in run\n",
      "    \"History will not be written to the database.\") % repr(e))\n",
      "ValueError: I/O operation on closed file.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "run_experiments = [\"isprs_tumholl_transformer_randomsplit\",\"isprs_tumnowa_transformer_randomsplit\",\n",
    "                   \"isprs_tumkrum_transformer_randomsplit\"]\n",
    "metric = sklearn.metrics.cohen_kappa_score\n",
    "\n",
    "original = sys.stdout\n",
    "with open(os.devnull, 'w') as f:\n",
    "    sys.stdout = f\n",
    "    M = get_matrix_all_seeds(run_experiments, metric)\n",
    "sys.stdout = original\n",
    "\n",
    "m_mean = M.mean(0)\n",
    "m_std = M.std(0)\n",
    "\n",
    "print_tex(m_mean, m_std, prefix=[\"& Hollfeld & \", \"trained & Bavarian Forest & \", \"& Krumbach & \"])\n",
    "save_plot(plot(m_mean, m_std), os.path.join(figdir,\"tum_kappa_random.png\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train on holl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing BavarianCropsDataset test partition in holl\n",
      "read 12 classes\n",
      "precached dataset files found at /data/BavarianCrops/npy/classmapping.isprs2.csv/blocks/holl/test\n",
      "loaded 9583 samples\n",
      "Dataset /data/BavarianCrops. region holl. partition test. X:9583x(144, 13), y:(9583,) with 12 classes\n",
      "Initializing BavarianCropsDataset trainvalid partition in holl\n",
      "read 12 classes\n",
      "precached dataset files found at /data/BavarianCrops/npy/classmapping.isprs2.csv/blocks/holl/trainvalid\n",
      "loaded 24767 samples\n",
      "Dataset /data/BavarianCrops. region holl. partition trainvalid. X:24767x(71, 13), y:(24767,) with 12 classes\n",
      "setting random seed to 0\n",
      "Initializing BavarianCropsDataset test partition in nowa\n",
      "read 12 classes\n",
      "precached dataset files found at /data/BavarianCrops/npy/classmapping.isprs2.csv/blocks/nowa/test\n",
      "loaded 3547 samples\n",
      "Dataset /data/BavarianCrops. region nowa. partition test. X:3547x(287, 13), y:(3547,) with 12 classes\n",
      "Initializing BavarianCropsDataset trainvalid partition in nowa\n",
      "read 12 classes\n",
      "precached dataset files found at /data/BavarianCrops/npy/classmapping.isprs2.csv/blocks/nowa/trainvalid\n",
      "loaded 8425 samples\n",
      "Dataset /data/BavarianCrops. region nowa. partition trainvalid. X:8425x(289, 13), y:(8425,) with 12 classes\n",
      "setting random seed to 0\n",
      "Initializing BavarianCropsDataset test partition in krum\n",
      "read 12 classes\n",
      "precached dataset files found at /data/BavarianCrops/npy/classmapping.isprs2.csv/blocks/krum/test\n",
      "loaded 4278 samples\n",
      "Dataset /data/BavarianCrops. region krum. partition test. X:4278x(143, 13), y:(4278,) with 12 classes\n",
      "Initializing BavarianCropsDataset trainvalid partition in krum\n",
      "read 12 classes\n",
      "precached dataset files found at /data/BavarianCrops/npy/classmapping.isprs2.csv/blocks/krum/trainvalid\n",
      "loaded 25083 samples\n",
      "Dataset /data/BavarianCrops. region krum. partition trainvalid. X:25083x(71, 13), y:(25083,) with 12 classes\n",
      "setting random seed to 0\n",
      "initialized transformer model (604680 parameters)\n",
      "loading model from /data/isprs/preraw/0/isprs_tum_transformer/model.pth\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for TransformerEncoder:\n\tUnexpected key(s) in state_dict: \"encoder.layer_stack.3.slf_attn.w_qs.weight\", \"encoder.layer_stack.3.slf_attn.w_qs.bias\", \"encoder.layer_stack.3.slf_attn.w_ks.weight\", \"encoder.layer_stack.3.slf_attn.w_ks.bias\", \"encoder.layer_stack.3.slf_attn.w_vs.weight\", \"encoder.layer_stack.3.slf_attn.w_vs.bias\", \"encoder.layer_stack.3.slf_attn.layer_norm.weight\", \"encoder.layer_stack.3.slf_attn.layer_norm.bias\", \"encoder.layer_stack.3.slf_attn.fc.weight\", \"encoder.layer_stack.3.slf_attn.fc.bias\", \"encoder.layer_stack.3.pos_ffn.w_1.weight\", \"encoder.layer_stack.3.pos_ffn.w_1.bias\", \"encoder.layer_stack.3.pos_ffn.w_2.weight\", \"encoder.layer_stack.3.pos_ffn.w_2.bias\", \"encoder.layer_stack.3.pos_ffn.layer_norm.weight\", \"encoder.layer_stack.3.pos_ffn.layer_norm.bias\", \"encoder.layer_stack.4.slf_attn.w_qs.weight\", \"encoder.layer_stack.4.slf_attn.w_qs.bias\", \"encoder.layer_stack.4.slf_attn.w_ks.weight\", \"encoder.layer_stack.4.slf_attn.w_ks.bias\", \"encoder.layer_stack.4.slf_attn.w_vs.weight\", \"encoder.layer_stack.4.slf_attn.w_vs.bias\", \"encoder.layer_stack.4.slf_attn.layer_norm.weight\", \"encoder.layer_stack.4.slf_attn.layer_norm.bias\", \"encoder.layer_stack.4.slf_attn.fc.weight\", \"encoder.layer_stack.4.slf_attn.fc.bias\", \"encoder.layer_stack.4.pos_ffn.w_1.weight\", \"encoder.layer_stack.4.pos_ffn.w_1.bias\", \"encoder.layer_stack.4.pos_ffn.w_2.weight\", \"encoder.layer_stack.4.pos_ffn.w_2.bias\", \"encoder.layer_stack.4.pos_ffn.layer_norm.weight\", \"encoder.layer_stack.4.pos_ffn.layer_norm.bias\", \"encoder.layer_stack.5.slf_attn.w_qs.weight\", \"encoder.layer_stack.5.slf_attn.w_qs.bias\", \"encoder.layer_stack.5.slf_attn.w_ks.weight\", \"encoder.layer_stack.5.slf_attn.w_ks.bias\", \"encoder.layer_stack.5.slf_attn.w_vs.weight\", \"encoder.layer_stack.5.slf_attn.w_vs.bias\", \"encoder.layer_stack.5.slf_attn.layer_norm.weight\", \"encoder.layer_stack.5.slf_attn.layer_norm.bias\", \"encoder.layer_stack.5.slf_attn.fc.weight\", \"encoder.layer_stack.5.slf_attn.fc.bias\", \"encoder.layer_stack.5.pos_ffn.w_1.weight\", \"encoder.layer_stack.5.pos_ffn.w_1.bias\", \"encoder.layer_stack.5.pos_ffn.w_2.weight\", \"encoder.layer_stack.5.pos_ffn.w_2.bias\", \"encoder.layer_stack.5.pos_ffn.layer_norm.weight\", \"encoder.layer_stack.5.pos_ffn.layer_norm.bias\", \"encoder.layer_stack.6.slf_attn.w_qs.weight\", \"encoder.layer_stack.6.slf_attn.w_qs.bias\", \"encoder.layer_stack.6.slf_attn.w_ks.weight\", \"encoder.layer_stack.6.slf_attn.w_ks.bias\", \"encoder.layer_stack.6.slf_attn.w_vs.weight\", \"encoder.layer_stack.6.slf_attn.w_vs.bias\", \"encoder.layer_stack.6.slf_attn.layer_norm.weight\", \"encoder.layer_stack.6.slf_attn.layer_norm.bias\", \"encoder.layer_stack.6.slf_attn.fc.weight\", \"encoder.layer_stack.6.slf_attn.fc.bias\", \"encoder.layer_stack.6.pos_ffn.w_1.weight\", \"encoder.layer_stack.6.pos_ffn.w_1.bias\", \"encoder.layer_stack.6.pos_ffn.w_2.weight\", \"encoder.layer_stack.6.pos_ffn.w_2.bias\", \"encoder.layer_stack.6.pos_ffn.layer_norm.weight\", \"encoder.layer_stack.6.pos_ffn.layer_norm.bias\", \"encoder.layer_stack.7.slf_attn.w_qs.weight\", \"encoder.layer_stack.7.slf_attn.w_qs.bias\", \"encoder.layer_stack.7.slf_attn.w_ks.weight\", \"encoder.layer_stack.7.slf_attn.w_ks.bias\", \"encoder.layer_stack.7.slf_attn.w_vs.weight\", \"encoder.layer_stack.7.slf_attn.w_vs.bias\", \"encoder.layer_stack.7.slf_attn.layer_norm.weight\", \"encoder.layer_stack.7.slf_attn.layer_norm.bias\", \"encoder.layer_stack.7.slf_attn.fc.weight\", \"encoder.layer_stack.7.slf_attn.fc.bias\", \"encoder.layer_stack.7.pos_ffn.w_1.weight\", \"encoder.layer_stack.7.pos_ffn.w_1.bias\", \"encoder.layer_stack.7.pos_ffn.w_2.weight\", \"encoder.layer_stack.7.pos_ffn.w_2.bias\", \"encoder.layer_stack.7.pos_ffn.layer_norm.weight\", \"encoder.layer_stack.7.pos_ffn.layer_norm.bias\". \n\tsize mismatch for convlayernorm.weight: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for convlayernorm.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for outlayernorm.weight: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for outlayernorm.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for inconv.weight: copying a param with shape torch.Size([64, 13, 1]) from checkpoint, the shape in current model is torch.Size([128, 13, 1]).\n\tsize mismatch for inconv.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for encoder.position_enc.weight: copying a param with shape torch.Size([71, 64]) from checkpoint, the shape in current model is torch.Size([71, 128]).\n\tsize mismatch for encoder.layer_stack.0.slf_attn.w_qs.weight: copying a param with shape torch.Size([63, 64]) from checkpoint, the shape in current model is torch.Size([126, 128]).\n\tsize mismatch for encoder.layer_stack.0.slf_attn.w_qs.bias: copying a param with shape torch.Size([63]) from checkpoint, the shape in current model is torch.Size([126]).\n\tsize mismatch for encoder.layer_stack.0.slf_attn.w_ks.weight: copying a param with shape torch.Size([63, 64]) from checkpoint, the shape in current model is torch.Size([126, 128]).\n\tsize mismatch for encoder.layer_stack.0.slf_attn.w_ks.bias: copying a param with shape torch.Size([63]) from checkpoint, the shape in current model is torch.Size([126]).\n\tsize mismatch for encoder.layer_stack.0.slf_attn.w_vs.weight: copying a param with shape torch.Size([63, 64]) from checkpoint, the shape in current model is torch.Size([126, 128]).\n\tsize mismatch for encoder.layer_stack.0.slf_attn.w_vs.bias: copying a param with shape torch.Size([63]) from checkpoint, the shape in current model is torch.Size([126]).\n\tsize mismatch for encoder.layer_stack.0.slf_attn.layer_norm.weight: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for encoder.layer_stack.0.slf_attn.layer_norm.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for encoder.layer_stack.0.slf_attn.fc.weight: copying a param with shape torch.Size([64, 63]) from checkpoint, the shape in current model is torch.Size([128, 126]).\n\tsize mismatch for encoder.layer_stack.0.slf_attn.fc.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for encoder.layer_stack.0.pos_ffn.w_1.weight: copying a param with shape torch.Size([256, 64, 1]) from checkpoint, the shape in current model is torch.Size([512, 128, 1]).\n\tsize mismatch for encoder.layer_stack.0.pos_ffn.w_1.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for encoder.layer_stack.0.pos_ffn.w_2.weight: copying a param with shape torch.Size([64, 256, 1]) from checkpoint, the shape in current model is torch.Size([128, 512, 1]).\n\tsize mismatch for encoder.layer_stack.0.pos_ffn.w_2.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for encoder.layer_stack.0.pos_ffn.layer_norm.weight: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for encoder.layer_stack.0.pos_ffn.layer_norm.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for encoder.layer_stack.1.slf_attn.w_qs.weight: copying a param with shape torch.Size([63, 64]) from checkpoint, the shape in current model is torch.Size([126, 128]).\n\tsize mismatch for encoder.layer_stack.1.slf_attn.w_qs.bias: copying a param with shape torch.Size([63]) from checkpoint, the shape in current model is torch.Size([126]).\n\tsize mismatch for encoder.layer_stack.1.slf_attn.w_ks.weight: copying a param with shape torch.Size([63, 64]) from checkpoint, the shape in current model is torch.Size([126, 128]).\n\tsize mismatch for encoder.layer_stack.1.slf_attn.w_ks.bias: copying a param with shape torch.Size([63]) from checkpoint, the shape in current model is torch.Size([126]).\n\tsize mismatch for encoder.layer_stack.1.slf_attn.w_vs.weight: copying a param with shape torch.Size([63, 64]) from checkpoint, the shape in current model is torch.Size([126, 128]).\n\tsize mismatch for encoder.layer_stack.1.slf_attn.w_vs.bias: copying a param with shape torch.Size([63]) from checkpoint, the shape in current model is torch.Size([126]).\n\tsize mismatch for encoder.layer_stack.1.slf_attn.layer_norm.weight: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for encoder.layer_stack.1.slf_attn.layer_norm.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for encoder.layer_stack.1.slf_attn.fc.weight: copying a param with shape torch.Size([64, 63]) from checkpoint, the shape in current model is torch.Size([128, 126]).\n\tsize mismatch for encoder.layer_stack.1.slf_attn.fc.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for encoder.layer_stack.1.pos_ffn.w_1.weight: copying a param with shape torch.Size([256, 64, 1]) from checkpoint, the shape in current model is torch.Size([512, 128, 1]).\n\tsize mismatch for encoder.layer_stack.1.pos_ffn.w_1.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for encoder.layer_stack.1.pos_ffn.w_2.weight: copying a param with shape torch.Size([64, 256, 1]) from checkpoint, the shape in current model is torch.Size([128, 512, 1]).\n\tsize mismatch for encoder.layer_stack.1.pos_ffn.w_2.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for encoder.layer_stack.1.pos_ffn.layer_norm.weight: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for encoder.layer_stack.1.pos_ffn.layer_norm.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for encoder.layer_stack.2.slf_attn.w_qs.weight: copying a param with shape torch.Size([63, 64]) from checkpoint, the shape in current model is torch.Size([126, 128]).\n\tsize mismatch for encoder.layer_stack.2.slf_attn.w_qs.bias: copying a param with shape torch.Size([63]) from checkpoint, the shape in current model is torch.Size([126]).\n\tsize mismatch for encoder.layer_stack.2.slf_attn.w_ks.weight: copying a param with shape torch.Size([63, 64]) from checkpoint, the shape in current model is torch.Size([126, 128]).\n\tsize mismatch for encoder.layer_stack.2.slf_attn.w_ks.bias: copying a param with shape torch.Size([63]) from checkpoint, the shape in current model is torch.Size([126]).\n\tsize mismatch for encoder.layer_stack.2.slf_attn.w_vs.weight: copying a param with shape torch.Size([63, 64]) from checkpoint, the shape in current model is torch.Size([126, 128]).\n\tsize mismatch for encoder.layer_stack.2.slf_attn.w_vs.bias: copying a param with shape torch.Size([63]) from checkpoint, the shape in current model is torch.Size([126]).\n\tsize mismatch for encoder.layer_stack.2.slf_attn.layer_norm.weight: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for encoder.layer_stack.2.slf_attn.layer_norm.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for encoder.layer_stack.2.slf_attn.fc.weight: copying a param with shape torch.Size([64, 63]) from checkpoint, the shape in current model is torch.Size([128, 126]).\n\tsize mismatch for encoder.layer_stack.2.slf_attn.fc.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for encoder.layer_stack.2.pos_ffn.w_1.weight: copying a param with shape torch.Size([256, 64, 1]) from checkpoint, the shape in current model is torch.Size([512, 128, 1]).\n\tsize mismatch for encoder.layer_stack.2.pos_ffn.w_1.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for encoder.layer_stack.2.pos_ffn.w_2.weight: copying a param with shape torch.Size([64, 256, 1]) from checkpoint, the shape in current model is torch.Size([128, 512, 1]).\n\tsize mismatch for encoder.layer_stack.2.pos_ffn.w_2.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for encoder.layer_stack.2.pos_ffn.layer_norm.weight: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for encoder.layer_stack.2.pos_ffn.layer_norm.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for outlinear.weight: copying a param with shape torch.Size([12, 64]) from checkpoint, the shape in current model is torch.Size([12, 128]).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-b13811c6192b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m#with open(os.devnull, 'w') as f:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m#    sys.stdout = f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate_regions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"isprs_tum_transformer\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetric\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmetric\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"preraw\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;31m#sys.stdout = original\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-53330f29320d>\u001b[0m in \u001b[0;36mevaluate_regions\u001b[0;34m(experiment, seed, metric, name)\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"/data/isprs/{name}/{seed}/{experiment}/model.pth\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0mids_holl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets_holl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprobas_holl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mholltestdataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/projects/crop-type-mapping/src/models/TransformerEncoder.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(self, path)\u001b[0m\n\u001b[1;32m     84\u001b[0m         \u001b[0msnapshot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"cpu\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m         \u001b[0mmodel_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msnapshot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'model_state'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msnapshot\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0msnapshot\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/pytorch/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mload_state_dict\u001b[0;34m(self, state_dict, strict)\u001b[0m\n\u001b[1;32m    843\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_msgs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    844\u001b[0m             raise RuntimeError('Error(s) in loading state_dict for {}:\\n\\t{}'.format(\n\u001b[0;32m--> 845\u001b[0;31m                                self.__class__.__name__, \"\\n\\t\".join(error_msgs)))\n\u001b[0m\u001b[1;32m    846\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_IncompatibleKeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmissing_keys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munexpected_keys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    847\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for TransformerEncoder:\n\tUnexpected key(s) in state_dict: \"encoder.layer_stack.3.slf_attn.w_qs.weight\", \"encoder.layer_stack.3.slf_attn.w_qs.bias\", \"encoder.layer_stack.3.slf_attn.w_ks.weight\", \"encoder.layer_stack.3.slf_attn.w_ks.bias\", \"encoder.layer_stack.3.slf_attn.w_vs.weight\", \"encoder.layer_stack.3.slf_attn.w_vs.bias\", \"encoder.layer_stack.3.slf_attn.layer_norm.weight\", \"encoder.layer_stack.3.slf_attn.layer_norm.bias\", \"encoder.layer_stack.3.slf_attn.fc.weight\", \"encoder.layer_stack.3.slf_attn.fc.bias\", \"encoder.layer_stack.3.pos_ffn.w_1.weight\", \"encoder.layer_stack.3.pos_ffn.w_1.bias\", \"encoder.layer_stack.3.pos_ffn.w_2.weight\", \"encoder.layer_stack.3.pos_ffn.w_2.bias\", \"encoder.layer_stack.3.pos_ffn.layer_norm.weight\", \"encoder.layer_stack.3.pos_ffn.layer_norm.bias\", \"encoder.layer_stack.4.slf_attn.w_qs.weight\", \"encoder.layer_stack.4.slf_attn.w_qs.bias\", \"encoder.layer_stack.4.slf_attn.w_ks.weight\", \"encoder.layer_stack.4.slf_attn.w_ks.bias\", \"encoder.layer_stack.4.slf_attn.w_vs.weight\", \"encoder.layer_stack.4.slf_attn.w_vs.bias\", \"encoder.layer_stack.4.slf_attn.layer_norm.weight\", \"encoder.layer_stack.4.slf_attn.layer_norm.bias\", \"encoder.layer_stack.4.slf_attn.fc.weight\", \"encoder.layer_stack.4.slf_attn.fc.bias\", \"encoder.layer_stack.4.pos_ffn.w_1.weight\", \"encoder.layer_stack.4.pos_ffn.w_1.bias\", \"encoder.layer_stack.4.pos_ffn.w_2.weight\", \"encoder.layer_stack.4.pos_ffn.w_2.bias\", \"encoder.layer_stack.4.pos_ffn.layer_norm.weight\", \"encoder.layer_stack.4.pos_ffn.layer_norm.bias\", \"encoder.layer_stack.5.slf_attn.w_qs.weight\", \"encoder.layer_stack.5.slf_attn.w_qs.bias\", \"encoder.layer_stack.5.slf_attn.w_ks.weight\", \"encoder.layer_stack.5.slf_attn.w_ks.bias\", \"encoder.layer_stack.5.slf_attn.w_vs.weight\", \"encoder.layer_stack.5.slf_attn.w_vs.bias\", \"encoder.layer_stack.5.slf_attn.layer_norm.weight\", \"encoder.layer_stack.5.slf_attn.layer_norm.bias\", \"encoder.layer_stack.5.slf_attn.fc.weight\", \"encoder.layer_stack.5.slf_attn.fc.bias\", \"encoder.layer_stack.5.pos_ffn.w_1.weight\", \"encoder.layer_stack.5.pos_ffn.w_1.bias\", \"encoder.layer_stack.5.pos_ffn.w_2.weight\", \"encoder.layer_stack.5.pos_ffn.w_2.bias\", \"encoder.layer_stack.5.pos_ffn.layer_norm.weight\", \"encoder.layer_stack.5.pos_ffn.layer_norm.bias\", \"encoder.layer_stack.6.slf_attn.w_qs.weight\", \"encoder.layer_stack.6.slf_attn.w_qs.bias\", \"encoder.layer_stack.6.slf_attn.w_ks.weight\", \"encoder.layer_stack.6.slf_attn.w_ks.bias\", \"encoder.layer_stack.6.slf_attn.w_vs.weight\", \"encoder.layer_stack.6.slf_attn.w_vs.bias\", \"encoder.layer_stack.6.slf_attn.layer_norm.weight\", \"encoder.layer_stack.6.slf_attn.layer_norm.bias\", \"encoder.layer_stack.6.slf_attn.fc.weight\", \"encoder.layer_stack.6.slf_attn.fc.bias\", \"encoder.layer_stack.6.pos_ffn.w_1.weight\", \"encoder.layer_stack.6.pos_ffn.w_1.bias\", \"encoder.layer_stack.6.pos_ffn.w_2.weight\", \"encoder.layer_stack.6.pos_ffn.w_2.bias\", \"encoder.layer_stack.6.pos_ffn.layer_norm.weight\", \"encoder.layer_stack.6.pos_ffn.layer_norm.bias\", \"encoder.layer_stack.7.slf_attn.w_qs.weight\", \"encoder.layer_stack.7.slf_attn.w_qs.bias\", \"encoder.layer_stack.7.slf_attn.w_ks.weight\", \"encoder.layer_stack.7.slf_attn.w_ks.bias\", \"encoder.layer_stack.7.slf_attn.w_vs.weight\", \"encoder.layer_stack.7.slf_attn.w_vs.bias\", \"encoder.layer_stack.7.slf_attn.layer_norm.weight\", \"encoder.layer_stack.7.slf_attn.layer_norm.bias\", \"encoder.layer_stack.7.slf_attn.fc.weight\", \"encoder.layer_stack.7.slf_attn.fc.bias\", \"encoder.layer_stack.7.pos_ffn.w_1.weight\", \"encoder.layer_stack.7.pos_ffn.w_1.bias\", \"encoder.layer_stack.7.pos_ffn.w_2.weight\", \"encoder.layer_stack.7.pos_ffn.w_2.bias\", \"encoder.layer_stack.7.pos_ffn.layer_norm.weight\", \"encoder.layer_stack.7.pos_ffn.layer_norm.bias\". \n\tsize mismatch for convlayernorm.weight: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for convlayernorm.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for outlayernorm.weight: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for outlayernorm.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for inconv.weight: copying a param with shape torch.Size([64, 13, 1]) from checkpoint, the shape in current model is torch.Size([128, 13, 1]).\n\tsize mismatch for inconv.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for encoder.position_enc.weight: copying a param with shape torch.Size([71, 64]) from checkpoint, the shape in current model is torch.Size([71, 128]).\n\tsize mismatch for encoder.layer_stack.0.slf_attn.w_qs.weight: copying a param with shape torch.Size([63, 64]) from checkpoint, the shape in current model is torch.Size([126, 128]).\n\tsize mismatch for encoder.layer_stack.0.slf_attn.w_qs.bias: copying a param with shape torch.Size([63]) from checkpoint, the shape in current model is torch.Size([126]).\n\tsize mismatch for encoder.layer_stack.0.slf_attn.w_ks.weight: copying a param with shape torch.Size([63, 64]) from checkpoint, the shape in current model is torch.Size([126, 128]).\n\tsize mismatch for encoder.layer_stack.0.slf_attn.w_ks.bias: copying a param with shape torch.Size([63]) from checkpoint, the shape in current model is torch.Size([126]).\n\tsize mismatch for encoder.layer_stack.0.slf_attn.w_vs.weight: copying a param with shape torch.Size([63, 64]) from checkpoint, the shape in current model is torch.Size([126, 128]).\n\tsize mismatch for encoder.layer_stack.0.slf_attn.w_vs.bias: copying a param with shape torch.Size([63]) from checkpoint, the shape in current model is torch.Size([126]).\n\tsize mismatch for encoder.layer_stack.0.slf_attn.layer_norm.weight: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for encoder.layer_stack.0.slf_attn.layer_norm.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for encoder.layer_stack.0.slf_attn.fc.weight: copying a param with shape torch.Size([64, 63]) from checkpoint, the shape in current model is torch.Size([128, 126]).\n\tsize mismatch for encoder.layer_stack.0.slf_attn.fc.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for encoder.layer_stack.0.pos_ffn.w_1.weight: copying a param with shape torch.Size([256, 64, 1]) from checkpoint, the shape in current model is torch.Size([512, 128, 1]).\n\tsize mismatch for encoder.layer_stack.0.pos_ffn.w_1.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for encoder.layer_stack.0.pos_ffn.w_2.weight: copying a param with shape torch.Size([64, 256, 1]) from checkpoint, the shape in current model is torch.Size([128, 512, 1]).\n\tsize mismatch for encoder.layer_stack.0.pos_ffn.w_2.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for encoder.layer_stack.0.pos_ffn.layer_norm.weight: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for encoder.layer_stack.0.pos_ffn.layer_norm.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for encoder.layer_stack.1.slf_attn.w_qs.weight: copying a param with shape torch.Size([63, 64]) from checkpoint, the shape in current model is torch.Size([126, 128]).\n\tsize mismatch for encoder.layer_stack.1.slf_attn.w_qs.bias: copying a param with shape torch.Size([63]) from checkpoint, the shape in current model is torch.Size([126]).\n\tsize mismatch for encoder.layer_stack.1.slf_attn.w_ks.weight: copying a param with shape torch.Size([63, 64]) from checkpoint, the shape in current model is torch.Size([126, 128]).\n\tsize mismatch for encoder.layer_stack.1.slf_attn.w_ks.bias: copying a param with shape torch.Size([63]) from checkpoint, the shape in current model is torch.Size([126]).\n\tsize mismatch for encoder.layer_stack.1.slf_attn.w_vs.weight: copying a param with shape torch.Size([63, 64]) from checkpoint, the shape in current model is torch.Size([126, 128]).\n\tsize mismatch for encoder.layer_stack.1.slf_attn.w_vs.bias: copying a param with shape torch.Size([63]) from checkpoint, the shape in current model is torch.Size([126]).\n\tsize mismatch for encoder.layer_stack.1.slf_attn.layer_norm.weight: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for encoder.layer_stack.1.slf_attn.layer_norm.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for encoder.layer_stack.1.slf_attn.fc.weight: copying a param with shape torch.Size([64, 63]) from checkpoint, the shape in current model is torch.Size([128, 126]).\n\tsize mismatch for encoder.layer_stack.1.slf_attn.fc.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for encoder.layer_stack.1.pos_ffn.w_1.weight: copying a param with shape torch.Size([256, 64, 1]) from checkpoint, the shape in current model is torch.Size([512, 128, 1]).\n\tsize mismatch for encoder.layer_stack.1.pos_ffn.w_1.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for encoder.layer_stack.1.pos_ffn.w_2.weight: copying a param with shape torch.Size([64, 256, 1]) from checkpoint, the shape in current model is torch.Size([128, 512, 1]).\n\tsize mismatch for encoder.layer_stack.1.pos_ffn.w_2.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for encoder.layer_stack.1.pos_ffn.layer_norm.weight: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for encoder.layer_stack.1.pos_ffn.layer_norm.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for encoder.layer_stack.2.slf_attn.w_qs.weight: copying a param with shape torch.Size([63, 64]) from checkpoint, the shape in current model is torch.Size([126, 128]).\n\tsize mismatch for encoder.layer_stack.2.slf_attn.w_qs.bias: copying a param with shape torch.Size([63]) from checkpoint, the shape in current model is torch.Size([126]).\n\tsize mismatch for encoder.layer_stack.2.slf_attn.w_ks.weight: copying a param with shape torch.Size([63, 64]) from checkpoint, the shape in current model is torch.Size([126, 128]).\n\tsize mismatch for encoder.layer_stack.2.slf_attn.w_ks.bias: copying a param with shape torch.Size([63]) from checkpoint, the shape in current model is torch.Size([126]).\n\tsize mismatch for encoder.layer_stack.2.slf_attn.w_vs.weight: copying a param with shape torch.Size([63, 64]) from checkpoint, the shape in current model is torch.Size([126, 128]).\n\tsize mismatch for encoder.layer_stack.2.slf_attn.w_vs.bias: copying a param with shape torch.Size([63]) from checkpoint, the shape in current model is torch.Size([126]).\n\tsize mismatch for encoder.layer_stack.2.slf_attn.layer_norm.weight: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for encoder.layer_stack.2.slf_attn.layer_norm.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for encoder.layer_stack.2.slf_attn.fc.weight: copying a param with shape torch.Size([64, 63]) from checkpoint, the shape in current model is torch.Size([128, 126]).\n\tsize mismatch for encoder.layer_stack.2.slf_attn.fc.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for encoder.layer_stack.2.pos_ffn.w_1.weight: copying a param with shape torch.Size([256, 64, 1]) from checkpoint, the shape in current model is torch.Size([512, 128, 1]).\n\tsize mismatch for encoder.layer_stack.2.pos_ffn.w_1.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for encoder.layer_stack.2.pos_ffn.w_2.weight: copying a param with shape torch.Size([64, 256, 1]) from checkpoint, the shape in current model is torch.Size([128, 512, 1]).\n\tsize mismatch for encoder.layer_stack.2.pos_ffn.w_2.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for encoder.layer_stack.2.pos_ffn.layer_norm.weight: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for encoder.layer_stack.2.pos_ffn.layer_norm.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for outlinear.weight: copying a param with shape torch.Size([12, 64]) from checkpoint, the shape in current model is torch.Size([12, 128])."
     ]
    }
   ],
   "source": [
    "run_experiments = [\"isprs_gaf_transformer\"]\n",
    "metric = sklearn.metrics.cohen_kappa_score\n",
    "\n",
    "original = sys.stdout\n",
    "#with open(os.devnull, 'w') as f:\n",
    "#    sys.stdout = f\n",
    "m = evaluate_regions(\"isprs_tum_transformer\", seed=0, metric=metric, name=\"preraw\")\n",
    "#sys.stdout = original\n",
    "\n",
    "m_mean = M.mean(0)\n",
    "m_std = M.std(0)\n",
    "\n",
    "#print_tex(m_mean, m_std, prefix=[\"& Hollfeld & \", \"trained & Bavarian Forest & \", \"& Krumbach & \"])\n",
    "#save_plot(plot(m_mean, m_std), os.path.join(figdir,\"tum_kappa_random.png\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

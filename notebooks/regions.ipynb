{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import sys\n",
    "sys.path.append(\"../src\")\n",
    "sys.path.append(\"../src/models\")\n",
    "from train import getModel, prepare_dataset\n",
    "from experiments import experiments\n",
    "import argparse\n",
    "import tqdm\n",
    "import numpy as np\n",
    "from datasets.ConcatDataset import ConcatDataset\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import sklearn.metrics\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patheffects as path_effects\n",
    "\n",
    "figdir=\"/home/marc/projects/ISPRS_CropTypeMapping/images/regions\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate pretrained model with one dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, dataloader):\n",
    "\n",
    "    probaslist = list()\n",
    "    targetslist = list()\n",
    "    idslist = list()\n",
    "    for iteration, data in tqdm.tqdm(enumerate(dataloader)):\n",
    "        inputs, targets, ids = data\n",
    "        if torch.cuda.is_available():\n",
    "            inputs = inputs.cuda()\n",
    "            targets = targets.cuda()\n",
    "            model.cuda()\n",
    "        else:\n",
    "            model.cpu()\n",
    "\n",
    "        logprobabilities, deltas, pts, budget = model.forward(inputs.transpose(1, 2))\n",
    "        probaslist.append(logprobabilities.exp().cpu().detach().numpy())\n",
    "        targetslist.append(targets.cpu().detach().numpy())\n",
    "        idslist.append(ids.numpy())\n",
    "\n",
    "    ids = np.hstack(idslist)\n",
    "    probas = np.vstack(probaslist)\n",
    "    targets = np.vstack(targetslist)[:,0]\n",
    "\n",
    "    return ids, targets, probas\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get pretrained model and run it on all three regions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def evaluate_regions(experiment, seed=0, metric=sklearn.metrics.cohen_kappa_score, name=\"regions\"):\n",
    "\n",
    "    args = argparse.Namespace(experiment=experiment, seed=seed, batchsize=256, workers=0, hparamset=None)\n",
    "    args = experiments(args)\n",
    "    \n",
    "    args.testregions = args.trainregions = [\"holl\"]\n",
    "    holltraindataloader, holltestdataloader = prepare_dataset(args)\n",
    "\n",
    "    args.testregions = args.trainregions = [\"nowa\"]\n",
    "    nowatraindataloader, nowatestdataloader = prepare_dataset(args)\n",
    "\n",
    "    args.testregions = args.trainregions = [\"krum\"]\n",
    "    krumtraindataloader, krumtestdataloader = prepare_dataset(args)\n",
    "\n",
    "    args.nclasses = holltraindataloader.dataset.nclasses\n",
    "    classname = holltraindataloader.dataset.classname\n",
    "    klassenname = holltraindataloader.dataset.klassenname\n",
    "    args.seqlength = holltraindataloader.dataset.sequencelength\n",
    "    args.input_dims = holltraindataloader.dataset.ndims\n",
    "    \n",
    "    model = getModel(args)\n",
    "    model.load(f\"/data/isprs/{name}/{seed}/{experiment}/model.pth\")\n",
    "\n",
    "    ids_holl, targets_holl, probas_holl = evaluate(model, holltestdataloader)\n",
    "    ids_nowa, targets_nowa, probas_nowa = evaluate(model, nowatestdataloader)\n",
    "    ids_krum, targets_krum, probas_krum = evaluate(model, krumtestdataloader)\n",
    "\n",
    "    holl = metric(targets_holl, probas_holl.argmax(1))\n",
    "    nowa = metric(targets_nowa, probas_nowa.argmax(1))\n",
    "    krum = metric(targets_krum, probas_krum.argmax(1))\n",
    "    \n",
    "    return holl, nowa, krum\n",
    "\n",
    "def plot(matrix, std_matrix=None):\n",
    "    fig,ax = plt.subplots()\n",
    "    ax.imshow(matrix)\n",
    "    ax.set_xticks([0,1,2])\n",
    "    ax.set_xticklabels([\"Hollfeld\", \"Bavarian Forest\", \"Krumbach\"])\n",
    "    ax.set_yticks([0,1,2])\n",
    "    ax.set_yticklabels([\"Hollfeld\", \"Bavarian Forest\", \"Krumbach\"])\n",
    "    ax.set_ylabel(\"trained\")\n",
    "    ax.set_xlabel(\"evaluated\")\n",
    "\n",
    "    for i in np.arange(matrix.shape[0]):\n",
    "        for j in np.arange(matrix.shape[0]):\n",
    "            entry=f\"{matrix[j,i]:.2f}\"\n",
    "            if std_matrix is not None:\n",
    "                entry+=\"$^{\" + f\"\\pm{std_matrix[j,i]:.2f}\" + \"}$\"\n",
    "            \n",
    "            txt = ax.text(i,j,entry, ha=\"center\", va=\"center\", color=\"black\",fontsize=14)\n",
    "            txt.set_path_effects([path_effects.Stroke(linewidth=2, foreground='white'),\n",
    "                           path_effects.Normal()])\n",
    "            \n",
    "    return fig\n",
    "\n",
    "\n",
    "def save_plot(fig,fname):\n",
    "    print(f\"writing {fname}\")\n",
    "    fig.savefig(fname,bbox_inches='tight',transparent=True, density=300)\n",
    "    \n",
    "def get_matrix(seed, run_experiments, metric):\n",
    "\n",
    "    hh, hn, hk = evaluate_regions(run_experiments[0], seed=seed, metric=metric)\n",
    "    nh, nn, nk = evaluate_regions(run_experiments[1], seed=seed, metric=metric)\n",
    "    kh, kn, kk = evaluate_regions(run_experiments[2], seed=seed, metric=metric)\n",
    "\n",
    "    return np.array([[hh, hn, hk],[nh, nn, nk],[kh, kn, kk]])\n",
    "    \n",
    "def print_tex(m_mean, m_std, prefix=[\"\",\"\",\"\"]):\n",
    "    table=\"\"\n",
    "    for row_mean, row_std, pre in zip(m_mean,m_std, prefix):\n",
    "        row = list()\n",
    "        for mean, std in zip(row_mean,row_std):\n",
    "            row.append(f\"{mean:.2f}\" + \"$^{\\pm\"+f\"{std:.2f}\"+\"}$\")\n",
    "\n",
    "        print(pre + \" & \".join(row) + r\" \\\\\")\n",
    "        \n",
    "def get_matrix_all_seeds(run_experiments, metric):\n",
    "\n",
    "    M = list()\n",
    "    for seed in [0,1,2]:\n",
    "        M.append(get_matrix(seed,run_experiments,metric))\n",
    "\n",
    "    M = np.stack(M)\n",
    "    \n",
    "    return M\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accuracy on preprocessed datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "run_experiments = [\"isprs_gafholl_transformer\",\"isprs_gafnowa_transformer\",\"isprs_gafkrum_transformer\"]\n",
    "metric = sklearn.metrics.accuracy_score\n",
    "\n",
    "original = sys.stdout\n",
    "with open(os.devnull, 'w') as f:\n",
    "    sys.stdout = f\n",
    "    M = get_matrix_all_seeds(run_experiments, metric)\n",
    "sys.stdout = original\n",
    "\n",
    "m_mean = M.mean(0)\n",
    "m_std = M.std(0)\n",
    "\n",
    "print_tex(m_mean, m_std, prefix=[\"& Hollfeld & \", \"trained & Bavarian Forest & \", \"& Krumbach & \"])\n",
    "save_plot(plot(m_mean, m_std), os.path.join(figdir,\"gaf_accuracy.png\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kappa on preprocessed datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread IPythonHistorySavingThread:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/marc/miniconda3/envs/croptypemapping/lib/python3.7/site-packages/IPython/core/history.py\", line 780, in writeout_cache\n",
      "    self._writeout_input_cache(conn)\n",
      "  File \"/home/marc/miniconda3/envs/croptypemapping/lib/python3.7/site-packages/IPython/core/history.py\", line 764, in _writeout_input_cache\n",
      "    (self.session_number,)+line)\n",
      "sqlite3.IntegrityError: UNIQUE constraint failed: history.session, history.line\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/marc/miniconda3/envs/croptypemapping/lib/python3.7/site-packages/IPython/core/history.py\", line 834, in run\n",
      "    self.history_manager.writeout_cache(self.db)\n",
      "  File \"</home/marc/miniconda3/envs/croptypemapping/lib/python3.7/site-packages/decorator.py:decorator-gen-23>\", line 2, in writeout_cache\n",
      "  File \"/home/marc/miniconda3/envs/croptypemapping/lib/python3.7/site-packages/IPython/core/history.py\", line 58, in needs_sqlite\n",
      "    return f(self, *a, **kw)\n",
      "  File \"/home/marc/miniconda3/envs/croptypemapping/lib/python3.7/site-packages/IPython/core/history.py\", line 785, in writeout_cache\n",
      "    self.session_number)\n",
      "ValueError: I/O operation on closed file.\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/marc/miniconda3/envs/croptypemapping/lib/python3.7/threading.py\", line 917, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"</home/marc/miniconda3/envs/croptypemapping/lib/python3.7/site-packages/decorator.py:decorator-gen-24>\", line 2, in run\n",
      "  File \"/home/marc/miniconda3/envs/croptypemapping/lib/python3.7/site-packages/IPython/core/history.py\", line 58, in needs_sqlite\n",
      "    return f(self, *a, **kw)\n",
      "  File \"/home/marc/miniconda3/envs/croptypemapping/lib/python3.7/site-packages/IPython/core/history.py\", line 837, in run\n",
      "    \"History will not be written to the database.\") % repr(e))\n",
      "ValueError: I/O operation on closed file.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "run_experiments = [\"isprs_gafholl_transformer\",\"isprs_gafnowa_transformer\",\"isprs_gafkrum_transformer\"]\n",
    "metric = sklearn.metrics.cohen_kappa_score\n",
    "\n",
    "original = sys.stdout\n",
    "with open(os.devnull, 'w') as f:\n",
    "    sys.stdout = original\n",
    "    M = get_matrix_all_seeds(run_experiments, metric)\n",
    "sys.stdout = original\n",
    "\n",
    "cm_mean = M.mean(0)\n",
    "m_std = M.std(0)\n",
    "\n",
    "print_tex(m_mean, m_std, prefix=[\"& Hollfeld & \", \"trained & Bavarian Forest & \", \"& Krumbach & \"])\n",
    "save_plot(plot(m_mean, m_std), os.path.join(figdir,\"gaf_kappa.png\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kappa on raw datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "run_experiments = [\"isprs_tumholl_transformer\",\"isprs_tumnowa_transformer\",\"isprs_tumkrum_transformer\"]\n",
    "metric = sklearn.metrics.cohen_kappa_score\n",
    "\n",
    "original = sys.stdout\n",
    "with open(os.devnull, 'w') as f:\n",
    "    sys.stdout = f\n",
    "    M = get_matrix_all_seeds(run_experiments, metric)\n",
    "sys.stdout = original\n",
    "\n",
    "m_mean = M.mean(0)\n",
    "m_std = M.std(0)\n",
    "\n",
    "print_tex(m_mean, m_std, prefix=[\"& Hollfeld & \", \"trained & Bavarian Forest & \", \"& Krumbach & \"])\n",
    "save_plot(plot(m_mean, m_std), os.path.join(figdir,\"tum_kappa.png\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accuracy on raw datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "run_experiments = [\"isprs_tumholl_transformer\",\"isprs_tumnowa_transformer\",\"isprs_tumkrum_transformer\"]\n",
    "metric = sklearn.metrics.accuracy_score\n",
    "\n",
    "original = sys.stdout\n",
    "with open(os.devnull, 'w') as f:\n",
    "    sys.stdout = f\n",
    "    M = get_matrix_all_seeds(run_experiments, metric)\n",
    "sys.stdout = original\n",
    "\n",
    "m_mean = M.mean(0)\n",
    "m_std = M.std(0)\n",
    "\n",
    "print_tex(m_mean, m_std, prefix=[\"& Hollfeld & \", \"trained & Bavarian Forest & \", \"& Krumbach & \"])\n",
    "save_plot(plot(m_mean, m_std), os.path.join(figdir,\"tum_accuracy.png\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accuracy on preprocessed datasets random split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "run_experiments = [\"isprs_gafholl_transformer_randomsplit\",\"isprs_gafnowa_transformer_randomsplit\",\n",
    "                   \"isprs_gafkrum_transformer_randomsplit\"]\n",
    "metric = sklearn.metrics.accuracy_score\n",
    "\n",
    "original = sys.stdout\n",
    "with open(os.devnull, 'w') as f:\n",
    "    sys.stdout = f\n",
    "    M = get_matrix_all_seeds(run_experiments, metric)\n",
    "sys.stdout = original\n",
    "\n",
    "m_mean = M.mean(0)\n",
    "m_std = M.std(0)\n",
    "\n",
    "print_tex(m_mean, m_std, prefix=[\"& Hollfeld & \", \"trained & Bavarian Forest & \", \"& Krumbach & \"])\n",
    "save_plot(plot(m_mean, m_std), os.path.join(figdir,\"gaf_accuracy_random.png\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kappa on preprocessed datasets random split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "run_experiments = [\"isprs_gafholl_transformer_randomsplit\",\"isprs_gafnowa_transformer_randomsplit\",\n",
    "                   \"isprs_gafkrum_transformer_randomsplit\"]\n",
    "metric = sklearn.metrics.cohen_kappa_score\n",
    "\n",
    "original = sys.stdout\n",
    "with open(os.devnull, 'w') as f:\n",
    "    sys.stdout = f\n",
    "    M = get_matrix_all_seeds(run_experiments, metric)\n",
    "sys.stdout = original\n",
    "\n",
    "m_mean = M.mean(0)\n",
    "m_std = M.std(0)\n",
    "\n",
    "print_tex(m_mean, m_std, prefix=[\"& Hollfeld & \", \"trained & Bavarian Forest & \", \"& Krumbach & \"])\n",
    "save_plot(plot(m_mean, m_std), os.path.join(figdir,\"gaf_kappa_random.png\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accuracy on raw datasets random split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "run_experiments = [\"isprs_tumholl_transformer_randomsplit\",\"isprs_tumnowa_transformer_randomsplit\",\n",
    "                   \"isprs_tumkrum_transformer_randomsplit\"]\n",
    "metric = sklearn.metrics.accuracy_score\n",
    "\n",
    "original = sys.stdout\n",
    "with open(os.devnull, 'w') as f:\n",
    "    sys.stdout = f\n",
    "    M = get_matrix_all_seeds(run_experiments, metric)\n",
    "sys.stdout = original\n",
    "\n",
    "m_mean = M.mean(0)\n",
    "m_std = M.std(0)\n",
    "\n",
    "print_tex(m_mean, m_std, prefix=[\"& Hollfeld & \", \"trained & Bavarian Forest & \", \"& Krumbach & \"])\n",
    "save_plot(plot(m_mean, m_std), os.path.join(figdir,\"tum_accuracy_random.png\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kappa on raw datasets random split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "run_experiments = [\"isprs_tumholl_transformer_randomsplit\",\"isprs_tumnowa_transformer_randomsplit\",\n",
    "                   \"isprs_tumkrum_transformer_randomsplit\"]\n",
    "metric = sklearn.metrics.cohen_kappa_score\n",
    "\n",
    "original = sys.stdout\n",
    "with open(os.devnull, 'w') as f:\n",
    "    sys.stdout = f\n",
    "    M = get_matrix_all_seeds(run_experiments, metric)\n",
    "sys.stdout = original\n",
    "\n",
    "m_mean = M.mean(0)\n",
    "m_std = M.std(0)\n",
    "\n",
    "print_tex(m_mean, m_std, prefix=[\"& Hollfeld & \", \"trained & Bavarian Forest & \", \"& Krumbach & \"])\n",
    "save_plot(plot(m_mean, m_std), os.path.join(figdir,\"tum_kappa_random.png\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train on holl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_experiments = [\"isprs_gaf_transformer\"]\n",
    "metric = sklearn.metrics.cohen_kappa_score\n",
    "\n",
    "original = sys.stdout\n",
    "#with open(os.devnull, 'w') as f:\n",
    "#    sys.stdout = f\n",
    "m = evaluate_regions(\"isprs_tum_transformer\", seed=0, metric=metric, name=\"preraw\")\n",
    "#sys.stdout = original\n",
    "\n",
    "m_mean = M.mean(0)\n",
    "m_std = M.std(0)\n",
    "\n",
    "#print_tex(m_mean, m_std, prefix=[\"& Hollfeld & \", \"trained & Bavarian Forest & \", \"& Krumbach & \"])\n",
    "#save_plot(plot(m_mean, m_std), os.path.join(figdir,\"tum_kappa_random.png\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
